{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41d1afce",
   "metadata": {},
   "source": [
    "# YOLOv11s Fine-tuning for Chest X-ray Abnormality Detection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d7bbfc",
   "metadata": {},
   "source": [
    "## Section 1: Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74c92a5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T01:26:56.276268Z",
     "iopub.status.busy": "2025-11-10T01:26:56.275931Z",
     "iopub.status.idle": "2025-11-10T01:27:16.120851Z",
     "shell.execute_reply": "2025-11-10T01:27:16.120054Z",
     "shell.execute_reply.started": "2025-11-10T01:26:56.276243Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!uv pip install -q roboflow ultralytics wandb tqdm pillow numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "644a5e3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T01:27:16.122574Z",
     "iopub.status.busy": "2025-11-10T01:27:16.122347Z",
     "iopub.status.idle": "2025-11-10T01:27:22.217318Z",
     "shell.execute_reply": "2025-11-10T01:27:22.216587Z",
     "shell.execute_reply.started": "2025-11-10T01:27:16.122551Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new Ultralytics Settings v0.0.6 file ‚úÖ \n",
      "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
      "‚úì Imports successful\n",
      "  PyTorch version: 2.6.0+cu124\n",
      "  CUDA available: True\n",
      "  GPU: Tesla T4\n",
      "  GPU Memory: 15.8 GB\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "\n",
    "import torch\n",
    "import wandb\n",
    "from ultralytics import YOLO, settings\n",
    "\n",
    "# Import custom augmentation\n",
    "import sys\n",
    "sys.path.insert(0, str(Path.cwd()))\n",
    "\n",
    "print(\"‚úì Imports successful\")\n",
    "print(f\"  PyTorch version: {torch.__version__}\")\n",
    "print(f\"  CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"  GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"  GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062737cc",
   "metadata": {},
   "source": [
    "## Section 2: Verify Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b568c272-26ba-4326-bd68-70427bc707de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T01:27:22.218236Z",
     "iopub.status.busy": "2025-11-10T01:27:22.217978Z",
     "iopub.status.idle": "2025-11-10T01:27:28.025271Z",
     "shell.execute_reply": "2025-11-10T01:27:28.024603Z",
     "shell.execute_reply.started": "2025-11-10T01:27:22.218206Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'preprocessed_with_aug.zip'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gdown\n",
    "gdown.download(quiet=True, id=\"1WZYxOg76hdgoKMiRfBFeyi8Baig2ooF1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06a1e38e-17db-48da-b565-096355c35d0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T01:27:28.026922Z",
     "iopub.status.busy": "2025-11-10T01:27:28.026602Z",
     "iopub.status.idle": "2025-11-10T01:27:39.493906Z",
     "shell.execute_reply": "2025-11-10T01:27:39.492879Z",
     "shell.execute_reply.started": "2025-11-10T01:27:28.026904Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "os.makedirs('data/', exist_ok=True)\n",
    "!unzip -q /kaggle/working/preprocessed_with_aug.zip -d data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e94609bf-ffd7-4d97-90e5-7da918bd5f75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T01:27:39.495547Z",
     "iopub.status.busy": "2025-11-10T01:27:39.495219Z",
     "iopub.status.idle": "2025-11-10T01:27:39.621954Z",
     "shell.execute_reply": "2025-11-10T01:27:39.620824Z",
     "shell.execute_reply.started": "2025-11-10T01:27:39.495511Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path: /home/minhquana/workspace/project_DeepLearning/computer_vision/Abnormal-Prediction-In-Chest-X-Ray/data/preprocessed_with_aug\n",
      "train: train/images\n",
      "val: valid/images\n",
      "test: test/images\n",
      "nc: 8\n",
      "names:\n",
      "- Aortic enlargement\n",
      "- Cardiomegaly\n",
      "- Lung Opacity\n",
      "- Other lesion\n",
      "- Pleural effusion\n",
      "- Pleural thickening\n",
      "- Pulmonary fibrosis\n",
      "- Normal\n"
     ]
    }
   ],
   "source": [
    "!cat /kaggle/working/data/preprocessed_with_aug/data.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbaf93dd-4a6f-44b6-8163-1dcdbcb14c29",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T01:27:39.623399Z",
     "iopub.status.busy": "2025-11-10T01:27:39.623070Z",
     "iopub.status.idle": "2025-11-10T01:27:41.380081Z",
     "shell.execute_reply": "2025-11-10T01:27:41.379141Z",
     "shell.execute_reply.started": "2025-11-10T01:27:39.623361Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path: /home/minhquana/workspace/project_DeepLearning/computer_vision/Abnormal-Prediction-In-Chest-X-Ray/data/preprocessed_with_aug\n",
      "train: train/images\n",
      "val: valid/images\n",
      "test: test/images\n",
      "nc: 8\n",
      "names:\n",
      "- Ph√¨nh ƒë·ªông m·∫°ch ch·ªß\n",
      "- Tim to\n",
      "- ƒê·ª•c ph·ªïi\n",
      "- T·ªïn th∆∞∆°ng kh√°c\n",
      "- Tr√†n d·ªãch m√†ng ph·ªïi\n",
      "- D√†y m√†ng ph·ªïi\n",
      "- X∆° ph·ªïi\n",
      "- B√¨nh th∆∞·ªùng\n"
     ]
    }
   ],
   "source": [
    "!cat /kaggle/working/data/preprocessed_with_aug/data_vi.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "384b05b3-5459-4a08-8b96-3b6d695ee2dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T01:27:41.381633Z",
     "iopub.status.busy": "2025-11-10T01:27:41.381333Z",
     "iopub.status.idle": "2025-11-10T01:27:43.303906Z",
     "shell.execute_reply": "2025-11-10T01:27:43.303045Z",
     "shell.execute_reply.started": "2025-11-10T01:27:41.381601Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correcting paths in /kaggle/working/data/preprocessed_with_aug/data.yaml\n",
      "‚úì Paths corrected successfully!\n",
      "\n",
      "Content of corrected data.yaml:\n",
      "--------------------------------------------------------------------------------\n",
      "path: /kaggle/working/data/preprocessed_with_aug\n",
      "train: train/images\n",
      "val: valid/images\n",
      "test: test/images\n",
      "nc: 8\n",
      "names:\n",
      "- Aortic enlargement\n",
      "- Cardiomegaly\n",
      "- Lung Opacity\n",
      "- Other lesion\n",
      "- Pleural effusion\n",
      "- Pleural thickening\n",
      "- Pulmonary fibrosis\n",
      "- Normal\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Correct paths in data.yaml\n",
    "data_yaml_path = Path('/kaggle/working/data/preprocessed_with_aug/data.yaml')\n",
    "\n",
    "if data_yaml_path.exists():\n",
    "    print(f\"Correcting paths in {data_yaml_path}\")\n",
    "    with open(data_yaml_path, 'r') as f:\n",
    "        data_yaml_content = f.read()\n",
    "\n",
    "    # Replace the incorrect path with the correct one\n",
    "    corrected_yaml_content = data_yaml_content.replace(\n",
    "        '/home/minhquana/workspace/project_DeepLearning/computer_vision/Abnormal-Prediction-In-Chest-X-Ray/data/preprocessed_with_aug',\n",
    "        '/kaggle/working/data/preprocessed_with_aug'\n",
    "    )\n",
    "\n",
    "    with open(data_yaml_path, 'w') as f:\n",
    "        f.write(corrected_yaml_content)\n",
    "\n",
    "    print(\"‚úì Paths corrected successfully!\")\n",
    "    print(\"\\nContent of corrected data.yaml:\")\n",
    "    print(\"-\" * 80)\n",
    "    print(corrected_yaml_content)\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "else:\n",
    "    print(f\"Error: data.yaml not found at {data_yaml_path}\")\n",
    "    raise FileNotFoundError(f\"data.yaml not found at {data_yaml_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6388d70e-cec2-4255-a037-bf0069dc5d21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T01:27:43.305489Z",
     "iopub.status.busy": "2025-11-10T01:27:43.304953Z",
     "iopub.status.idle": "2025-11-10T01:27:43.319601Z",
     "shell.execute_reply": "2025-11-10T01:27:43.318901Z",
     "shell.execute_reply.started": "2025-11-10T01:27:43.305466Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correcting paths in /kaggle/working/data/preprocessed_with_aug/data_vi.yaml\n",
      "‚úì Paths corrected successfully!\n",
      "\n",
      "Content of corrected data.yaml:\n",
      "--------------------------------------------------------------------------------\n",
      "path: /kaggle/working/data/preprocessed_with_aug\n",
      "train: train/images\n",
      "val: valid/images\n",
      "test: test/images\n",
      "nc: 8\n",
      "names:\n",
      "- Ph√¨nh ƒë·ªông m·∫°ch ch·ªß\n",
      "- Tim to\n",
      "- ƒê·ª•c ph·ªïi\n",
      "- T·ªïn th∆∞∆°ng kh√°c\n",
      "- Tr√†n d·ªãch m√†ng ph·ªïi\n",
      "- D√†y m√†ng ph·ªïi\n",
      "- X∆° ph·ªïi\n",
      "- B√¨nh th∆∞·ªùng\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Correct paths in data.yaml\n",
    "data_yaml_path = Path('/kaggle/working/data/preprocessed_with_aug/data_vi.yaml')\n",
    "\n",
    "if data_yaml_path.exists():\n",
    "    print(f\"Correcting paths in {data_yaml_path}\")\n",
    "    with open(data_yaml_path, 'r') as f:\n",
    "        data_yaml_content = f.read()\n",
    "\n",
    "    # Replace the incorrect path with the correct one\n",
    "    corrected_yaml_content = data_yaml_content.replace(\n",
    "        '/home/minhquana/workspace/project_DeepLearning/computer_vision/Abnormal-Prediction-In-Chest-X-Ray/data/preprocessed_with_aug',\n",
    "        '/kaggle/working/data/preprocessed_with_aug'\n",
    "    )\n",
    "\n",
    "    with open(data_yaml_path, 'w') as f:\n",
    "        f.write(corrected_yaml_content)\n",
    "\n",
    "    print(\"‚úì Paths corrected successfully!\")\n",
    "    print(\"\\nContent of corrected data.yaml:\")\n",
    "    print(\"-\" * 80)\n",
    "    print(corrected_yaml_content)\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "else:\n",
    "    print(f\"Error: data.yaml not found at {data_yaml_path}\")\n",
    "    raise FileNotFoundError(f\"data.yaml not found at {data_yaml_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0b57cdb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T01:27:43.320682Z",
     "iopub.status.busy": "2025-11-10T01:27:43.320427Z",
     "iopub.status.idle": "2025-11-10T01:27:43.389265Z",
     "shell.execute_reply": "2025-11-10T01:27:43.388431Z",
     "shell.execute_reply.started": "2025-11-10T01:27:43.320659Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying Preprocessed Data\n",
      "================================================================================\n",
      "‚úì Preprocessed data directory found: data/preprocessed_with_aug\n",
      "‚úì Data YAML found: data/preprocessed_with_aug/data.yaml\n",
      "\n",
      "Dataset Configuration:\n",
      "  Number of classes: 8\n",
      "  Class names: ['Aortic enlargement', 'Cardiomegaly', 'Lung Opacity', 'Other lesion', 'Pleural effusion', 'Pleural thickening', 'Pulmonary fibrosis', 'Normal']\n",
      "\n",
      "Dataset Statistics:\n",
      "  Train:      10,038 images\n",
      "  Validation: 1,530 images\n",
      "  Test:       745 images\n",
      "  Total:      12,313 images\n",
      "\n",
      "‚úì Data verification complete - ready for training!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Verify preprocessed data directory\n",
    "preprocessed_dir = Path('data/preprocessed_with_aug')\n",
    "data_yaml = preprocessed_dir / 'data.yaml'\n",
    "\n",
    "print(\"Verifying Preprocessed Data\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if not preprocessed_dir.exists():\n",
    "    print(\"ERROR: Preprocessed data not found!\")\n",
    "    print(f\"   Expected location: {preprocessed_dir.absolute()}\")\n",
    "    print(\"\\nPlease run data_preparation.ipynb first to create preprocessed data.\")\n",
    "    raise FileNotFoundError(f\"Preprocessed data not found at {preprocessed_dir}\")\n",
    "\n",
    "if not data_yaml.exists():\n",
    "    print(f\"ERROR: data.yaml not found at {data_yaml}\")\n",
    "    raise FileNotFoundError(f\"data.yaml not found\")\n",
    "\n",
    "print(f\"‚úì Preprocessed data directory found: {preprocessed_dir}\")\n",
    "print(f\"‚úì Data YAML found: {data_yaml}\")\n",
    "\n",
    "# Load data.yaml\n",
    "with open(data_yaml, 'r') as f:\n",
    "    data_config = yaml.safe_load(f)\n",
    "\n",
    "print(f\"\\nDataset Configuration:\")\n",
    "print(f\"  Number of classes: {data_config['nc']}\")\n",
    "print(f\"  Class names: {data_config['names']}\")\n",
    "\n",
    "# Count images in each split\n",
    "splits = ['train', 'valid', 'test']\n",
    "split_counts = {}\n",
    "\n",
    "for split in splits:\n",
    "    images_dir = preprocessed_dir / split / 'images'\n",
    "    if images_dir.exists():\n",
    "        count = len(list(images_dir.glob('*.png'))) + len(list(images_dir.glob('*.jpg')))\n",
    "        split_counts[split] = count\n",
    "    else:\n",
    "        split_counts[split] = 0\n",
    "\n",
    "print(f\"\\nDataset Statistics:\")\n",
    "print(f\"  Train:      {split_counts['train']:,} images\")\n",
    "print(f\"  Validation: {split_counts['valid']:,} images\")\n",
    "print(f\"  Test:       {split_counts['test']:,} images\")\n",
    "print(f\"  Total:      {sum(split_counts.values()):,} images\")\n",
    "\n",
    "if split_counts['train'] == 0:\n",
    "    print(\"\\nERROR: No training images found!\")\n",
    "    raise ValueError(\"No training images found in preprocessed data\")\n",
    "\n",
    "print(\"\\n‚úì Data verification complete - ready for training!\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b049554",
   "metadata": {},
   "source": [
    "### ‚ö†Ô∏è Important Note v·ªÅ Class \"Normal\" (Class 7)\n",
    "\n",
    "Trong validation results, b·∫°n c√≥ th·ªÉ th·∫•y **ch·ªâ c√≥ 7 classes** thay v√¨ 8:\n",
    "- **Nguy√™n nh√¢n**: Class \"Normal\" (class 7) ch·ªâ √°p d·ª•ng cho ·∫£nh **KH√îNG c√≥ bounding box**\n",
    "- **Validation set**: Ch·ª©a 2,545 instances = T·∫§T C·∫¢ l√† abnormalities (c√≥ bounding boxes)\n",
    "- **Training set**: C√≥ c·∫£ Normal images (kh√¥ng c√≥ bbox) v√† abnormality images (c√≥ bbox)\n",
    "\n",
    "**Impact**:\n",
    "- Model v·∫´n train ƒë√∫ng v·ªõi 8 classes\n",
    "- Validation ch·ªâ ƒë√°nh gi√° 7 classes (kh√¥ng c√≥ Normal)\n",
    "- Khi inference ·∫£nh b√¨nh th∆∞·ªùng (no detections) ‚Üí model classify l√† \"Normal\"\n",
    "\n",
    "**Kh√¥ng c·∫ßn lo l·∫Øng** - ƒë√¢y l√† behavior ƒë√∫ng cho object detection v·ªõi negative samples!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887a7279",
   "metadata": {},
   "source": [
    "## Section 3: WandB Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c680bfc-b2e7-47a9-a30f-7bc7fd384f2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T01:27:43.391718Z",
     "iopub.status.busy": "2025-11-10T01:27:43.391442Z",
     "iopub.status.idle": "2025-11-10T01:27:43.485128Z",
     "shell.execute_reply": "2025-11-10T01:27:43.484582Z",
     "shell.execute_reply.started": "2025-11-10T01:27:43.391703Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from kaggle_secrets import UserSecretsClient\n",
    "user_secrets = UserSecretsClient()\n",
    "key = user_secrets.get_secret(\"wandb_api_key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35609f76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T01:27:43.485958Z",
     "iopub.status.busy": "2025-11-10T01:27:43.485764Z",
     "iopub.status.idle": "2025-11-10T01:27:50.666206Z",
     "shell.execute_reply": "2025-11-10T01:27:50.665468Z",
     "shell.execute_reply.started": "2025-11-10T01:27:43.485943Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mminhquana\u001b[0m (\u001b[33mminhquana-university-of-transportation-and-communication\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Logged into Weights & Biases successfully\n"
     ]
    }
   ],
   "source": [
    "# Login to WandB\n",
    "wandb.login(key=key)\n",
    "print(\"‚úì Logged into Weights & Biases successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f969a042",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME=\"yolov11s-gaussian-blur-rotation-AdamW\"\n",
    "PROJECT=\"chest-xray-abnormality-detection\"\n",
    "EPOCH=100\n",
    "BATCH_SIZE=48\n",
    "IMG_SIZE=1024\n",
    "PATIENCE=10\n",
    "OPTIMIZER=\"AdamW\"\n",
    "LR=0.0025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbf1148",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T01:27:50.667390Z",
     "iopub.status.busy": "2025-11-10T01:27:50.666995Z",
     "iopub.status.idle": "2025-11-10T01:27:58.513469Z",
     "shell.execute_reply": "2025-11-10T01:27:58.512499Z",
     "shell.execute_reply.started": "2025-11-10T01:27:50.667372Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20251110_012750-xd3meqvk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/minhquana-university-of-transportation-and-communication/chest-xray-abnormality-detection/runs/xd3meqvk' target=\"_blank\">yolov11s-gaussian-blur-rotation-Adam</a></strong> to <a href='https://wandb.ai/minhquana-university-of-transportation-and-communication/chest-xray-abnormality-detection' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/minhquana-university-of-transportation-and-communication/chest-xray-abnormality-detection' target=\"_blank\">https://wandb.ai/minhquana-university-of-transportation-and-communication/chest-xray-abnormality-detection</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/minhquana-university-of-transportation-and-communication/chest-xray-abnormality-detection/runs/xd3meqvk' target=\"_blank\">https://wandb.ai/minhquana-university-of-transportation-and-communication/chest-xray-abnormality-detection/runs/xd3meqvk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì WandB initialized successfully\n",
      "  Project: chest-xray-abnormality-detection\n",
      "  Run name: yolov11s-gaussian-blur-rotation-Adam\n",
      "  Run URL: https://wandb.ai/minhquana-university-of-transportation-and-communication/chest-xray-abnormality-detection/runs/xd3meqvk\n"
     ]
    }
   ],
   "source": [
    "# Initialize WandB project\n",
    "wandb.init(\n",
    "    project=PROJECT,\n",
    "    name=NAME,\n",
    "    config={\n",
    "        \"model\": \"YOLOv11s\",\n",
    "        \"dataset\": \"VinBigData Chest X-ray v3 (Preprocessed + Filtered)\",\n",
    "        \"epochs\": EPOCH,\n",
    "        \"batch_size\": BATCH_SIZE,\n",
    "        \"image_size\": IMG_SIZE,\n",
    "        \"patience\": PATIENCE,\n",
    "        \"optimizer\": OPTIMIZER,\n",
    "        \"learning_rate\": LR,\n",
    "        \"preprocessing\": \"grayscale + histogram_eq + normalization (NO blur)\",\n",
    "        \"augmentation\": \"gaussian_blur (custom callback) + rotation (YOLO degrees=5.0)\",\n",
    "        \"training_strategy\": \"minimal augmentation to preserve medical features\",\n",
    "        \"gaussian_blur\": \"80% 3x3, 20% 5x5 with sigma=0.5\",\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"‚úì WandB initialized successfully\")\n",
    "print(f\"  Project: chest-xray-abnormality-detection\")\n",
    "print(f\"  Run name: {wandb.run.name}\")\n",
    "print(f\"  Run URL: {wandb.run.url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "933ec05f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T01:27:58.514676Z",
     "iopub.status.busy": "2025-11-10T01:27:58.514432Z",
     "iopub.status.idle": "2025-11-10T01:27:58.521338Z",
     "shell.execute_reply": "2025-11-10T01:27:58.520774Z",
     "shell.execute_reply.started": "2025-11-10T01:27:58.514657Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì WandB integration enabled for Ultralytics YOLO\n",
      "\n",
      "Training metrics will be automatically logged to WandB:\n",
      "   - Loss curves (box_loss, cls_loss, dfl_loss)\n",
      "   - mAP scores (mAP50, mAP50-95)\n",
      "   - Learning rate schedules\n",
      "   - Training/validation images with predictions\n"
     ]
    }
   ],
   "source": [
    "# Enable WandB integration in Ultralytics\n",
    "settings.update({'wandb': True})\n",
    "\n",
    "print(\"‚úì WandB integration enabled for Ultralytics YOLO\")\n",
    "print(\"\\nTraining metrics will be automatically logged to WandB:\")\n",
    "print(\"   - Loss curves (box_loss, cls_loss, dfl_loss)\")\n",
    "print(\"   - mAP scores (mAP50, mAP50-95)\")\n",
    "print(\"   - Learning rate schedules\")\n",
    "print(\"   - Training/validation images with predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16153797",
   "metadata": {},
   "source": [
    "## Section 4: Training Configuration\n",
    "\n",
    "Configure training parameters with minimal augmentation strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45043374",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T01:27:58.522090Z",
     "iopub.status.busy": "2025-11-10T01:27:58.521894Z",
     "iopub.status.idle": "2025-11-10T01:27:59.498654Z",
     "shell.execute_reply": "2025-11-10T01:27:59.497805Z",
     "shell.execute_reply.started": "2025-11-10T01:27:58.522076Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Configuration\n",
      "================================================================================\n",
      "  data                     : data/preprocessed_with_aug/data.yaml\n",
      "  epochs                   : 100\n",
      "  batch                    : 48\n",
      "  imgsz                    : 1024\n",
      "  patience                 : 7\n",
      "  save                     : True\n",
      "  plots                    : True\n",
      "  verbose                  : True\n",
      "  device                   : [-1, -1]\n",
      "  workers                  : 8\n",
      "  cache                    : False\n",
      "  optimizer                : Adam\n",
      "  lr0                      : 0.0025\n",
      "  lrf                      : 0.0001\n",
      "  momentum                 : 0.937\n",
      "  weight_decay             : 0.0005\n",
      "  warmup_epochs            : 3.0\n",
      "  warmup_momentum          : 0.8\n",
      "  warmup_bias_lr           : 0.1\n",
      "  cos_lr                   : True\n",
      "  degrees                  : 5.0\n",
      "  hsv_h                    : 0.0\n",
      "  hsv_s                    : 0.0\n",
      "  hsv_v                    : 0.0\n",
      "  translate                : 0.0\n",
      "  scale                    : 0.0\n",
      "  shear                    : 0.0\n",
      "  perspective              : 0.0\n",
      "  fliplr                   : 0.0\n",
      "  flipud                   : 0.0\n",
      "  mosaic                   : 0.0\n",
      "  mixup                    : 0.0\n",
      "  copy_paste               : 0.0\n",
      "  auto_augment             : None\n",
      "  erasing                  : 0.0\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Training configuration\n",
    "training_config = {\n",
    "    # Data\n",
    "    'data': str(data_yaml),\n",
    "    \n",
    "    # Training hyperparameters\n",
    "    'epochs': EPOCH,\n",
    "    'batch': BATCH_SIZE,\n",
    "    'imgsz': IMG_SIZE,\n",
    "    'patience': PATIENCE,\n",
    "    'save': True,\n",
    "    'plots': True,\n",
    "    'verbose': True,\n",
    "    \n",
    "    # Device and performance\n",
    "    'device': [0, 1],\n",
    "    'workers': 8,\n",
    "    'cache': False,\n",
    "    \n",
    "    # Optimization parameters\n",
    "    'optimizer': OPTIMIZER,\n",
    "    'lr0': LR,\n",
    "    'lrf': 0.0001,          # Final learning rate (lr0 * lrf)\n",
    "    'momentum': 0.937,\n",
    "    'weight_decay': 0.0005,\n",
    "    'warmup_epochs': 3.0,\n",
    "    'warmup_momentum': 0.8,\n",
    "    'warmup_bias_lr': 0.1,\n",
    "    'cos_lr': True,         # Use cosine learning rate scheduler\n",
    "    \n",
    "    # Only rotation is enabled from YOLO built-in augmentations\n",
    "    # 'degrees': 5.0,\n",
    "    # 'hsv_h': 0.0,    \n",
    "    # 'hsv_s': 0.0,  \n",
    "    # 'hsv_v': 0.0,    \n",
    "    # 'translate': 0.0,   \n",
    "    # 'scale': 0.0,    \n",
    "    # 'shear': 0.0,          \n",
    "    # 'perspective': 0.0,  \n",
    "    # 'fliplr': 0.0, \n",
    "    # 'flipud': 0.0,\n",
    "    # 'mosaic': 0.0,\n",
    "    # 'mixup': 0.0,  \n",
    "    # 'copy_paste': 0.0,    \n",
    "    # 'auto_augment': None,  \n",
    "    # 'erasing': 0.0,        \n",
    "    'degrees': 5.0,        # small rotation\n",
    "    'translate': 0.1,      # mild translation\n",
    "    'scale': 0.1,          # slight zoom\n",
    "    'shear': 0.0,\n",
    "    'perspective': 0.0,\n",
    "    'fliplr': 0.5,         # horizontal flip (safe for X-ray)\n",
    "    'flipud': 0.0,         # vertical flip = unsafe (lung orientation changes)\n",
    "    'hsv_h': 0.015,\n",
    "    'hsv_s': 0.4,\n",
    "    'hsv_v': 0.4,\n",
    "    'mosaic': 0.2,         # moderate mosaic helps class balance\n",
    "    'mixup': 0.1,\n",
    "    'copy_paste': 0.0,\n",
    "    'erasing': 0.1,\n",
    "}\n",
    "\n",
    "print(\"Training Configuration\")\n",
    "print(\"=\" * 80)\n",
    "for key, value in training_config.items():\n",
    "    print(f\"  {key:25s}: {value}\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b6d562",
   "metadata": {},
   "source": [
    "## Section 5: Model Training\n",
    "\n",
    "Train YOLOv11s with custom augmentation callback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98236b87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T01:27:59.499754Z",
     "iopub.status.busy": "2025-11-10T01:27:59.499493Z",
     "iopub.status.idle": "2025-11-10T01:28:00.032150Z",
     "shell.execute_reply": "2025-11-10T01:28:00.031451Z",
     "shell.execute_reply.started": "2025-11-10T01:27:59.499735Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading YOLOv11s model...\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11s.pt to 'yolo11s.pt': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 18.4MB 98.0MB/s 0.2s.1s<0.1s\n",
      "‚úì Model loaded successfully\n",
      "  Model architecture: YOLOv11s\n",
      "  Parameters: ~9.5M\n",
      "\n",
      "Starting training...\n",
      "Progress will be tracked in WandB dashboard\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Load YOLOv11s model\n",
    "print(\"\\nLoading YOLOv11s model...\")\n",
    "model = YOLO('yolo11s.pt')\n",
    "\n",
    "print(\"‚úì Model loaded successfully\")\n",
    "print(f\"  Model architecture: YOLOv11s\")\n",
    "print(f\"  Parameters: ~{sum(p.numel() for p in model.model.parameters()) / 1e6:.1f}M\")\n",
    "\n",
    "print(\"\\nStarting training...\")\n",
    "print(\"Progress will be tracked in WandB dashboard\")\n",
    "print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe011fe0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T01:28:00.033119Z",
     "iopub.status.busy": "2025-11-10T01:28:00.032890Z",
     "iopub.status.idle": "2025-11-10T03:43:12.169455Z",
     "shell.execute_reply": "2025-11-10T03:43:12.168160Z",
     "shell.execute_reply.started": "2025-11-10T01:28:00.033102Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for 2 idle GPUs with free memory >= 20.0% and free utilization >= 0.0%...\n",
      "Selected idle CUDA devices [0, 1]\n",
      "Ultralytics 8.3.227 üöÄ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
      "                                                       CUDA:1 (Tesla T4, 15095MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=None, batch=48, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=True, cutmix=0.0, data=data/preprocessed_with_aug/data.yaml, degrees=5.0, deterministic=True, device=0,1, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.0, exist_ok=False, fliplr=0.0, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.0, hsv_s=0.0, hsv_v=0.0, imgsz=1024, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0025, lrf=0.0001, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11s.pt, momentum=0.937, mosaic=0.0, multi_scale=False, name=yolov11s-gaussian-blur-rotation-Adam, nbs=64, nms=False, opset=None, optimize=False, optimizer=Adam, overlap_mask=True, patience=7, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=chest-xray-training, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/chest-xray-training/yolov11s-gaussian-blur-rotation-Adam, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.0, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.0, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 755.1KB 9.0MB/s 0.1s\n",
      "Overriding model.yaml nc=80 with nc=8\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  3                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  4                  -1  1    103360  ultralytics.nn.modules.block.C3k2            [128, 256, 1, False, 0.25]    \n",
      "  5                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      "  6                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.C2PSA           [512, 512, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    443776  ultralytics.nn.modules.block.C3k2            [768, 256, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    127680  ultralytics.nn.modules.block.C3k2            [512, 128, 1, False]          \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    345472  ultralytics.nn.modules.block.C3k2            [384, 256, 1, False]          \n",
      " 20                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1511424  ultralytics.nn.modules.block.C3k2            [768, 512, 1, True]           \n",
      " 23        [16, 19, 22]  1    822504  ultralytics.nn.modules.head.Detect           [8, [128, 256, 512]]          \n",
      "YOLO11s summary: 181 layers, 9,430,888 parameters, 9,430,872 gradients, 21.6 GFLOPs\n",
      "\n",
      "Transferred 493/499 items from pretrained weights\n",
      "\u001b[34m\u001b[1mDDP:\u001b[0m debug command /usr/bin/python3 -m torch.distributed.run --nproc_per_node 2 --master_port 45205 /root/.config/Ultralytics/DDP/_temp_a29kbu4f136204005768976.py\n",
      "Ultralytics 8.3.227 üöÄ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
      "                                                       CUDA:1 (Tesla T4, 15095MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "wandb: Currently logged in as: minhquana (minhquana-university-of-transportation-and-communication) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n",
      "wandb: Tracking run with wandb version 0.21.0\n",
      "wandb: Run data is saved locally in /kaggle/working/wandb/run-20251110_012809-sn8ylyws\n",
      "wandb: Run `wandb offline` to turn off syncing.\n",
      "wandb: Syncing run yolov11s-gaussian-blur-rotation-Adam\n",
      "wandb: ‚≠êÔ∏è View project at https://wandb.ai/minhquana-university-of-transportation-and-communication/chest-xray-training\n",
      "wandb: üöÄ View run at https://wandb.ai/minhquana-university-of-transportation-and-communication/chest-xray-training/runs/sn8ylyws\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding model.yaml nc=80 with nc=8\n",
      "Transferred 493/499 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5.4MB 73.5MB/s 0.1s\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 2039.4¬±678.1 MB/s, size: 90.5 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/data/preprocessed_with_aug/train/labels... 10038 images, 4000 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10038/10038 1.6Kit/s 6.4s<0.0s\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/data/preprocessed_with_aug/train/labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 856.4¬±336.2 MB/s, size: 71.6 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/data/preprocessed_with_aug/valid/labels... 1530 images, 624 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1530/1530 2.4Kit/s 0.6s0.1s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/data/preprocessed_with_aug/valid/labels.cache\n",
      "Plotting labels to /kaggle/working/chest-xray-training/yolov11s-gaussian-blur-rotation-Adam/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.0025, momentum=0.937) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.000375), 87 bias(decay=0.0)\n",
      "Image sizes 1024 train, 1024 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1m/kaggle/working/chest-xray-training/yolov11s-gaussian-blur-rotation-Adam\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      1/100      14.2G       2.13      4.504      2.158          4       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 210/210 1.0it/s 3:20<0.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 1.0it/s 15.3s0.9s\n",
      "                   all       1530       2545     0.0618     0.0828     0.0521     0.0216\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      2/100      14.4G      1.998       2.53      2.058          4       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 210/210 1.0it/s 3:31<0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 1.0it/s 16.4s1.0s\n",
      "                   all       1530       2545      0.547      0.247       0.14     0.0603\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      3/100      14.4G      1.982      2.445       2.03          2       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 210/210 1.0it/s 3:33<0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 1.0it/s 15.3s1.0s\n",
      "                   all       1530       2545       0.31     0.0513     0.0672     0.0282\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      4/100      14.3G      1.959      2.375      2.001         13       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 210/210 1.0it/s 3:33<0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 1.1it/s 15.1s0.9s\n",
      "                   all       1530       2545      0.603     0.0882     0.0937      0.044\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      5/100      14.3G      1.895      2.247      1.948          5       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 210/210 1.0it/s 3:33<0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 1.1it/s 15.2s0.9s\n",
      "                   all       1530       2545      0.876      0.235      0.253      0.121\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      6/100      14.3G      1.859      2.182      1.911          4       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 210/210 1.0it/s 3:33<0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 1.0it/s 15.5s1.0s\n",
      "                   all       1530       2545      0.717      0.106      0.109     0.0491\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      7/100      14.3G      1.862      2.154      1.912          2       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 210/210 1.0it/s 3:32<0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 1.1it/s 15.2s0.9s\n",
      "                   all       1530       2545      0.163      0.148      0.122     0.0484\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      8/100      14.4G      1.821       2.09      1.875         11       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 210/210 1.0it/s 3:32<0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 1.0it/s 15.4s0.9s\n",
      "                   all       1530       2545      0.584      0.211      0.224      0.105\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      9/100      14.3G      1.804      2.039      1.858          5       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 210/210 1.0it/s 3:32<0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 1.0it/s 15.4s1.0s\n",
      "                   all       1530       2545      0.847       0.22      0.252      0.118\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     10/100      14.2G      1.791      2.007      1.853          5       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 210/210 1.0it/s 3:33<0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 1.0it/s 15.6s1.0s\n",
      "                   all       1530       2545      0.391      0.296      0.281       0.13\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     11/100      14.3G      1.753      2.012      1.822          0       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 210/210 1.0it/s 3:33<0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 1.0it/s 15.3s1.0s\n",
      "                   all       1530       2545      0.417      0.258      0.274      0.129\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     12/100      14.2G      1.739      1.968      1.811          0       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 210/210 1.0it/s 3:33<0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 1.0it/s 15.3s1.0s\n",
      "                   all       1530       2545      0.365       0.24      0.243      0.109\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     13/100      14.3G      1.733      1.928      1.804          5       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 210/210 1.0it/s 3:33<0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 1.0it/s 15.3s0.9s\n",
      "                   all       1530       2545      0.842       0.26       0.28      0.135\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     14/100      14.3G      1.705      1.875      1.785          5       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 210/210 1.0it/s 3:34<0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 1.0it/s 15.5s1.0s\n",
      "                   all       1530       2545      0.278      0.277       0.26      0.126\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     15/100      14.3G      1.697      1.845      1.776          8       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 210/210 1.0it/s 3:34<0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 1.1it/s 15.1s1.0s\n",
      "                   all       1530       2545      0.374      0.288      0.268       0.12\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     16/100      14.3G      1.665      1.792      1.757          2       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 210/210 1.0it/s 3:34<0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 1.1it/s 15.2s1.0s\n",
      "                   all       1530       2545      0.282      0.287       0.27      0.129\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     17/100      14.3G      1.634      1.751      1.729          7       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 210/210 1.0it/s 3:34<0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 1.1it/s 15.2s0.9s\n",
      "                   all       1530       2545      0.279      0.278      0.266      0.123\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     18/100      14.3G      1.625      1.702      1.716          8       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 210/210 1.0it/s 3:33<0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 1.0it/s 15.3s0.9s\n",
      "                   all       1530       2545       0.29      0.321      0.288      0.139\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     19/100      14.3G      1.605      1.673      1.702          7       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 210/210 1.0it/s 3:34<0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 1.0it/s 15.3s0.9s\n",
      "                   all       1530       2545      0.287      0.297      0.273      0.127\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     20/100      14.3G       1.58      1.645      1.688          5       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 210/210 1.0it/s 3:35<0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 1.1it/s 15.1s0.9s\n",
      "                   all       1530       2545      0.255      0.326      0.286      0.133\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     21/100      14.3G      1.552      1.574      1.661          4       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 210/210 1.0it/s 3:35<0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 1.1it/s 15.0s0.9s\n",
      "                   all       1530       2545      0.284      0.329      0.293      0.134\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     22/100      14.4G       1.51      1.509      1.634          6       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 210/210 1.0it/s 3:34<0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 1.0it/s 15.3s0.9s\n",
      "                   all       1530       2545      0.269      0.352        0.3       0.14\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     23/100      14.3G      1.492       1.47      1.612         10       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 210/210 1.0it/s 3:34<0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 1.1it/s 15.0s0.9s\n",
      "                   all       1530       2545      0.269      0.328       0.29      0.134\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     24/100      14.3G      1.458      1.396      1.585          6       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 210/210 1.0it/s 3:34<0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 1.1it/s 15.0s0.9s\n",
      "                   all       1530       2545      0.292      0.353        0.3      0.142\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     25/100      14.3G       1.44      1.368      1.579         11       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 210/210 1.0it/s 3:34<0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 1.1it/s 15.1s0.9s\n",
      "                   all       1530       2545      0.291       0.34      0.294      0.137\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     26/100      14.3G      1.381      1.315      1.532          5       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 210/210 1.0it/s 3:34<0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 1.1it/s 15.1s1.0s\n",
      "                   all       1530       2545      0.302      0.335      0.299      0.138\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     27/100      14.3G      1.346       1.24      1.505          7       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 210/210 1.0it/s 3:34<0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 1.1it/s 15.2s0.9s\n",
      "                   all       1530       2545      0.301      0.341      0.296      0.138\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     28/100      14.3G      1.318       1.19      1.486          7       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 210/210 1.0it/s 3:34<0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 1.1it/s 15.2s0.9s\n",
      "                   all       1530       2545      0.301      0.363      0.304      0.144\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     29/100      14.3G      1.292      1.149      1.461          3       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 210/210 1.0it/s 3:34<0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 1.1it/s 15.2s1.0s\n",
      "                   all       1530       2545      0.281      0.358        0.3      0.141\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     30/100      14.3G      1.258      1.104      1.435          4       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 210/210 1.0it/s 3:35<0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 1.1it/s 15.0s0.9s\n",
      "                   all       1530       2545      0.293      0.348      0.297       0.14\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     31/100      14.3G       1.22      1.047      1.409         12       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 210/210 1.0it/s 3:35<0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 1.0it/s 15.4s1.0s\n",
      "                   all       1530       2545      0.296      0.338      0.292      0.134\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     32/100      14.3G      1.195      1.024      1.395         11       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 210/210 1.0it/s 3:35<0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 1.0it/s 15.3s0.9s\n",
      "                   all       1530       2545      0.298      0.335      0.301      0.139\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     33/100      14.3G      1.174     0.9869      1.373          4       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 210/210 1.0it/s 3:35<0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 1.1it/s 15.1s0.9s\n",
      "                   all       1530       2545      0.318      0.341      0.297      0.138\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     34/100      14.3G      1.133     0.9355      1.344          6       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 210/210 1.0it/s 3:35<0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 1.0it/s 15.3s1.0s\n",
      "                   all       1530       2545      0.305      0.348      0.299      0.136\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     35/100      14.3G      1.113     0.9164      1.337          3       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 210/210 1.0it/s 3:35<0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 1.1it/s 15.0s1.0s\n",
      "                   all       1530       2545      0.298      0.366      0.297      0.138\n",
      "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 7 epochs. Best results observed at epoch 28, best model saved as best.pt.\n",
      "To update EarlyStopping(patience=7) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n",
      "\n",
      "35 epochs completed in 2.234 hours.\n",
      "Optimizer stripped from /kaggle/working/chest-xray-training/yolov11s-gaussian-blur-rotation-Adam/weights/last.pt, 19.3MB\n",
      "Optimizer stripped from /kaggle/working/chest-xray-training/yolov11s-gaussian-blur-rotation-Adam/weights/best.pt, 19.3MB\n",
      "\n",
      "Validating /kaggle/working/chest-xray-training/yolov11s-gaussian-blur-rotation-Adam/weights/best.pt...\n",
      "YOLO11s summary (fused): 100 layers, 9,415,896 parameters, 0 gradients, 21.3 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 0.8it/s 19.2s0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1530       2545      0.296      0.368      0.304      0.144\n",
      "    Aortic enlargement        632        632      0.668      0.897      0.838       0.41\n",
      "          Cardiomegaly        492        492      0.695      0.951      0.923      0.493\n",
      "          Lung Opacity        276        276      0.195      0.109     0.0704     0.0228\n",
      "          Other lesion        220        220     0.0882     0.0273      0.011    0.00292\n",
      "      Pleural effusion        209        209      0.168      0.435      0.186     0.0537\n",
      "    Pleural thickening        397        397       0.12     0.0907     0.0524     0.0129\n",
      "    Pulmonary fibrosis        319        319      0.139     0.0658     0.0466     0.0134\n",
      "Speed: 0.4ms preprocess, 7.3ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Results saved to \u001b[1m/kaggle/working/chest-xray-training/yolov11s-gaussian-blur-rotation-Adam\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb:                                                                                \n",
      "wandb: \n",
      "wandb: Run history:\n",
      "wandb:                  lr/pg0 ‚ñà‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
      "wandb:                  lr/pg1 ‚ñÅ‚ñÖ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ\n",
      "wandb:                  lr/pg2 ‚ñÅ‚ñÖ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ\n",
      "wandb:        metrics/mAP50(B) ‚ñÅ‚ñÉ‚ñÅ‚ñÇ‚ñá‚ñÉ‚ñÉ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "wandb:     metrics/mAP50-95(B) ‚ñÅ‚ñÉ‚ñÅ‚ñÇ‚ñá‚ñÉ‚ñÉ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà\n",
      "wandb:    metrics/precision(B) ‚ñÅ‚ñÖ‚ñÉ‚ñÜ‚ñà‚ñá‚ñÇ‚ñÖ‚ñà‚ñÑ‚ñÑ‚ñÑ‚ñà‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ\n",
      "wandb:       metrics/recall(B) ‚ñÇ‚ñÖ‚ñÅ‚ñÇ‚ñÖ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà\n",
      "wandb:            model/GFLOPs ‚ñÅ\n",
      "wandb:        model/parameters ‚ñÅ\n",
      "wandb: model/speed_PyTorch(ms) ‚ñÅ\n",
      "wandb:          train/box_loss ‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ\n",
      "wandb:          train/cls_loss ‚ñà‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
      "wandb:          train/dfl_loss ‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
      "wandb:            val/box_loss ‚ñà‚ñÉ‚ñÜ‚ñÑ‚ñÅ‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ\n",
      "wandb:            val/cls_loss ‚ñÑ‚ñà‚ñÉ‚ñÉ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
      "wandb:            val/dfl_loss ‚ñà‚ñÇ‚ñÑ‚ñÉ‚ñÅ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ\n",
      "wandb: \n",
      "wandb: Run summary:\n",
      "wandb:                  lr/pg0 0.00185\n",
      "wandb:                  lr/pg1 0.00185\n",
      "wandb:                  lr/pg2 0.00185\n",
      "wandb:        metrics/mAP50(B) 0.29734\n",
      "wandb:     metrics/mAP50-95(B) 0.13844\n",
      "wandb:    metrics/precision(B) 0.29815\n",
      "wandb:       metrics/recall(B) 0.36566\n",
      "wandb:            model/GFLOPs 21.564\n",
      "wandb:        model/parameters 9430888\n",
      "wandb: model/speed_PyTorch(ms) 7.157\n",
      "wandb:          train/box_loss 1.11263\n",
      "wandb:          train/cls_loss 0.91642\n",
      "wandb:          train/dfl_loss 1.33738\n",
      "wandb:            val/box_loss 2.15807\n",
      "wandb:            val/cls_loss 1.94552\n",
      "wandb:            val/dfl_loss 2.32216\n",
      "wandb: \n",
      "wandb: üöÄ View run yolov11s-gaussian-blur-rotation-Adam at: https://wandb.ai/minhquana-university-of-transportation-and-communication/chest-xray-training/runs/sn8ylyws\n",
      "wandb: ‚≠êÔ∏è View project at: https://wandb.ai/minhquana-university-of-transportation-and-communication/chest-xray-training\n",
      "wandb: Synced 5 W&B file(s), 21 media file(s), 10 artifact file(s) and 0 other file(s)\n",
      "wandb: Find logs at: ./wandb/run-20251110_012809-sn8ylyws/logs\n",
      "wandb: WARNING Tried to log to step 35 that is less than the current step 36. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "wandb: WARNING Tried to log to step 35 that is less than the current step 36. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "wandb: WARNING Tried to log to step 35 that is less than the current step 36. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "wandb: WARNING Tried to log to step 35 that is less than the current step 36. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "wandb: WARNING Tried to log to step 35 that is less than the current step 36. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "wandb: WARNING Tried to log to step 35 that is less than the current step 36. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "wandb: WARNING Tried to log to step 35 that is less than the current step 36. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "wandb: WARNING Tried to log to step 35 that is less than the current step 36. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "wandb: WARNING Tried to log to step 35 that is less than the current step 36. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "wandb: WARNING Tried to log to step 35 that is less than the current step 36. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "wandb: WARNING Tried to log to step 35 that is less than the current step 36. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "wandb: WARNING Tried to log to step 35 that is less than the current step 36. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "wandb: WARNING Tried to log to step 35 that is less than the current step 36. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n",
      "wandb: WARNING Tried to log to step 35 that is less than the current step 36. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "‚úì Training completed successfully!\n",
      "================================================================================\n",
      "\n",
      "Training Results:\n",
      "\n",
      "Training failed: 'NoneType' object has no attribute 'save_dir'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_48/3641916676.py\", line 20, in <cell line: 0>\n",
      "    best_model_path = Path(results.save_dir) / 'weights' / 'best.pt'\n",
      "                           ^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'NoneType' object has no attribute 'save_dir'\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'save_dir'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_48/3641916676.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# Save best model path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mbest_model_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_dir\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m'weights'\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m'best.pt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nBest model saved to: {best_model_path}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'save_dir'"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "try:\n",
    "    results = model.train(\n",
    "        **training_config,\n",
    "        project='chest-xray-training',\n",
    "        name='yolov11s-gaussian-blur-rotation-Adam'\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"‚úì Training completed successfully!\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Check if results is valid\n",
    "    if results is None:\n",
    "        print(\"\\n‚ö†Ô∏è WARNING: Training returned None - checking training directory...\")\n",
    "        # Find the latest training directory\n",
    "        training_dir = Path('chest-xray-training')\n",
    "        if training_dir.exists():\n",
    "            # Get all run directories sorted by modification time\n",
    "            run_dirs = sorted(training_dir.glob('yolov11s-gaussian-blur-rotation-Adam*'), \n",
    "                            key=lambda x: x.stat().st_mtime, reverse=True)\n",
    "            if run_dirs:\n",
    "                latest_run = run_dirs[0]\n",
    "                print(f\"  Found latest training run: {latest_run}\")\n",
    "                best_model_path = latest_run / 'weights' / 'best.pt'\n",
    "                last_model_path = latest_run / 'weights' / 'last.pt'\n",
    "                \n",
    "                if best_model_path.exists():\n",
    "                    print(f\"  ‚úì Best model found: {best_model_path}\")\n",
    "                elif last_model_path.exists():\n",
    "                    print(f\"  ‚úì Last model found: {last_model_path}\")\n",
    "                    best_model_path = last_model_path\n",
    "                else:\n",
    "                    print(f\"  ‚ùå No model weights found in {latest_run}\")\n",
    "                    best_model_path = None\n",
    "            else:\n",
    "                print(\"  ‚ùå No training runs found\")\n",
    "                best_model_path = None\n",
    "        else:\n",
    "            print(\"  ‚ùå Training directory not found\")\n",
    "            best_model_path = None\n",
    "    else:\n",
    "        # Display results\n",
    "        print(\"\\nTraining Results:\")\n",
    "        if hasattr(results, 'results_dict'):\n",
    "            print(f\"  Best mAP50: {results.results_dict.get('metrics/mAP50(B)', 'N/A')}\")\n",
    "            print(f\"  Best mAP50-95: {results.results_dict.get('metrics/mAP50-95(B)', 'N/A')}\")\n",
    "        \n",
    "        # Save best model path\n",
    "        if hasattr(results, 'save_dir') and results.save_dir:\n",
    "            best_model_path = Path(results.save_dir) / 'weights' / 'best.pt'\n",
    "            print(f\"\\nBest model saved to: {best_model_path}\")\n",
    "        else:\n",
    "            print(\"\\n‚ö†Ô∏è WARNING: results.save_dir not available\")\n",
    "            best_model_path = None\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Training failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    best_model_path = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efecaef4-86fa-4d64-a481-4b10acd3d533",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dir(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9e4f32",
   "metadata": {},
   "source": [
    "## Section 6: Model Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d595a0",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-11-10T03:43:12.169968Z",
     "iopub.status.idle": "2025-11-10T03:43:12.170221Z",
     "shell.execute_reply": "2025-11-10T03:43:12.170123Z",
     "shell.execute_reply.started": "2025-11-10T03:43:12.170112Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Validate on test set\n",
    "print(\"Model Validation on Test Set\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Load best model\n",
    "if 'best_model_path' in locals() and best_model_path.exists():\n",
    "    print(f\"Loading best model: {best_model_path}\")\n",
    "    model = YOLO(str(best_model_path))\n",
    "else:\n",
    "    print(\"Using last trained model\")\n",
    "\n",
    "print(\"\\nRunning validation...\")\n",
    "metrics = model.val(data=str(data_yaml), split='test')\n",
    "\n",
    "print(\"\\nValidation Results:\")\n",
    "print(\"=\" * 80)\n",
    "results_dict = metrics.results_dict\n",
    "print(f\"  mAP50:       {results_dict.get('metrics/mAP50(B)', 0):.4f}\")\n",
    "print(f\"  mAP50-95:    {results_dict.get('metrics/mAP50-95(B)', 0):.4f}\")\n",
    "print(f\"  Precision:   {results_dict.get('metrics/precision(B)', 0):.4f}\")\n",
    "print(f\"  Recall:      {results_dict.get('metrics/recall(B)', 0):.4f}\")\n",
    "print(\"=\" * 80) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b03bfe",
   "metadata": {},
   "source": [
    "## Section 7: Model Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602ff5d0",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-11-10T03:43:12.171301Z",
     "iopub.status.idle": "2025-11-10T03:43:12.171544Z",
     "shell.execute_reply": "2025-11-10T03:43:12.171440Z",
     "shell.execute_reply.started": "2025-11-10T03:43:12.171427Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Export to backend\n",
    "backend_models_dir = Path('backend/models')\n",
    "backend_models_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "target_model_path = backend_models_dir / 'yolov11s_finetuned.pt'\n",
    "\n",
    "print(\"Exporting Model to Backend\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Check if best_model_path exists\n",
    "if 'best_model_path' not in locals() or best_model_path is None:\n",
    "    print(\"‚ö†Ô∏è WARNING: best_model_path not found from training\")\n",
    "    print(\"   Searching for latest trained model...\")\n",
    "    \n",
    "    # Try to find the latest model\n",
    "    training_dir = Path('chest-xray-training')\n",
    "    if training_dir.exists():\n",
    "        run_dirs = sorted(training_dir.glob('yolov11s-gaussian-blur-rotation-Adam*'), \n",
    "                        key=lambda x: x.stat().st_mtime, reverse=True)\n",
    "        if run_dirs:\n",
    "            latest_run = run_dirs[0]\n",
    "            best_model_path = latest_run / 'weights' / 'best.pt'\n",
    "            if not best_model_path.exists():\n",
    "                best_model_path = latest_run / 'weights' / 'last.pt'\n",
    "            \n",
    "            if best_model_path.exists():\n",
    "                print(f\"   ‚úì Found model: {best_model_path}\")\n",
    "            else:\n",
    "                print(f\"   ‚ùå No model weights found\")\n",
    "                best_model_path = None\n",
    "        else:\n",
    "            print(\"   ‚ùå No training runs found\")\n",
    "            best_model_path = None\n",
    "    else:\n",
    "        print(\"   ‚ùå Training directory not found\")\n",
    "        best_model_path = None\n",
    "\n",
    "if best_model_path and best_model_path.exists():\n",
    "    print(f\"Source: {best_model_path}\")\n",
    "    print(f\"Target: {target_model_path}\")\n",
    "    \n",
    "    shutil.copy(best_model_path, target_model_path)\n",
    "    \n",
    "    if target_model_path.exists():\n",
    "        size_mb = target_model_path.stat().st_size / (1024*1024)\n",
    "        print(f\"\\n‚úì Model exported successfully!\")\n",
    "        print(f\"  File size: {size_mb:.2f} MB\")\n",
    "        print(f\"  Location: {target_model_path}\")\n",
    "        print(f\"\\nModel ready for production use!\")\n",
    "    else:\n",
    "        print(\"‚ùå Export failed\")\n",
    "else:\n",
    "    print(\"‚ùå Cannot export - model not found\")\n",
    "    print(\"\\nPlease check:\")\n",
    "    print(\"  1. Training completed successfully\")\n",
    "    print(\"  2. Model weights exist in training directory\")\n",
    "    print(\"  3. No errors during training\")\n",
    "\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afe21dd",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-11-10T03:43:12.172641Z",
     "iopub.status.idle": "2025-11-10T03:43:12.172875Z",
     "shell.execute_reply": "2025-11-10T03:43:12.172770Z",
     "shell.execute_reply.started": "2025-11-10T03:43:12.172758Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Close WandB run\n",
    "wandb.finish()\n",
    "print(\"‚úì WandB run finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7efa34",
   "metadata": {},
   "source": [
    "## Section 8: Training Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a08fb9",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-11-10T03:43:12.173914Z",
     "iopub.status.idle": "2025-11-10T03:43:12.174307Z",
     "shell.execute_reply": "2025-11-10T03:43:12.174127Z",
     "shell.execute_reply.started": "2025-11-10T03:43:12.174092Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"\\nTRAINING SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nCompleted Tasks:\")\n",
    "print(\"  1. ‚úì Loaded preprocessed data from data/preprocessed/\")\n",
    "print(\"  2. ‚úì Applied custom Gaussian blur augmentation during training\")\n",
    "print(\"  3. ‚úì Applied YOLO rotation augmentation (¬±5¬∞)\")\n",
    "print(\"  4. ‚úì Trained YOLOv11s model for 100 epochs with early stopping\")\n",
    "print(\"  5. ‚úì Tracked training with WandB\")\n",
    "print(\"  6. ‚úì Validated on test set\")\n",
    "print(\"  7. ‚úì Exported best model to backend/models/\")\n",
    "\n",
    "print(\"\\nFinal Metrics:\")\n",
    "if 'results_dict' in locals():\n",
    "    print(f\"  mAP50:       {results_dict.get('metrics/mAP50(B)', 'N/A')}\")\n",
    "    print(f\"  mAP50-95:    {results_dict.get('metrics/mAP50-95(B)', 'N/A')}\")\n",
    "    print(f\"  Precision:   {results_dict.get('metrics/precision(B)', 'N/A')}\")\n",
    "    print(f\"  Recall:      {results_dict.get('metrics/recall(B)', 'N/A')}\")\n",
    "\n",
    "print(\"\\nNext Steps:\")\n",
    "print(\"  1. Run compare_baseline_finetuned.ipynb to compare with baseline\")\n",
    "print(\"  2. Check WandB dashboard for detailed training metrics\")\n",
    "print(\"  3. Test model in production via backend API\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
