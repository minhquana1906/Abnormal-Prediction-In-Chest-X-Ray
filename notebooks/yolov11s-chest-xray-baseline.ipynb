{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"41d1afce","cell_type":"markdown","source":"# YOLOv11s Fine-tuning for Chest X-ray Abnormality Detection\n","metadata":{}},{"id":"38d7bbfc","cell_type":"markdown","source":"## Section 1: Setup and Imports","metadata":{}},{"id":"74c92a5c","cell_type":"code","source":"!uv pip install -q roboflow ultralytics wandb tqdm pillow numpy ","metadata":{"execution":{"iopub.status.busy":"2025-11-12T11:43:01.077790Z","iopub.execute_input":"2025-11-12T11:43:01.078553Z","iopub.status.idle":"2025-11-12T11:43:21.735095Z","shell.execute_reply.started":"2025-11-12T11:43:01.078515Z","shell.execute_reply":"2025-11-12T11:43:21.734034Z"},"trusted":true},"outputs":[],"execution_count":1},{"id":"241ec81f-81de-4986-8ba4-b65445f68097","cell_type":"code","source":"!uv pip install --force-reinstall nvidia-cudnn-cu12==9.1.0.70","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T11:43:21.736674Z","iopub.execute_input":"2025-11-12T11:43:21.736927Z","iopub.status.idle":"2025-11-12T11:43:27.544625Z","shell.execute_reply.started":"2025-11-12T11:43:21.736902Z","shell.execute_reply":"2025-11-12T11:43:27.543932Z"}},"outputs":[{"name":"stdout","text":"\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n\u001b[2K\u001b[2mResolved \u001b[1m2 packages\u001b[0m \u001b[2min 103ms\u001b[0m\u001b[0m                                         \u001b[0m\n\u001b[2K\u001b[2mPrepared \u001b[1m2 packages\u001b[0m \u001b[2min 5.46s\u001b[0m\u001b[0m                                             \n\u001b[2mUninstalled \u001b[1m2 packages\u001b[0m \u001b[2min 2ms\u001b[0m\u001b[0m\n\u001b[2K\u001b[2mInstalled \u001b[1m2 packages\u001b[0m \u001b[2min 3ms\u001b[0m\u001b[0m.1.0.70                          \u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-cublas-cu12\u001b[0m\u001b[2m==12.4.5.8\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cublas-cu12\u001b[0m\u001b[2m==12.9.1.4\u001b[0m\n \u001b[33m~\u001b[39m \u001b[1mnvidia-cudnn-cu12\u001b[0m\u001b[2m==9.1.0.70\u001b[0m\n","output_type":"stream"}],"execution_count":2},{"id":"a5bf9ba0-182d-4763-b289-61bc33d0670b","cell_type":"code","source":"!uv pip uninstall albumentations","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T11:43:27.545509Z","iopub.execute_input":"2025-11-12T11:43:27.545722Z","iopub.status.idle":"2025-11-12T11:43:27.794114Z","shell.execute_reply.started":"2025-11-12T11:43:27.545693Z","shell.execute_reply":"2025-11-12T11:43:27.793326Z"}},"outputs":[{"name":"stdout","text":"\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n\u001b[2mUninstalled \u001b[1m1 package\u001b[0m \u001b[2min 121ms\u001b[0m\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1malbumentations\u001b[0m\u001b[2m==2.0.8\u001b[0m\n","output_type":"stream"}],"execution_count":3},{"id":"644a5e3b","cell_type":"code","source":"import os\nos.environ[\"ALBUMENTATIONS_DISABLE\"] = \"1\"\n# Import required libraries\nimport shutil\nfrom pathlib import Path\nimport yaml\n\nimport torch\nimport wandb\nfrom ultralytics import YOLO, settings\n\n# Import custom augmentation\nimport sys\nsys.path.insert(0, str(Path.cwd()))\n\nprint(\"‚úì Imports successful\")\nprint(f\"  PyTorch version: {torch.__version__}\")\nprint(f\"  CUDA available: {torch.cuda.is_available()}\")\nif torch.cuda.is_available():\n    print(f\"  GPU: {torch.cuda.get_device_name(0)}\")\n    print(f\"  GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T11:43:27.796005Z","iopub.execute_input":"2025-11-12T11:43:27.796210Z","iopub.status.idle":"2025-11-12T11:43:34.172753Z","shell.execute_reply.started":"2025-11-12T11:43:27.796188Z","shell.execute_reply":"2025-11-12T11:43:34.171706Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Creating new Ultralytics Settings v0.0.6 file ‚úÖ \nView Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\nUpdate Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n‚úì Imports successful\n  PyTorch version: 2.6.0+cu124\n  CUDA available: True\n  GPU: Tesla T4\n  GPU Memory: 15.8 GB\n","output_type":"stream"}],"execution_count":4},{"id":"062737cc","cell_type":"markdown","source":"## Section 2: Verify Preprocessed Data","metadata":{}},{"id":"b568c272-26ba-4326-bd68-70427bc707de","cell_type":"code","source":"import gdown\ngdown.download(quiet=True, id=\"12n6LBj8AEcs3Oy9V0vFOv1-aD7EMCEN6\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T11:43:34.173680Z","iopub.execute_input":"2025-11-12T11:43:34.173996Z","iopub.status.idle":"2025-11-12T11:43:39.406333Z","shell.execute_reply.started":"2025-11-12T11:43:34.173965Z","shell.execute_reply":"2025-11-12T11:43:39.405731Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"'baseline_2classes.zip'"},"metadata":{}}],"execution_count":5},{"id":"06a1e38e-17db-48da-b565-096355c35d0e","cell_type":"code","source":"os.makedirs('data/', exist_ok=True)\n!unzip -q /kaggle/working/baseline_2classes.zip -d data/","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T11:43:39.407167Z","iopub.execute_input":"2025-11-12T11:43:39.407641Z","iopub.status.idle":"2025-11-12T11:43:42.226662Z","shell.execute_reply.started":"2025-11-12T11:43:39.407616Z","shell.execute_reply":"2025-11-12T11:43:42.225615Z"}},"outputs":[],"execution_count":6},{"id":"e94609bf-ffd7-4d97-90e5-7da918bd5f75","cell_type":"code","source":"!cat /kaggle/working/data/baseline_2classes/data.yaml","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T11:43:42.227761Z","iopub.execute_input":"2025-11-12T11:43:42.227990Z","iopub.status.idle":"2025-11-12T11:43:42.356336Z","shell.execute_reply.started":"2025-11-12T11:43:42.227967Z","shell.execute_reply":"2025-11-12T11:43:42.355635Z"}},"outputs":[{"name":"stdout","text":"path: /home/minhquana/workspace/project_DeepLearning/computer_vision/Abnormal-Prediction-In-Chest-X-Ray/data/baseline_2classes\ntrain: train/images\nval: valid/images\ntest: test/images\nnc: 2\nnames:\n- Aortic enlargement\n- Cardiomegaly\n","output_type":"stream"}],"execution_count":7},{"id":"384b05b3-5459-4a08-8b96-3b6d695ee2dd","cell_type":"code","source":"# Correct paths in data.yaml\ndata_yaml_path = Path('/kaggle/working/data/baseline_2classes/data.yaml')\n\nif data_yaml_path.exists():\n    print(f\"Correcting paths in {data_yaml_path}\")\n    with open(data_yaml_path, 'r') as f:\n        data_yaml_content = f.read()\n\n    # Replace the incorrect path with the correct one\n    corrected_yaml_content = data_yaml_content.replace(\n        \"/home/minhquana/workspace/project_DeepLearning/computer_vision/Abnormal-Prediction-In-Chest-X-Ray/data/baseline_2classes\",\n        \"/kaggle/working/data/baseline_2classes\"\n    )\n\n    with open(data_yaml_path, 'w') as f:\n        f.write(corrected_yaml_content)\n\n    print(\"‚úì Paths corrected successfully!\")\n    print(\"\\nContent of corrected data.yaml:\")\n    print(\"-\" * 80)\n    print(corrected_yaml_content)\n    print(\"-\" * 80)\n\nelse:\n    print(f\"Error: data.yaml not found at {data_yaml_path}\")\n    raise FileNotFoundError(f\"data.yaml not found at {data_yaml_path}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T11:43:42.357423Z","iopub.execute_input":"2025-11-12T11:43:42.357661Z","iopub.status.idle":"2025-11-12T11:43:42.365630Z","shell.execute_reply.started":"2025-11-12T11:43:42.357638Z","shell.execute_reply":"2025-11-12T11:43:42.364916Z"}},"outputs":[{"name":"stdout","text":"Correcting paths in /kaggle/working/data/baseline_2classes/data.yaml\n‚úì Paths corrected successfully!\n\nContent of corrected data.yaml:\n--------------------------------------------------------------------------------\npath: /kaggle/working/data/baseline_2classes\ntrain: train/images\nval: valid/images\ntest: test/images\nnc: 2\nnames:\n- Aortic enlargement\n- Cardiomegaly\n\n--------------------------------------------------------------------------------\n","output_type":"stream"}],"execution_count":8},{"id":"c0b57cdb","cell_type":"code","source":"# Verify preprocessed data directory\npreprocessed_dir = Path('data/baseline_2classes')\ndata_yaml = preprocessed_dir / 'data.yaml'\n\nprint(\"Verifying Preprocessed Data\")\nprint(\"=\" * 80)\n\nif not preprocessed_dir.exists():\n    print(\"ERROR: Preprocessed data not found!\")\n    print(f\"   Expected location: {preprocessed_dir.absolute()}\")\n    print(\"\\nPlease run data_preparation.ipynb first to create preprocessed data.\")\n    raise FileNotFoundError(f\"Preprocessed data not found at {preprocessed_dir}\")\n\nif not data_yaml.exists():\n    print(f\"ERROR: data.yaml not found at {data_yaml}\")\n    raise FileNotFoundError(f\"data.yaml not found\")\n\nprint(f\"‚úì Preprocessed data directory found: {preprocessed_dir}\")\nprint(f\"‚úì Data YAML found: {data_yaml}\")\n\n# Load data.yaml\nwith open(data_yaml, 'r') as f:\n    data_config = yaml.safe_load(f)\n\nprint(f\"\\nDataset Configuration:\")\nprint(f\"  Number of classes: {data_config['nc']}\")\nprint(f\"  Class names: {data_config['names']}\")\n\n# Count images in each split\nsplits = ['train', 'valid', 'test']\nsplit_counts = {}\n\nfor split in splits:\n    images_dir = preprocessed_dir / split / 'images'\n    if images_dir.exists():\n        count = len(list(images_dir.glob('*.png'))) + len(list(images_dir.glob('*.jpg')))\n        split_counts[split] = count\n    else:\n        split_counts[split] = 0\n\nprint(f\"\\nDataset Statistics:\")\nprint(f\"  Train:      {split_counts['train']:,} images\")\nprint(f\"  Validation: {split_counts['valid']:,} images\")\nprint(f\"  Test:       {split_counts['test']:,} images\")\nprint(f\"  Total:      {sum(split_counts.values()):,} images\")\n\nif split_counts['train'] == 0:\n    print(\"\\nERROR: No training images found!\")\n    raise ValueError(\"No training images found in preprocessed data\")\n\nprint(\"\\n‚úì Data verification complete - ready for training!\")\nprint(\"=\" * 80)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T11:43:42.366239Z","iopub.execute_input":"2025-11-12T11:43:42.366404Z","iopub.status.idle":"2025-11-12T11:43:42.392996Z","shell.execute_reply.started":"2025-11-12T11:43:42.366391Z","shell.execute_reply":"2025-11-12T11:43:42.392349Z"}},"outputs":[{"name":"stdout","text":"Verifying Preprocessed Data\n================================================================================\n‚úì Preprocessed data directory found: data/baseline_2classes\n‚úì Data YAML found: data/baseline_2classes/data.yaml\n\nDataset Configuration:\n  Number of classes: 2\n  Class names: ['Aortic enlargement', 'Cardiomegaly']\n\nDataset Statistics:\n  Train:      2,362 images\n  Validation: 704 images\n  Test:       328 images\n  Total:      3,394 images\n\n‚úì Data verification complete - ready for training!\n================================================================================\n","output_type":"stream"}],"execution_count":9},{"id":"887a7279","cell_type":"markdown","source":"## Section 3: WandB Setup","metadata":{}},{"id":"0c680bfc-b2e7-47a9-a30f-7bc7fd384f2a","cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nkey = user_secrets.get_secret(\"wandb_api_key\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T11:43:42.395102Z","iopub.execute_input":"2025-11-12T11:43:42.395348Z","iopub.status.idle":"2025-11-12T11:43:42.489242Z","shell.execute_reply.started":"2025-11-12T11:43:42.395333Z","shell.execute_reply":"2025-11-12T11:43:42.488502Z"}},"outputs":[],"execution_count":10},{"id":"35609f76","cell_type":"code","source":"# Login to WandB\nwandb.login(key=key)\nprint(\"‚úì Logged into Weights & Biases successfully\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T11:43:42.490002Z","iopub.execute_input":"2025-11-12T11:43:42.490243Z","iopub.status.idle":"2025-11-12T11:43:49.634211Z","shell.execute_reply.started":"2025-11-12T11:43:42.490221Z","shell.execute_reply":"2025-11-12T11:43:49.633643Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mminhquana\u001b[0m (\u001b[33mminhquana-university-of-transportation-and-communication\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"name":"stdout","text":"‚úì Logged into Weights & Biases successfully\n","output_type":"stream"}],"execution_count":11},{"id":"f969a042","cell_type":"code","source":"NAME=\"yolov11s-AdamW-2classes-baseline\"\nPROJECT=\"chest-xray-abnormality-detection\"\nEPOCH=200\nBATCH_SIZE=48\nIMG_SIZE=1024\nPATIENCE=10\nOPTIMIZER=\"AdamW\"\nLR=0.00008\nLRF=0.001\nDEVICE=[0, 1]\nWARMUP_EPOCH=10.0\nWEIGHT_DECAY=0.001","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T11:43:49.634864Z","iopub.execute_input":"2025-11-12T11:43:49.635194Z","iopub.status.idle":"2025-11-12T11:43:49.639724Z","shell.execute_reply.started":"2025-11-12T11:43:49.635177Z","shell.execute_reply":"2025-11-12T11:43:49.638789Z"}},"outputs":[],"execution_count":12},{"id":"5bbf1148","cell_type":"code","source":"# Initialize WandB project\nwandb.init(\n    project=PROJECT,\n    name=NAME,\n    config={\n        \"model\": \"YOLOv11s\",\n        \"dataset\": \"VinBigData Chest X-ray v3 (Preprocessed + Filtered)\",\n        \"epochs\": EPOCH,\n        \"batch_size\": BATCH_SIZE,\n        \"image_size\": IMG_SIZE,\n        \"patience\": PATIENCE,\n        \"optimizer\": OPTIMIZER,\n        \"learning_rate\": LR,\n        \"preprocessing\": \"None\",\n        \"augmentation\": \"None\",\n        \"training_strategy\": \"minimal augmentation to preserve medical features\",\n    }\n)\n\nprint(\"‚úì WandB initialized successfully\")\nprint(f\"  Project: chest-xray-abnormality-detection\")\nprint(f\"  Run name: {wandb.run.name}\")\nprint(f\"  Run URL: {wandb.run.url}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T11:43:49.640530Z","iopub.execute_input":"2025-11-12T11:43:49.640827Z","iopub.status.idle":"2025-11-12T11:43:58.577277Z","shell.execute_reply.started":"2025-11-12T11:43:49.640810Z","shell.execute_reply":"2025-11-12T11:43:58.576644Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.21.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20251112_114349-bol1tf1g</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/minhquana-university-of-transportation-and-communication/chest-xray-abnormality-detection/runs/bol1tf1g' target=\"_blank\">yolov11s-AdamW-2classes-baseline</a></strong> to <a href='https://wandb.ai/minhquana-university-of-transportation-and-communication/chest-xray-abnormality-detection' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/minhquana-university-of-transportation-and-communication/chest-xray-abnormality-detection' target=\"_blank\">https://wandb.ai/minhquana-university-of-transportation-and-communication/chest-xray-abnormality-detection</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/minhquana-university-of-transportation-and-communication/chest-xray-abnormality-detection/runs/bol1tf1g' target=\"_blank\">https://wandb.ai/minhquana-university-of-transportation-and-communication/chest-xray-abnormality-detection/runs/bol1tf1g</a>"},"metadata":{}},{"name":"stdout","text":"‚úì WandB initialized successfully\n  Project: chest-xray-abnormality-detection\n  Run name: yolov11s-AdamW-2classes-baseline\n  Run URL: https://wandb.ai/minhquana-university-of-transportation-and-communication/chest-xray-abnormality-detection/runs/bol1tf1g\n","output_type":"stream"}],"execution_count":13},{"id":"933ec05f","cell_type":"code","source":"# Enable WandB integration in Ultralytics\nsettings.update({'wandb': True})\n\nprint(\"‚úì WandB integration enabled for Ultralytics YOLO\")\nprint(\"\\nTraining metrics will be automatically logged to WandB:\")\nprint(\"   - Loss curves (box_loss, cls_loss, dfl_loss)\")\nprint(\"   - mAP scores (mAP50, mAP50-95)\")\nprint(\"   - Learning rate schedules\")\nprint(\"   - Training/validation images with predictions\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T11:43:58.577947Z","iopub.execute_input":"2025-11-12T11:43:58.578131Z","iopub.status.idle":"2025-11-12T11:44:03.886899Z","shell.execute_reply.started":"2025-11-12T11:43:58.578116Z","shell.execute_reply":"2025-11-12T11:44:03.885910Z"}},"outputs":[{"name":"stdout","text":"‚úì WandB integration enabled for Ultralytics YOLO\n\nTraining metrics will be automatically logged to WandB:\n   - Loss curves (box_loss, cls_loss, dfl_loss)\n   - mAP scores (mAP50, mAP50-95)\n   - Learning rate schedules\n   - Training/validation images with predictions\n","output_type":"stream"}],"execution_count":14},{"id":"16153797","cell_type":"markdown","source":"## Section 4: Training Configuration\n\nConfigure training parameters with minimal augmentation strategy.","metadata":{}},{"id":"45043374","cell_type":"code","source":"# Training configuration\ntraining_config = {\n    # Data\n    'data': str(data_yaml),\n    \n    # Training hyperparameters\n    'epochs': EPOCH,\n    'batch': BATCH_SIZE,\n    'imgsz': IMG_SIZE,\n    'patience': PATIENCE,\n    'save': True,\n    'plots': True,\n    'verbose': True,\n    \n    # Device and performance\n    'device': DEVICE,\n    'workers': 8,\n    'cache': False,\n    \n    # Optimization parameters\n    'optimizer': OPTIMIZER,\n    'lr0': LR,\n    'lrf': LRF,          # Final learning rate (lr0 * lrf)\n    'momentum': 0.937,\n    'weight_decay': WEIGHT_DECAY,\n    'warmup_epochs': WARMUP_EPOCH,\n    'warmup_momentum': 0.8,\n    'warmup_bias_lr': 0.1,\n    'cos_lr': True,         # Use cosine learning rate scheduler\n\n    'hsv_h': 0.0,\n    'hsv_s': 0.0,\n    'hsv_v': 0.0,\n    'degrees': 0.0,\n    'translate': 0.0,\n    'scale': 0.0,\n    'shear': 0.0,\n    'perspective': 0.0,\n    'flipud': 0.0,\n    'fliplr': 0.0,\n    'mosaic': 0.0,\n    'mixup': 0.0,        \n    'erasing': 0.0,\n    'auto_augment': None,  \n    \n}\n\nprint(\"Training Configuration\")\nprint(\"=\" * 80)\nfor key, value in training_config.items():\n    print(f\"  {key:25s}: {value}\")\nprint(\"=\" * 80)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T11:44:03.888559Z","iopub.execute_input":"2025-11-12T11:44:03.889006Z","iopub.status.idle":"2025-11-12T11:44:09.268745Z","shell.execute_reply.started":"2025-11-12T11:44:03.888979Z","shell.execute_reply":"2025-11-12T11:44:09.267681Z"}},"outputs":[{"name":"stdout","text":"Training Configuration\n================================================================================\n  data                     : data/baseline_2classes/data.yaml\n  epochs                   : 200\n  batch                    : 48\n  imgsz                    : 1024\n  patience                 : 10\n  save                     : True\n  plots                    : True\n  verbose                  : True\n  device                   : [0, 1]\n  workers                  : 8\n  cache                    : False\n  optimizer                : AdamW\n  lr0                      : 8e-05\n  lrf                      : 0.001\n  momentum                 : 0.937\n  weight_decay             : 0.001\n  warmup_epochs            : 10.0\n  warmup_momentum          : 0.8\n  warmup_bias_lr           : 0.1\n  cos_lr                   : True\n  hsv_h                    : 0.0\n  hsv_s                    : 0.0\n  hsv_v                    : 0.0\n  degrees                  : 0.0\n  translate                : 0.0\n  scale                    : 0.0\n  shear                    : 0.0\n  perspective              : 0.0\n  flipud                   : 0.0\n  fliplr                   : 0.0\n  mosaic                   : 0.0\n  mixup                    : 0.0\n  erasing                  : 0.0\n  auto_augment             : None\n================================================================================\n","output_type":"stream"}],"execution_count":15},{"id":"29b6d562","cell_type":"markdown","source":"## Section 5: Model Training\n\nTrain YOLOv11s with custom augmentation callback.","metadata":{}},{"id":"98236b87","cell_type":"code","source":"# Load YOLOv11s model\nprint(\"\\nLoading YOLOv11s model...\")\nmodel = YOLO('yolo11s.pt')\n\nprint(\"‚úì Model loaded successfully\")\nprint(f\"  Model architecture: YOLOv11s\")\nprint(f\"  Parameters: ~{sum(p.numel() for p in model.model.parameters()) / 1e6:.1f}M\")\n\nprint(\"\\nStarting training...\")\nprint(\"Progress will be tracked in WandB dashboard\")\nprint(\"-\" * 80)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T11:44:09.269604Z","iopub.execute_input":"2025-11-12T11:44:09.269877Z","iopub.status.idle":"2025-11-12T11:44:15.097207Z","shell.execute_reply.started":"2025-11-12T11:44:09.269851Z","shell.execute_reply":"2025-11-12T11:44:15.096449Z"}},"outputs":[{"name":"stdout","text":"\nLoading YOLOv11s model...\n\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11s.pt to 'yolo11s.pt': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 18.4MB 151.4MB/s 0.1s0.1s<0.0s\n‚úì Model loaded successfully\n  Model architecture: YOLOv11s\n  Parameters: ~9.5M\n\nStarting training...\nProgress will be tracked in WandB dashboard\n--------------------------------------------------------------------------------\n","output_type":"stream"}],"execution_count":16},{"id":"fe011fe0","cell_type":"code","source":"# Train the model\ntry:\n    results = model.train(\n        **training_config,\n        project=PROJECT,\n        name=NAME\n    )\n    \n    print(\"\\n\" + \"=\" * 80)\n    print(\"‚úì Training completed successfully!\")\n    print(\"=\" * 80)\n    \n    # Check if results is valid\n    if results is None:\n        print(\"\\nWARNING: Training returned None - checking training directory...\")\n        # Find the latest training directory\n        training_dir = Path('chest-xray-abnormality-detection')\n        if training_dir.exists():\n            # Get all run directories sorted by modification time\n            run_dirs = sorted(training_dir.glob('yolov11s-Adam*'), \n                            key=lambda x: x.stat().st_mtime, reverse=True)\n            if run_dirs:\n                latest_run = run_dirs[0]\n                print(f\"  Found latest training run: {latest_run}\")\n                best_model_path = latest_run / 'weights' / 'best.pt'\n                last_model_path = latest_run / 'weights' / 'last.pt'\n                \n                if best_model_path.exists():\n                    print(f\"  ‚úì Best model found: {best_model_path}\")\n                elif last_model_path.exists():\n                    print(f\"  ‚úì Last model found: {last_model_path}\")\n                    best_model_path = last_model_path\n                else:\n                    print(f\"  No model weights found in {latest_run}\")\n                    best_model_path = None\n            else:\n                print(\"  No training runs found\")\n                best_model_path = None\n        else:\n            print(\"  Training directory not found\")\n            best_model_path = None\n    else:\n        # Display results\n        print(\"\\nTraining Results:\")\n        if hasattr(results, 'results_dict'):\n            print(f\"  Best mAP50: {results.results_dict.get('metrics/mAP50(B)', 'N/A')}\")\n            print(f\"  Best mAP50-95: {results.results_dict.get('metrics/mAP50-95(B)', 'N/A')}\")\n        \n        # Save best model path\n        if hasattr(results, 'save_dir') and results.save_dir:\n            best_model_path = Path(results.save_dir) / 'weights' / 'best.pt'\n            print(f\"\\nBest model saved to: {best_model_path}\")\n        else:\n            print(\"\\nWARNING: results.save_dir not available\")\n            best_model_path = None\n    \nexcept Exception as e:\n    print(f\"\\nTraining failed: {e}\")\n    import traceback\n    traceback.print_exc()\n    best_model_path = None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T11:44:15.098030Z","iopub.execute_input":"2025-11-12T11:44:15.098294Z","iopub.status.idle":"2025-11-12T12:02:35.713864Z","shell.execute_reply.started":"2025-11-12T11:44:15.098276Z","shell.execute_reply":"2025-11-12T12:02:35.712940Z"}},"outputs":[{"name":"stdout","text":"Ultralytics 8.3.227 üöÄ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n                                                       CUDA:1 (Tesla T4, 15095MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=None, batch=48, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=True, cutmix=0.0, data=data/baseline_2classes/data.yaml, degrees=0.0, deterministic=True, device=0,1, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=200, erasing=0.0, exist_ok=False, fliplr=0.0, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.0, hsv_s=0.0, hsv_v=0.0, imgsz=1024, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=8e-05, lrf=0.001, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11s.pt, momentum=0.937, mosaic=0.0, multi_scale=False, name=yolov11s-AdamW-2classes-baseline, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=10, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=chest-xray-abnormality-detection, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/chest-xray-abnormality-detection/yolov11s-AdamW-2classes-baseline, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.0, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.0, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=10.0, warmup_momentum=0.8, weight_decay=0.001, workers=8, workspace=None\n\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 755.1KB 16.8MB/s 0.0s\nOverriding model.yaml nc=80 with nc=2\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n  2                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n  3                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n  4                  -1  1    103360  ultralytics.nn.modules.block.C3k2            [128, 256, 1, False, 0.25]    \n  5                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n  6                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n  8                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n 10                  -1  1    990976  ultralytics.nn.modules.block.C2PSA           [512, 512, 1]                 \n 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 13                  -1  1    443776  ultralytics.nn.modules.block.C3k2            [768, 256, 1, False]          \n 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 16                  -1  1    127680  ultralytics.nn.modules.block.C3k2            [512, 128, 1, False]          \n 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 19                  -1  1    345472  ultralytics.nn.modules.block.C3k2            [384, 256, 1, False]          \n 20                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 22                  -1  1   1511424  ultralytics.nn.modules.block.C3k2            [768, 512, 1, True]           \n 23        [16, 19, 22]  1    820182  ultralytics.nn.modules.head.Detect           [2, [128, 256, 512]]          \nYOLO11s summary: 181 layers, 9,428,566 parameters, 9,428,550 gradients, 21.6 GFLOPs\n\nTransferred 493/499 items from pretrained weights\n\u001b[34m\u001b[1mDDP:\u001b[0m debug command /usr/bin/python3 -m torch.distributed.run --nproc_per_node 2 --master_port 60599 /root/.config/Ultralytics/DDP/_temp_ylswkzrq140671932924880.py\nUltralytics 8.3.227 üöÄ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n                                                       CUDA:1 (Tesla T4, 15095MiB)\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\nwandb: Currently logged in as: minhquana (minhquana-university-of-transportation-and-communication) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\nwandb: Tracking run with wandb version 0.21.0\nwandb: Run data is saved locally in /kaggle/working/wandb/run-20251112_114430-bzu6cp8g\nwandb: Run `wandb offline` to turn off syncing.\nwandb: Syncing run yolov11s-AdamW-2classes-baseline\nwandb: ‚≠êÔ∏è View project at https://wandb.ai/minhquana-university-of-transportation-and-communication/chest-xray-abnormality-detection\nwandb: üöÄ View run at https://wandb.ai/minhquana-university-of-transportation-and-communication/chest-xray-abnormality-detection/runs/bzu6cp8g\n","output_type":"stream"},{"name":"stdout","text":"Overriding model.yaml nc=80 with nc=2\nTransferred 493/499 items from pretrained weights\nFreezing layer 'model.23.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5.4MB 62.1MB/s 0.1s\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1459.0¬±525.8 MB/s, size: 67.4 KB)\n\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/data/baseline_2classes/train/labels... 2362 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2362/2362 1.2Kit/s 1.9s0.0s\n\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/data/baseline_2classes/train/labels.cache\n\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 473.6¬±286.4 MB/s, size: 63.6 KB)\n\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/data/baseline_2classes/valid/labels... 704 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 704/704 1.2Kit/s 0.6s<0.1s\n\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/data/baseline_2classes/valid/labels.cache\nPlotting labels to /kaggle/working/chest-xray-abnormality-detection/yolov11s-AdamW-2classes-baseline/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=8e-05, momentum=0.937) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.00075), 87 bias(decay=0.0)\nImage sizes 1024 train, 1024 val\nUsing 4 dataloader workers\nLogging results to \u001b[1m/kaggle/working/chest-xray-abnormality-detection/yolov11s-AdamW-2classes-baseline\u001b[0m\nStarting training for 200 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      1/200      14.2G      2.012      4.772      1.956          8       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 50/50 1.0it/s 48.3s0.8ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.3it/s 6.3s0.9ss\n                   all        704       1124          0          0          0          0\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      2/200      14.3G      1.475      1.089      1.463          8       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 50/50 1.0it/s 47.6s0.6ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 0.9it/s 8.5s1.0ss\n                   all        704       1124      0.568      0.694      0.628      0.305\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      3/200      14.3G      1.452     0.9435      1.427          9       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 50/50 1.0it/s 50.2s0.6ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.1it/s 7.5s1.0ss\n                   all        704       1124      0.427      0.223       0.28        0.1\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      4/200      14.3G      1.388     0.8697      1.379          9       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 50/50 1.0it/s 49.6s0.6ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.1it/s 7.6s1.0ss\n                   all        704       1124      0.726      0.713      0.783      0.389\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      5/200      14.3G      1.367     0.8077       1.38          8       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 50/50 1.0it/s 49.6s0.6ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.0it/s 7.6s1.0ss\n                   all        704       1124      0.786      0.828      0.861      0.465\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      6/200      14.3G      1.318     0.7244      1.337          7       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 50/50 1.0it/s 49.7s0.6ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.1it/s 7.6s1.0ss\n                   all        704       1124      0.836      0.886      0.903      0.463\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      7/200      14.3G      1.257     0.6781      1.302          8       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 50/50 1.0it/s 49.7s0.6ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.1it/s 7.4s1.0ss\n                   all        704       1124      0.781      0.881       0.83      0.422\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      8/200      14.3G      1.152     0.5995      1.244         10       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 50/50 1.0it/s 49.6s0.6ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.1it/s 7.5s1.0ss\n                   all        704       1124      0.862      0.896      0.916       0.48\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      9/200      14.3G      1.077     0.5498      1.203          9       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 50/50 1.0it/s 49.6s0.6ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.1it/s 7.5s1.0ss\n                   all        704       1124      0.835      0.879       0.91      0.479\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     10/200      14.3G     0.9934     0.5016      1.147          8       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 50/50 1.0it/s 49.6s0.6ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.1it/s 7.3s1.0ss\n                   all        704       1124      0.859      0.909      0.905      0.463\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     11/200      14.3G      0.909      0.466        1.1          9       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 50/50 1.0it/s 49.5s0.6ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.1it/s 7.3s1.0ss\n                   all        704       1124      0.845      0.911      0.893      0.461\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     12/200      14.3G     0.8301      0.434      1.052          9       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 50/50 1.0it/s 49.5s0.6ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.1it/s 7.2s1.0ss\n                   all        704       1124      0.845      0.833      0.881      0.437\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     13/200      14.3G     0.7633     0.3811      1.017          7       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 50/50 1.0it/s 49.6s0.6ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.1it/s 7.3s1.0ss\n                   all        704       1124      0.837        0.9      0.882      0.444\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     14/200      14.3G     0.6948     0.3572     0.9753          6       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 50/50 1.0it/s 49.7s0.6ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.1it/s 7.3s1.0ss\n                   all        704       1124      0.844      0.835      0.871      0.437\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     15/200      14.3G     0.6637     0.3467     0.9543          6       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 50/50 1.0it/s 49.5s0.6ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.1it/s 7.3s1.0ss\n                   all        704       1124      0.847      0.832      0.879       0.44\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     16/200      14.3G     0.5993     0.3329     0.9257          8       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 50/50 1.0it/s 49.5s0.6ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.1it/s 7.5s1.0ss\n                   all        704       1124      0.854      0.835      0.879      0.446\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     17/200      14.3G     0.5651     0.3056     0.9038          7       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 50/50 1.0it/s 49.6s0.6ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.1it/s 7.5s1.0ss\n                   all        704       1124       0.86      0.871      0.884       0.46\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     18/200      14.3G     0.5264     0.2938     0.8872          6       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 50/50 1.0it/s 49.5s0.6ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.1it/s 7.3s1.0ss\n                   all        704       1124       0.86      0.823       0.87       0.44\n\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 10 epochs. Best results observed at epoch 8, best model saved as best.pt.\nTo update EarlyStopping(patience=10) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n\n18 epochs completed in 0.289 hours.\nOptimizer stripped from /kaggle/working/chest-xray-abnormality-detection/yolov11s-AdamW-2classes-baseline/weights/last.pt, 19.3MB\nOptimizer stripped from /kaggle/working/chest-xray-abnormality-detection/yolov11s-AdamW-2classes-baseline/weights/best.pt, 19.3MB\n\nValidating /kaggle/working/chest-xray-abnormality-detection/yolov11s-AdamW-2classes-baseline/weights/best.pt...\nYOLO11s summary (fused): 100 layers, 9,413,574 parameters, 0 gradients, 21.3 GFLOPs\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 0.7it/s 11.6s1.2s\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\n/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\n","output_type":"stream"},{"name":"stdout","text":"                   all        704       1124      0.864       0.89      0.916      0.481\n    Aortic enlargement        632        632      0.893      0.846      0.904      0.448\n          Cardiomegaly        492        492      0.835      0.935      0.928      0.514\nSpeed: 0.3ms preprocess, 7.5ms inference, 0.0ms loss, 2.7ms postprocess per image\nResults saved to \u001b[1m/kaggle/working/chest-xray-abnormality-detection/yolov11s-AdamW-2classes-baseline\u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"wandb:                                                                                \nwandb: \nwandb: Run history:\nwandb:                  lr/pg0 ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\nwandb:                  lr/pg1 ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\nwandb:                  lr/pg2 ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\nwandb:        metrics/mAP50(B) ‚ñÅ‚ñÜ‚ñÉ‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\nwandb:     metrics/mAP50-95(B) ‚ñÅ‚ñÖ‚ñÇ‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá\nwandb:    metrics/precision(B) ‚ñÅ‚ñÜ‚ñÑ‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\nwandb:       metrics/recall(B) ‚ñÅ‚ñÜ‚ñÉ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñá‚ñá‚ñá‚ñà‚ñá\nwandb:            model/GFLOPs ‚ñÅ\nwandb:        model/parameters ‚ñÅ\nwandb: model/speed_PyTorch(ms) ‚ñÅ\nwandb:          train/box_loss ‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ\nwandb:          train/cls_loss ‚ñà‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\nwandb:          train/dfl_loss ‚ñà‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\nwandb:            val/box_loss ‚ñá‚ñÉ‚ñà‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ\nwandb:            val/cls_loss ‚ñà‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\nwandb:            val/dfl_loss ‚ñà‚ñÇ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ\nwandb: \nwandb: Run summary:\nwandb:                  lr/pg0 8e-05\nwandb:                  lr/pg1 8e-05\nwandb:                  lr/pg2 8e-05\nwandb:        metrics/mAP50(B) 0.87048\nwandb:     metrics/mAP50-95(B) 0.4403\nwandb:    metrics/precision(B) 0.85959\nwandb:       metrics/recall(B) 0.8226\nwandb:            model/GFLOPs 21.551\nwandb:        model/parameters 9428566\nwandb: model/speed_PyTorch(ms) 7.123\nwandb:          train/box_loss 0.52636\nwandb:          train/cls_loss 0.29381\nwandb:          train/dfl_loss 0.8872\nwandb:            val/box_loss 1.61081\nwandb:            val/cls_loss 0.87809\nwandb:            val/dfl_loss 1.77675\nwandb: \nwandb: üöÄ View run yolov11s-AdamW-2classes-baseline at: https://wandb.ai/minhquana-university-of-transportation-and-communication/chest-xray-abnormality-detection/runs/bzu6cp8g\nwandb: ‚≠êÔ∏è View project at: https://wandb.ai/minhquana-university-of-transportation-and-communication/chest-xray-abnormality-detection\nwandb: Synced 5 W&B file(s), 21 media file(s), 10 artifact file(s) and 0 other file(s)\nwandb: Find logs at: ./wandb/run-20251112_114430-bzu6cp8g/logs\nwandb: WARNING Tried to log to step 18 that is less than the current step 19. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\nwandb: WARNING Tried to log to step 18 that is less than the current step 19. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\nwandb: WARNING Tried to log to step 18 that is less than the current step 19. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\nwandb: WARNING Tried to log to step 18 that is less than the current step 19. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\nwandb: WARNING Tried to log to step 18 that is less than the current step 19. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\nwandb: WARNING Tried to log to step 18 that is less than the current step 19. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\nwandb: WARNING Tried to log to step 18 that is less than the current step 19. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\nwandb: WARNING Tried to log to step 18 that is less than the current step 19. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\nwandb: WARNING Tried to log to step 18 that is less than the current step 19. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\nwandb: WARNING Tried to log to step 18 that is less than the current step 19. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\nwandb: WARNING Tried to log to step 18 that is less than the current step 19. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\nwandb: WARNING Tried to log to step 18 that is less than the current step 19. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\nwandb: WARNING Tried to log to step 18 that is less than the current step 19. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\nwandb: WARNING Tried to log to step 18 that is less than the current step 19. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n","output_type":"stream"},{"name":"stdout","text":"\n================================================================================\n‚úì Training completed successfully!\n================================================================================\n\nWARNING: Training returned None - checking training directory...\n  Found latest training run: chest-xray-abnormality-detection/yolov11s-AdamW-2classes-baseline\n  ‚úì Best model found: chest-xray-abnormality-detection/yolov11s-AdamW-2classes-baseline/weights/best.pt\n","output_type":"stream"}],"execution_count":17},{"id":"2c9e4f32","cell_type":"markdown","source":"## Section 6: Model Validation","metadata":{}},{"id":"51d595a0","cell_type":"code","source":"# Validate on test set\nprint(\"Model Validation on Test Set\")\nprint(\"=\" * 80)\n\n# Load best model\nif 'best_model_path' in locals() and best_model_path.exists():\n    print(f\"Loading best model: {best_model_path}\")\n    model = YOLO(str(best_model_path))\nelse:\n    print(\"Using last trained model\")\n\n# model = YOLO(\"/kaggle/working/chest-xray-abnormality-detection/yolov11s-AdamW-/weights/best.pt\")\n\nprint(\"\\nRunning validation...\")\nmetrics = model.val(data=str(data_yaml), split='test')\n\nprint(\"\\nValidation Results:\")\nprint(\"=\" * 80)\nresults_dict = metrics.results_dict\nprint(f\"  mAP50:       {results_dict.get('metrics/mAP50(B)', 0):.4f}\")\nprint(f\"  mAP50-95:    {results_dict.get('metrics/mAP50-95(B)', 0):.4f}\")\nprint(f\"  Precision:   {results_dict.get('metrics/precision(B)', 0):.4f}\")\nprint(f\"  Recall:      {results_dict.get('metrics/recall(B)', 0):.4f}\")\nprint(\"=\" * 80) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T12:02:35.714959Z","iopub.execute_input":"2025-11-12T12:02:35.715216Z","iopub.status.idle":"2025-11-12T12:02:57.644773Z","shell.execute_reply.started":"2025-11-12T12:02:35.715196Z","shell.execute_reply":"2025-11-12T12:02:57.643949Z"}},"outputs":[{"name":"stdout","text":"Model Validation on Test Set\n================================================================================\nLoading best model: chest-xray-abnormality-detection/yolov11s-AdamW-2classes-baseline/weights/best.pt\n\nRunning validation...\nUltralytics 8.3.227 üöÄ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\nYOLO11s summary (fused): 100 layers, 9,413,574 parameters, 0 gradients, 21.3 GFLOPs\n\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1760.4¬±507.6 MB/s, size: 75.3 KB)\n\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/data/baseline_2classes/test/labels... 328 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 328/328 1.3Kit/s 0.3s<0.1s\n\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/data/baseline_2classes/test/labels.cache\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 1.9it/s 11.1s0.5s\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\n/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\n","output_type":"stream"},{"name":"stdout","text":"                   all        328        519      0.842      0.883      0.903      0.457\n    Aortic enlargement        301        301      0.893      0.857      0.894      0.427\n          Cardiomegaly        218        218      0.792      0.908      0.913      0.488\nSpeed: 3.0ms preprocess, 25.7ms inference, 0.0ms loss, 1.8ms postprocess per image\nResults saved to \u001b[1m/kaggle/working/runs/detect/val\u001b[0m\n\nValidation Results:\n================================================================================\n  mAP50:       0.9035\n  mAP50-95:    0.4573\n  Precision:   0.8424\n  Recall:      0.8827\n================================================================================\n","output_type":"stream"}],"execution_count":18},{"id":"52b03bfe","cell_type":"markdown","source":"## Section 7: Model Export","metadata":{}},{"id":"602ff5d0","cell_type":"code","source":"# Export to backend\nbackend_models_dir = Path('backend/models')\nbackend_models_dir.mkdir(parents=True, exist_ok=True)\n\ntarget_model_path = backend_models_dir / 'yolov11s_finetuned.pt'\n\nprint(\"Exporting Model to Backend\")\nprint(\"=\" * 80)\n\n# Check if best_model_path exists\nif 'best_model_path' not in locals() or best_model_path is None:\n    print(\"WARNING: best_model_path not found from training\")\n    print(\"   Searching for latest trained model...\")\n    \n    # Try to find the latest model\n    training_dir = Path('chest-xray-abnormality-detection')\n    if training_dir.exists():\n        run_dirs = sorted(training_dir.glob('yolov11s-Adam*'), \n                        key=lambda x: x.stat().st_mtime, reverse=True)\n        if run_dirs:\n            latest_run = run_dirs[0]\n            best_model_path = latest_run / 'weights' / 'best.pt'\n            if not best_model_path.exists():\n                best_model_path = latest_run / 'weights' / 'last.pt'\n            \n            if best_model_path.exists():\n                print(f\"   ‚úì Found model: {best_model_path}\")\n            else:\n                print(f\"   No model weights found\")\n                best_model_path = None\n        else:\n            print(\"   No training runs found\")\n            best_model_path = None\n    else:\n        print(\"   Training directory not found\")\n        best_model_path = None\n\nif best_model_path and best_model_path.exists():\n    print(f\"Source: {best_model_path}\")\n    print(f\"Target: {target_model_path}\")\n    \n    shutil.copy(best_model_path, target_model_path)\n    \n    if target_model_path.exists():\n        size_mb = target_model_path.stat().st_size / (1024*1024)\n        print(f\"\\n‚úì Model exported successfully!\")\n        print(f\"  File size: {size_mb:.2f} MB\")\n        print(f\"  Location: {target_model_path}\")\n        print(f\"\\nModel ready for production use!\")\n    else:\n        print(\"Export failed\")\nelse:\n    print(\"Cannot export - model not found\")\n    print(\"\\nPlease check:\")\n    print(\"  1. Training completed successfully\")\n    print(\"  2. Model weights exist in training directory\")\n    print(\"  3. No errors during training\")\n\nprint(\"=\" * 80)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T12:02:57.646019Z","iopub.execute_input":"2025-11-12T12:02:57.646810Z","iopub.status.idle":"2025-11-12T12:03:03.058045Z","shell.execute_reply.started":"2025-11-12T12:02:57.646782Z","shell.execute_reply":"2025-11-12T12:03:03.057260Z"}},"outputs":[{"name":"stdout","text":"Exporting Model to Backend\n================================================================================\nSource: chest-xray-abnormality-detection/yolov11s-AdamW-2classes-baseline/weights/best.pt\nTarget: backend/models/yolov11s_finetuned.pt\n\n‚úì Model exported successfully!\n  File size: 18.36 MB\n  Location: backend/models/yolov11s_finetuned.pt\n\nModel ready for production use!\n================================================================================\n","output_type":"stream"}],"execution_count":19},{"id":"5afe21dd","cell_type":"code","source":"# Close WandB run\nwandb.finish()\nprint(\"‚úì WandB run finished\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T12:03:03.058914Z","iopub.execute_input":"2025-11-12T12:03:03.059194Z","iopub.status.idle":"2025-11-12T12:03:14.784051Z","shell.execute_reply.started":"2025-11-12T12:03:03.059170Z","shell.execute_reply":"2025-11-12T12:03:14.783245Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">yolov11s-AdamW-2classes-baseline</strong> at: <a href='https://wandb.ai/minhquana-university-of-transportation-and-communication/chest-xray-abnormality-detection/runs/bol1tf1g' target=\"_blank\">https://wandb.ai/minhquana-university-of-transportation-and-communication/chest-xray-abnormality-detection/runs/bol1tf1g</a><br> View project at: <a href='https://wandb.ai/minhquana-university-of-transportation-and-communication/chest-xray-abnormality-detection' target=\"_blank\">https://wandb.ai/minhquana-university-of-transportation-and-communication/chest-xray-abnormality-detection</a><br>Synced 5 W&B file(s), 0 media file(s), 10 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20251112_114349-bol1tf1g/logs</code>"},"metadata":{}},{"name":"stdout","text":"‚úì WandB run finished\n","output_type":"stream"}],"execution_count":20},{"id":"fe7efa34","cell_type":"markdown","source":"## Section 8: Training Summary","metadata":{}},{"id":"15a08fb9","cell_type":"code","source":"print(\"\\nTRAINING SUMMARY\")\nprint(\"=\" * 80)\n\nprint(\"\\nCompleted Tasks:\")\nprint(\"  1. ‚úì Loaded preprocessed data from data/preprocessed/\")\nprint(\"  2. ‚úì Applied custom Gaussian blur augmentation during training\")\nprint(\"  3. ‚úì Applied YOLO rotation augmentation (¬±5¬∞)\")\nprint(\"  4. ‚úì Trained YOLOv11s model for 100 epochs with early stopping\")\nprint(\"  5. ‚úì Tracked training with WandB\")\nprint(\"  6. ‚úì Validated on test set\")\nprint(\"  7. ‚úì Exported best model to backend/models/\")\n\nprint(\"\\nFinal Metrics:\")\nif 'results_dict' in locals():\n    print(f\"  mAP50:       {results_dict.get('metrics/mAP50(B)', 'N/A')}\")\n    print(f\"  mAP50-95:    {results_dict.get('metrics/mAP50-95(B)', 'N/A')}\")\n    print(f\"  Precision:   {results_dict.get('metrics/precision(B)', 'N/A')}\")\n    print(f\"  Recall:      {results_dict.get('metrics/recall(B)', 'N/A')}\")\n\nprint(\"\\n\" + \"=\" * 80)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T12:03:14.784935Z","iopub.execute_input":"2025-11-12T12:03:14.785216Z","iopub.status.idle":"2025-11-12T12:03:14.790944Z","shell.execute_reply.started":"2025-11-12T12:03:14.785198Z","shell.execute_reply":"2025-11-12T12:03:14.790126Z"}},"outputs":[{"name":"stdout","text":"\nTRAINING SUMMARY\n================================================================================\n\nCompleted Tasks:\n  1. ‚úì Loaded preprocessed data from data/preprocessed/\n  2. ‚úì Applied custom Gaussian blur augmentation during training\n  3. ‚úì Applied YOLO rotation augmentation (¬±5¬∞)\n  4. ‚úì Trained YOLOv11s model for 100 epochs with early stopping\n  5. ‚úì Tracked training with WandB\n  6. ‚úì Validated on test set\n  7. ‚úì Exported best model to backend/models/\n\nFinal Metrics:\n  mAP50:       0.9034718490684275\n  mAP50-95:    0.45726372061045\n  Precision:   0.842368553665918\n  Recall:      0.8826880588181323\n\n================================================================================\n","output_type":"stream"}],"execution_count":21}]}