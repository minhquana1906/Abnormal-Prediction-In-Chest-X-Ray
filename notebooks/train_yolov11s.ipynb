{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41d1afce",
   "metadata": {},
   "source": [
    "# YOLOv11s Fine-tuning for Chest X-ray Abnormality Detection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d7bbfc",
   "metadata": {},
   "source": [
    "## Section 1: Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74c92a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/minhquana/workspace/project_DeepLearning/computer_vision/Abnormal-Prediction-In-Chest-X-Ray\n"
     ]
    }
   ],
   "source": [
    "# Set working directory to repository root\n",
    "%cd /home/minhquana/workspace/project_DeepLearning/computer_vision/Abnormal-Prediction-In-Chest-X-Ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "644a5e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Imports successful\n",
      "  PyTorch version: 2.9.0+cu128\n",
      "  CUDA available: True\n",
      "  GPU: NVIDIA GeForce RTX 3060\n",
      "  GPU Memory: 12.5 GB\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "\n",
    "import torch\n",
    "import wandb\n",
    "from ultralytics import YOLO, settings\n",
    "\n",
    "# Import custom augmentation\n",
    "import sys\n",
    "sys.path.insert(0, str(Path.cwd()))\n",
    "\n",
    "print(\"‚úì Imports successful\")\n",
    "print(f\"  PyTorch version: {torch.__version__}\")\n",
    "print(f\"  CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"  GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"  GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062737cc",
   "metadata": {},
   "source": [
    "## Section 2: Verify Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0b57cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying Preprocessed Data\n",
      "================================================================================\n",
      "‚úì Preprocessed data directory found: data/preprocessed_with_aug\n",
      "‚úì Data YAML found: data/preprocessed_with_aug/data.yaml\n",
      "\n",
      "Dataset Configuration:\n",
      "  Number of classes: 8\n",
      "  Class names: ['Aortic enlargement', 'Cardiomegaly', 'Lung Opacity', 'Other lesion', 'Pleural effusion', 'Pleural thickening', 'Pulmonary fibrosis', 'Normal']\n",
      "\n",
      "Dataset Statistics:\n",
      "  Train:      10,038 images\n",
      "  Validation: 1,530 images\n",
      "  Test:       745 images\n",
      "  Total:      12,313 images\n",
      "\n",
      "‚úì Data verification complete - ready for training!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Verify preprocessed data directory\n",
    "preprocessed_dir = Path('data/preprocessed_with_aug')\n",
    "data_yaml = preprocessed_dir / 'data.yaml'\n",
    "\n",
    "print(\"Verifying Preprocessed Data\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if not preprocessed_dir.exists():\n",
    "    print(\"ERROR: Preprocessed data not found!\")\n",
    "    print(f\"   Expected location: {preprocessed_dir.absolute()}\")\n",
    "    print(\"\\nPlease run data_preparation.ipynb first to create preprocessed data.\")\n",
    "    raise FileNotFoundError(f\"Preprocessed data not found at {preprocessed_dir}\")\n",
    "\n",
    "if not data_yaml.exists():\n",
    "    print(f\"ERROR: data.yaml not found at {data_yaml}\")\n",
    "    raise FileNotFoundError(f\"data.yaml not found\")\n",
    "\n",
    "print(f\"‚úì Preprocessed data directory found: {preprocessed_dir}\")\n",
    "print(f\"‚úì Data YAML found: {data_yaml}\")\n",
    "\n",
    "# Load data.yaml\n",
    "with open(data_yaml, 'r') as f:\n",
    "    data_config = yaml.safe_load(f)\n",
    "\n",
    "print(f\"\\nDataset Configuration:\")\n",
    "print(f\"  Number of classes: {data_config['nc']}\")\n",
    "print(f\"  Class names: {data_config['names']}\")\n",
    "\n",
    "# Count images in each split\n",
    "splits = ['train', 'valid', 'test']\n",
    "split_counts = {}\n",
    "\n",
    "for split in splits:\n",
    "    images_dir = preprocessed_dir / split / 'images'\n",
    "    if images_dir.exists():\n",
    "        count = len(list(images_dir.glob('*.png'))) + len(list(images_dir.glob('*.jpg')))\n",
    "        split_counts[split] = count\n",
    "    else:\n",
    "        split_counts[split] = 0\n",
    "\n",
    "print(f\"\\nDataset Statistics:\")\n",
    "print(f\"  Train:      {split_counts['train']:,} images\")\n",
    "print(f\"  Validation: {split_counts['valid']:,} images\")\n",
    "print(f\"  Test:       {split_counts['test']:,} images\")\n",
    "print(f\"  Total:      {sum(split_counts.values()):,} images\")\n",
    "\n",
    "if split_counts['train'] == 0:\n",
    "    print(\"\\nERROR: No training images found!\")\n",
    "    raise ValueError(\"No training images found in preprocessed data\")\n",
    "\n",
    "print(\"\\n‚úì Data verification complete - ready for training!\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887a7279",
   "metadata": {},
   "source": [
    "## Section 3: WandB Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35609f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/minhquana/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mminhquana\u001b[0m (\u001b[33mminhquana-university-of-transportation-and-communication\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Logged into Weights & Biases successfully\n"
     ]
    }
   ],
   "source": [
    "# Login to WandB\n",
    "wandb.login(key=os.getenv('WANDB_API_KEY'))\n",
    "print(\"‚úì Logged into Weights & Biases successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bbf1148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/minhquana/workspace/project_DeepLearning/computer_vision/Abnormal-Prediction-In-Chest-X-Ray/wandb/run-20251110_041718-mj65kcd1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/minhquana-university-of-transportation-and-communication/chest-xray-abnormality-detection/runs/mj65kcd1' target=\"_blank\">yolov11s-gaussian-blur-rotation</a></strong> to <a href='https://wandb.ai/minhquana-university-of-transportation-and-communication/chest-xray-abnormality-detection' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/minhquana-university-of-transportation-and-communication/chest-xray-abnormality-detection' target=\"_blank\">https://wandb.ai/minhquana-university-of-transportation-and-communication/chest-xray-abnormality-detection</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/minhquana-university-of-transportation-and-communication/chest-xray-abnormality-detection/runs/mj65kcd1' target=\"_blank\">https://wandb.ai/minhquana-university-of-transportation-and-communication/chest-xray-abnormality-detection/runs/mj65kcd1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì WandB initialized successfully\n",
      "  Project: chest-xray-abnormality-detection\n",
      "  Run name: yolov11s-gaussian-blur-rotation\n",
      "  Run URL: https://wandb.ai/minhquana-university-of-transportation-and-communication/chest-xray-abnormality-detection/runs/mj65kcd1\n"
     ]
    }
   ],
   "source": [
    "# Initialize WandB project\n",
    "wandb.init(\n",
    "    project=\"chest-xray-abnormality-detection\",\n",
    "    name=\"yolov11s-gaussian-blur-rotation\",\n",
    "    config={\n",
    "        \"model\": \"YOLOv11s\",\n",
    "        \"dataset\": \"VinBigData Chest X-ray v3 (Preprocessed + Filtered)\",\n",
    "        \"epochs\": 100,\n",
    "        \"batch_size\": 16,\n",
    "        \"image_size\": 1024,\n",
    "        \"patience\": 10,\n",
    "        \"optimizer\": \"AdamW\",\n",
    "        \"learning_rate\": 0.001,\n",
    "        \"preprocessing\": \"grayscale + histogram_eq + normalization (NO blur)\",\n",
    "        \"augmentation\": \"gaussian_blur (custom callback) + rotation (YOLO degrees=5.0)\",\n",
    "        \"training_strategy\": \"minimal augmentation to preserve medical features\",\n",
    "        \"gaussian_blur\": \"80% 3x3, 20% 5x5 with sigma=0.5\",\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"‚úì WandB initialized successfully\")\n",
    "print(f\"  Project: chest-xray-abnormality-detection\")\n",
    "print(f\"  Run name: {wandb.run.name}\")\n",
    "print(f\"  Run URL: {wandb.run.url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "933ec05f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì WandB integration enabled for Ultralytics YOLO\n",
      "\n",
      "Training metrics will be automatically logged to WandB:\n",
      "   - Loss curves (box_loss, cls_loss, dfl_loss)\n",
      "   - mAP scores (mAP50, mAP50-95)\n",
      "   - Learning rate schedules\n",
      "   - Training/validation images with predictions\n"
     ]
    }
   ],
   "source": [
    "# Enable WandB integration in Ultralytics\n",
    "settings.update({'wandb': True})\n",
    "\n",
    "print(\"‚úì WandB integration enabled for Ultralytics YOLO\")\n",
    "print(\"\\nTraining metrics will be automatically logged to WandB:\")\n",
    "print(\"   - Loss curves (box_loss, cls_loss, dfl_loss)\")\n",
    "print(\"   - mAP scores (mAP50, mAP50-95)\")\n",
    "print(\"   - Learning rate schedules\")\n",
    "print(\"   - Training/validation images with predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16153797",
   "metadata": {},
   "source": [
    "## Section 4: Training Configuration\n",
    "\n",
    "Configure training parameters with minimal augmentation strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45043374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Configuration\n",
      "================================================================================\n",
      "  data                     : data/preprocessed_with_aug/data.yaml\n",
      "  epochs                   : 100\n",
      "  batch                    : 16\n",
      "  imgsz                    : 1024\n",
      "  patience                 : 10\n",
      "  save                     : True\n",
      "  plots                    : True\n",
      "  verbose                  : True\n",
      "  device                   : cuda\n",
      "  workers                  : 8\n",
      "  cache                    : False\n",
      "  optimizer                : AdamW\n",
      "  lr0                      : 0.001\n",
      "  lrf                      : 0.0001\n",
      "  momentum                 : 0.937\n",
      "  weight_decay             : 0.0005\n",
      "  warmup_epochs            : 3.0\n",
      "  warmup_momentum          : 0.8\n",
      "  warmup_bias_lr           : 0.1\n",
      "  cos_lr                   : True\n",
      "  degrees                  : 5.0\n",
      "  hsv_h                    : 0.0\n",
      "  hsv_s                    : 0.0\n",
      "  hsv_v                    : 0.0\n",
      "  translate                : 0.0\n",
      "  scale                    : 0.0\n",
      "  shear                    : 0.0\n",
      "  perspective              : 0.0\n",
      "  fliplr                   : 0.0\n",
      "  flipud                   : 0.0\n",
      "  mosaic                   : 0.0\n",
      "  mixup                    : 0.0\n",
      "  copy_paste               : 0.0\n",
      "  auto_augment             : None\n",
      "  erasing                  : 0.0\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Training configuration\n",
    "training_config = {\n",
    "    # Data\n",
    "    'data': str(data_yaml),\n",
    "    \n",
    "    # Training hyperparameters\n",
    "    'epochs': 100,\n",
    "    'batch': 16,\n",
    "    'imgsz': 1024,\n",
    "    'patience': 10,\n",
    "    'save': True,\n",
    "    'plots': True,\n",
    "    'verbose': True,\n",
    "    \n",
    "    # Device and performance\n",
    "    'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    'workers': 8,\n",
    "    'cache': False,\n",
    "    \n",
    "    # Optimization parameters\n",
    "    'optimizer': 'AdamW',\n",
    "    'lr0': 0.001,           # Initial learning rate\n",
    "    'lrf': 0.0001,          # Final learning rate (lr0 * lrf)\n",
    "    'momentum': 0.937,\n",
    "    'weight_decay': 0.0005,\n",
    "    'warmup_epochs': 3.0,\n",
    "    'warmup_momentum': 0.8,\n",
    "    'warmup_bias_lr': 0.1,\n",
    "    'cos_lr': True,         # Use cosine learning rate scheduler\n",
    "    \n",
    "    # Only rotation is enabled from YOLO built-in augmentations\n",
    "    'degrees': 5.0,\n",
    "    'hsv_h': 0.0,    \n",
    "    'hsv_s': 0.0,  \n",
    "    'hsv_v': 0.0,    \n",
    "    'translate': 0.0,   \n",
    "    'scale': 0.0,    \n",
    "    'shear': 0.0,          \n",
    "    'perspective': 0.0,  \n",
    "    'fliplr': 0.0, \n",
    "    'flipud': 0.0,\n",
    "    'mosaic': 0.0,\n",
    "    'mixup': 0.0,  \n",
    "    'copy_paste': 0.0,    \n",
    "    'auto_augment': None,  \n",
    "    'erasing': 0.0,        \n",
    "}\n",
    "\n",
    "print(\"Training Configuration\")\n",
    "print(\"=\" * 80)\n",
    "for key, value in training_config.items():\n",
    "    print(f\"  {key:25s}: {value}\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b6d562",
   "metadata": {},
   "source": [
    "## Section 5: Model Training\n",
    "\n",
    "Train YOLOv11s with custom augmentation callback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98236b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading YOLOv11s model...\n",
      "‚úì Model loaded successfully\n",
      "  Model architecture: YOLOv11s\n",
      "  Parameters: ~9.5M\n",
      "\n",
      "Starting training...\n",
      "Progress will be tracked in WandB dashboard\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Load YOLOv11s model\n",
    "print(\"\\nLoading YOLOv11s model...\")\n",
    "model = YOLO('backend/models/yolo11s.pt')\n",
    "\n",
    "print(\"‚úì Model loaded successfully\")\n",
    "print(f\"  Model architecture: YOLOv11s\")\n",
    "print(f\"  Parameters: ~{sum(p.numel() for p in model.model.parameters()) / 1e6:.1f}M\")\n",
    "\n",
    "print(\"\\nStarting training...\")\n",
    "print(\"Progress will be tracked in WandB dashboard\")\n",
    "print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe011fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.227 available üòÉ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.226 üöÄ Python-3.12.3 torch-2.9.0+cu128 CUDA:0 (NVIDIA GeForce RTX 3060, 11906MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=None, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=True, cutmix=0.0, data=data/preprocessed_with_aug/data.yaml, degrees=5.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.0, exist_ok=False, fliplr=0.0, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.0, hsv_s=0.0, hsv_v=0.0, imgsz=1024, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.0001, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=backend/models/yolo11s.pt, momentum=0.937, mosaic=0.0, multi_scale=False, name=yolov11s-gaussian-blur-rotation2, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=10, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=chest-xray-training, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/home/minhquana/workspace/project_DeepLearning/computer_vision/Abnormal-Prediction-In-Chest-X-Ray/chest-xray-training/yolov11s-gaussian-blur-rotation2, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.0, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.0, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=8\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  3                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  4                  -1  1    103360  ultralytics.nn.modules.block.C3k2            [128, 256, 1, False, 0.25]    \n",
      "  5                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      "  6                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.C2PSA           [512, 512, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    443776  ultralytics.nn.modules.block.C3k2            [768, 256, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    127680  ultralytics.nn.modules.block.C3k2            [512, 128, 1, False]          \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    345472  ultralytics.nn.modules.block.C3k2            [384, 256, 1, False]          \n",
      " 20                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1511424  ultralytics.nn.modules.block.C3k2            [768, 512, 1, True]           \n",
      " 23        [16, 19, 22]  1    822504  ultralytics.nn.modules.head.Detect           [8, [128, 256, 512]]          \n",
      "YOLO11s summary: 181 layers, 9,430,888 parameters, 9,430,872 gradients, 21.6 GFLOPs\n",
      "\n",
      "Transferred 493/499 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 3892.5¬±1552.0 MB/s, size: 83.3 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/minhquana/workspace/project_DeepLearning/computer_vision/Abnormal-Prediction-In-Chest-X-Ray/data/preprocessed_with_aug/train/labels... 10038 images, 4000 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10038/10038 2.7Kit/s 3.7s2s\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /home/minhquana/workspace/project_DeepLearning/computer_vision/Abnormal-Prediction-In-Chest-X-Ray/data/preprocessed_with_aug/train/labels.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1209.8¬±877.5 MB/s, size: 74.1 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/minhquana/workspace/project_DeepLearning/computer_vision/Abnormal-Prediction-In-Chest-X-Ray/data/preprocessed_with_aug/valid/labels... 1530 images, 624 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1530/1530 2.1Kit/s 0.7s0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/minhquana/workspace/project_DeepLearning/computer_vision/Abnormal-Prediction-In-Chest-X-Ray/data/preprocessed_with_aug/valid/labels.cache\n",
      "Plotting labels to /home/minhquana/workspace/project_DeepLearning/computer_vision/Abnormal-Prediction-In-Chest-X-Ray/chest-xray-training/yolov11s-gaussian-blur-rotation2/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.937) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
      "Image sizes 1024 train, 1024 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/home/minhquana/workspace/project_DeepLearning/computer_vision/Abnormal-Prediction-In-Chest-X-Ray/chest-xray-training/yolov11s-gaussian-blur-rotation2\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      1/100      9.72G      2.065      3.217      2.107          8       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 628/628 1.9it/s 5:24<0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 48/48 2.5it/s 19.5s0.4s\n",
      "                   all       1530       2545      0.498       0.24      0.234      0.102\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "try:\n",
    "    results = model.train(\n",
    "        **training_config,\n",
    "        project='chest-xray-training',\n",
    "        name='yolov11s-gaussian-blur-rotation'\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"‚úì Training completed successfully!\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Display results\n",
    "    print(\"\\nTraining Results:\")\n",
    "    if hasattr(results, 'results_dict'):\n",
    "        print(f\"  Best mAP50: {results.results_dict.get('metrics/mAP50(B)', 'N/A')}\")\n",
    "        print(f\"  Best mAP50-95: {results.results_dict.get('metrics/mAP50-95(B)', 'N/A')}\")\n",
    "    \n",
    "    # Save best model path\n",
    "    best_model_path = Path(results.save_dir) / 'weights' / 'best.pt'\n",
    "    print(f\"\\nBest model saved to: {best_model_path}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\nTraining failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9e4f32",
   "metadata": {},
   "source": [
    "## Section 6: Model Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d595a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate on test set\n",
    "print(\"Model Validation on Test Set\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Load best model\n",
    "if 'best_model_path' in locals() and best_model_path.exists():\n",
    "    print(f\"Loading best model: {best_model_path}\")\n",
    "    model = YOLO(str(best_model_path))\n",
    "else:\n",
    "    print(\"Using last trained model\")\n",
    "\n",
    "print(\"\\nRunning validation...\")\n",
    "metrics = model.val(data=str(data_yaml), split='test')\n",
    "\n",
    "print(\"\\nValidation Results:\")\n",
    "print(\"=\" * 80)\n",
    "results_dict = metrics.results_dict\n",
    "print(f\"  mAP50:       {results_dict.get('metrics/mAP50(B)', 0):.4f}\")\n",
    "print(f\"  mAP50-95:    {results_dict.get('metrics/mAP50-95(B)', 0):.4f}\")\n",
    "print(f\"  Precision:   {results_dict.get('metrics/precision(B)', 0):.4f}\")\n",
    "print(f\"  Recall:      {results_dict.get('metrics/recall(B)', 0):.4f}\")\n",
    "print(\"=\" * 80) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b03bfe",
   "metadata": {},
   "source": [
    "## Section 7: Model Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602ff5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to backend\n",
    "backend_models_dir = Path('backend/models')\n",
    "backend_models_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "target_model_path = backend_models_dir / 'yolov11s_finetuned.pt'\n",
    "\n",
    "print(\"Exporting Model to Backend\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if 'best_model_path' in locals() and best_model_path.exists():\n",
    "    print(f\"Source: {best_model_path}\")\n",
    "    print(f\"Target: {target_model_path}\")\n",
    "    \n",
    "    shutil.copy(best_model_path, target_model_path)\n",
    "    \n",
    "    if target_model_path.exists():\n",
    "        size_mb = target_model_path.stat().st_size / (1024*1024)\n",
    "        print(f\"\\n‚úì Model exported successfully!\")\n",
    "        print(f\"  File size: {size_mb:.2f} MB\")\n",
    "        print(f\"  Location: {target_model_path}\")\n",
    "        print(f\"\\nModel ready for production use!\")\n",
    "    else:\n",
    "        print(\"Export failed\")\n",
    "else:\n",
    "    print(\"Best model not found - cannot export\")\n",
    "\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afe21dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close WandB run\n",
    "wandb.finish()\n",
    "print(\"‚úì WandB run finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7efa34",
   "metadata": {},
   "source": [
    "## Section 8: Training Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a08fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nTRAINING SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nCompleted Tasks:\")\n",
    "print(\"  1. ‚úì Loaded preprocessed data from data/preprocessed/\")\n",
    "print(\"  2. ‚úì Applied custom Gaussian blur augmentation during training\")\n",
    "print(\"  3. ‚úì Applied YOLO rotation augmentation (¬±5¬∞)\")\n",
    "print(\"  4. ‚úì Trained YOLOv11s model for 100 epochs with early stopping\")\n",
    "print(\"  5. ‚úì Tracked training with WandB\")\n",
    "print(\"  6. ‚úì Validated on test set\")\n",
    "print(\"  7. ‚úì Exported best model to backend/models/\")\n",
    "\n",
    "print(\"\\nFinal Metrics:\")\n",
    "if 'results_dict' in locals():\n",
    "    print(f\"  mAP50:       {results_dict.get('metrics/mAP50(B)', 'N/A')}\")\n",
    "    print(f\"  mAP50-95:    {results_dict.get('metrics/mAP50-95(B)', 'N/A')}\")\n",
    "    print(f\"  Precision:   {results_dict.get('metrics/precision(B)', 'N/A')}\")\n",
    "    print(f\"  Recall:      {results_dict.get('metrics/recall(B)', 'N/A')}\")\n",
    "\n",
    "print(\"\\nNext Steps:\")\n",
    "print(\"  1. Run compare_baseline_finetuned.ipynb to compare with baseline\")\n",
    "print(\"  2. Check WandB dashboard for detailed training metrics\")\n",
    "print(\"  3. Test model in production via backend API\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Abnormal-Prediction-In-Chest-X-Ray",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
