{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44bc15d0",
   "metadata": {},
   "source": [
    "# YOLOv11s Training - Simple Version\n",
    "\n",
    "## üìù Overview\n",
    "\n",
    "Simplified training notebook that:\n",
    "- ‚úÖ Loads preprocessed data directly from `data/balanced_preprocessed/`\n",
    "- ‚úÖ Trains YOLOv11s model with WandB tracking\n",
    "- ‚úÖ Validates on test set\n",
    "- ‚úÖ Exports model to backend\n",
    "\n",
    "**Prerequisites:**\n",
    "- Data already preprocessed and balanced (run `finetune_yolo_balanced.ipynb` sections 1-5 first)\n",
    "- WandB account and API key\n",
    "\n",
    "**Time to complete:** ~2-3 hours (training only)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e796c9a3",
   "metadata": {},
   "source": [
    "## Section 1: Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2309fc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set working directory to repository root\n",
    "%cd /home/minhquana/workspace/project_DeepLearning/computer_vision/Abnormal-Prediction-In-Chest-X-Ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e21f36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import wandb\n",
    "from ultralytics import YOLO, settings\n",
    "import torch\n",
    "\n",
    "print(\"‚úì Imports successful\")\n",
    "print(f\"  PyTorch version: {torch.__version__}\")\n",
    "print(f\"  CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"  GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"  GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89acb01",
   "metadata": {},
   "source": [
    "## Section 2: Verify Preprocessed Data\n",
    "\n",
    "Check that preprocessed data exists and includes augmented images.\n",
    "\n",
    "**IMPORTANT:** This notebook expects augmented images to be merged into training set.\n",
    "- Run `finetune_yolo_balanced.ipynb` sections 1-5 first\n",
    "- Augmented images should be in `balanced_preprocessed/train/images/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae155a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify preprocessed data directory\n",
    "preprocessed_dir = Path('data/balanced_preprocessed')\n",
    "data_yaml = preprocessed_dir / 'data.yaml'\n",
    "\n",
    "print(\"üîç Verifying Preprocessed Data\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if not preprocessed_dir.exists():\n",
    "    print(\"‚ùå ERROR: Preprocessed data not found!\")\n",
    "    print(f\"   Expected location: {preprocessed_dir.absolute()}\")\n",
    "    print(\"\\n‚ö†Ô∏è Please run finetune_yolo_balanced.ipynb sections 1-5 first to:\")\n",
    "    print(\"   1. Download dataset\")\n",
    "    print(\"   2. Create balanced dataset\")\n",
    "    print(\"   3. Preprocess images\")\n",
    "    raise FileNotFoundError(f\"Preprocessed data not found at {preprocessed_dir}\")\n",
    "\n",
    "if not data_yaml.exists():\n",
    "    print(f\"‚ùå ERROR: data.yaml not found at {data_yaml}\")\n",
    "    raise FileNotFoundError(f\"data.yaml not found\")\n",
    "\n",
    "print(f\"‚úì Preprocessed data directory found: {preprocessed_dir}\")\n",
    "print(f\"‚úì Data YAML found: {data_yaml}\")\n",
    "\n",
    "# Count images in each split\n",
    "splits = ['train', 'valid', 'test']\n",
    "split_counts = {}\n",
    "\n",
    "for split in splits:\n",
    "    images_dir = preprocessed_dir / split / 'images'\n",
    "    if images_dir.exists():\n",
    "        count = len(list(images_dir.glob('*.png'))) + len(list(images_dir.glob('*.jpg')))\n",
    "        split_counts[split] = count\n",
    "    else:\n",
    "        split_counts[split] = 0\n",
    "\n",
    "print(f\"\\nüìä Dataset Statistics:\")\n",
    "print(f\"  Train:      {split_counts['train']:,} images\")\n",
    "print(f\"  Validation: {split_counts['valid']:,} images\")\n",
    "print(f\"  Test:       {split_counts['test']:,} images\")\n",
    "print(f\"  Total:      {sum(split_counts.values()):,} images\")\n",
    "\n",
    "if split_counts['train'] == 0:\n",
    "    print(\"\\n‚ùå ERROR: No training images found!\")\n",
    "    raise ValueError(\"No training images found in preprocessed data\")\n",
    "\n",
    "print(\"\\n‚úì Data verification complete - ready for training!\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564dfe74",
   "metadata": {},
   "source": [
    "## Section 3: WandB Setup\n",
    "\n",
    "Initialize Weights & Biases for experiment tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207f548f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Login to WandB\n",
    "wandb.login(key=os.getenv('WANDB_API_KEY'))\n",
    "print(\"‚úì Logged into Weights & Biases successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34897885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize WandB project\n",
    "wandb.init(\n",
    "    project=\"chest-xray-detection-balanced\",\n",
    "    name=\"yolov11s-no-augment\",\n",
    "    config={\n",
    "        \"model\": \"YOLOv11s\",\n",
    "        \"dataset\": \"VinBigData Chest X-ray v3 (Balanced + Preprocessed + Augmented)\",\n",
    "        \"epochs\": 100,\n",
    "        \"batch_size\": 16,\n",
    "        \"image_size\": 1024,\n",
    "        \"patience\": 10,\n",
    "        \"optimizer\": \"AdamW\",\n",
    "        \"learning_rate\": 0.001,\n",
    "        \"preprocessing\": \"histogram_eq + gaussian_blur + normalization\",\n",
    "        \"augmentation\": \"pre-augmented only (YOLO augmentation disabled)\",\n",
    "        \"training_strategy\": \"use pre-augmented data - no real-time augmentation\"\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"‚úì WandB initialized successfully\")\n",
    "print(f\"  Project: chest-xray-detection-balanced\")\n",
    "print(f\"  Run name: {wandb.run.name}\")\n",
    "print(f\"  Run URL: {wandb.run.url}\")\n",
    "print(f\"\\n‚ö†Ô∏è  Note: Training with pre-augmented data only\")\n",
    "print(f\"  ‚Üí All YOLO augmentations disabled\")\n",
    "print(f\"  ‚Üí Using fixed augmented variations from preprocessing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293d26aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable WandB integration in Ultralytics\n",
    "settings.update({'wandb': True})\n",
    "\n",
    "print(\"‚úì WandB integration enabled for Ultralytics YOLO\")\n",
    "print(\"\\nüìä Training metrics will be automatically logged to WandB:\")\n",
    "print(\"   - Loss curves (box_loss, cls_loss, dfl_loss)\")\n",
    "print(\"   - mAP scores (mAP50, mAP50-95)\")\n",
    "print(\"   - Learning rate schedules\")\n",
    "print(\"   - Training/validation images with predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36a51da",
   "metadata": {},
   "source": [
    "## Section 4: Model Training\n",
    "\n",
    "Train YOLOv11s on preprocessed balanced dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1eea24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration - NO AUGMENTATION (use pre-augmented data only)\n",
    "training_config = {\n",
    "    'data': str(data_yaml),\n",
    "    'epochs': 100,\n",
    "    'batch': 16,\n",
    "    'imgsz': 1024,\n",
    "    'patience': 10,\n",
    "    'save': True,\n",
    "    'plots': True,\n",
    "    'verbose': True,\n",
    "    'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    'workers': 8,\n",
    "    'cache': False,\n",
    "    # Optimization parameters for better convergence\n",
    "    'optimizer': 'AdamW',  # Changed from auto (SGD) to AdamW\n",
    "    'lr0': 0.001,  # Initial learning rate\n",
    "    'lrf': 0.0001,  # Final learning rate (lr0 * lrf)\n",
    "    'momentum': 0.937,\n",
    "    'weight_decay': 0.0005,\n",
    "    'warmup_epochs': 3.0,\n",
    "    'warmup_momentum': 0.8,\n",
    "    'warmup_bias_lr': 0.1,\n",
    "    'cos_lr': True,  # Use cosine learning rate scheduler\n",
    "    # ===== DISABLE ALL AUGMENTATIONS =====\n",
    "    # Use pre-augmented data from finetune_yolo_balanced.ipynb\n",
    "    # 'augment': False,  # Disable all augmentations\n",
    "    'hsv_h': 0.0,      # No hue shift\n",
    "    'hsv_s': 0.0,      # No saturation change\n",
    "    'hsv_v': 0.0,      # No value/brightness change\n",
    "    'degrees': 0.0,    # No rotation\n",
    "    'translate': 0.0,  # No translation\n",
    "    'scale': 0.0,      # No scaling\n",
    "    'shear': 0.0,      # No shearing\n",
    "    'perspective': 0.0,  # No perspective transform\n",
    "    'fliplr': 0.0,     # No horizontal flip\n",
    "    'flipud': 0.0,     # No vertical flip\n",
    "    'mosaic': 0.0,     # No mosaic augmentation\n",
    "    'mixup': 0.0,      # No mixup\n",
    "    'copy_paste': 0.0,  # No copy-paste\n",
    "    'auto_augment': None,  # Disable auto augmentation\n",
    "    'erasing': 0.0,    # No random erasing\n",
    "}\n",
    "\n",
    "print(\"üöÄ Starting YOLOv11s Training (NO AUGMENTATION MODE)\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\n‚öôÔ∏è  Training Configuration:\")\n",
    "for key, value in training_config.items():\n",
    "    print(f\"  {key:20s}: {value}\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\n‚ö†Ô∏è  IMPORTANT: All YOLO augmentations are DISABLED\")\n",
    "print(\"   ‚Üí Using ONLY pre-augmented data from balanced_preprocessed/\")\n",
    "print(\"   ‚Üí Ensure augmented images are merged into training set\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80397702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load YOLOv11s model\n",
    "print(\"\\nüì¶ Loading YOLOv11s model...\")\n",
    "model = YOLO('yolo11s.pt')\n",
    "\n",
    "print(\"‚úì Model loaded successfully\")\n",
    "print(f\"  Model architecture: YOLOv11s\")\n",
    "print(f\"  Parameters: ~{sum(p.numel() for p in model.model.parameters()) / 1e6:.1f}M\")\n",
    "\n",
    "print(\"\\nüèãÔ∏è  Starting training...\")\n",
    "print(\"üìä Progress will be tracked in WandB dashboard\")\n",
    "print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1b23da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "try:\n",
    "    results = model.train(\n",
    "        **training_config,\n",
    "        project='chest-xray-detection-balanced',\n",
    "        name='yolov11s-no-augment'\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"‚úì Training completed successfully!\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Display results\n",
    "    print(\"\\nüìà Training Results:\")\n",
    "    if hasattr(results, 'results_dict'):\n",
    "        print(f\"  Best mAP50: {results.results_dict.get('metrics/mAP50(B)', 'N/A')}\")\n",
    "        print(f\"  Best mAP50-95: {results.results_dict.get('metrics/mAP50-95(B)', 'N/A')}\")\n",
    "    \n",
    "    # Save best model path\n",
    "    best_model_path = Path(results.save_dir) / 'weights' / 'best.pt'\n",
    "    print(f\"\\nüíæ Best model saved to: {best_model_path}\")\n",
    "    \n",
    "    print(f\"\\nüí° Training Summary:\")\n",
    "    print(f\"  ‚úì Used pre-augmented data only\")\n",
    "    print(f\"  ‚úì No real-time augmentation applied\")\n",
    "    print(f\"  ‚úì Preserved preprocessed image quality\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Training failed: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8ad554",
   "metadata": {},
   "source": [
    "## Section 5: Model Validation\n",
    "\n",
    "Validate trained model on test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3964093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate on test set\n",
    "print(\"üß™ Model Validation on Test Set\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Load best model\n",
    "if 'best_model_path' in locals() and best_model_path.exists():\n",
    "    print(f\"üì¶ Loading best model: {best_model_path}\")\n",
    "    model = YOLO(str(best_model_path))\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Using last trained model\")\n",
    "\n",
    "print(\"\\nüîç Running validation...\")\n",
    "metrics = model.val(data=str(data_yaml), split='test')\n",
    "\n",
    "print(\"\\nüìä Validation Results:\")\n",
    "print(\"=\" * 80)\n",
    "results_dict = metrics.results_dict\n",
    "print(f\"  mAP50:       {results_dict.get('metrics/mAP50(B)', 0):.4f}\")\n",
    "print(f\"  mAP50-95:    {results_dict.get('metrics/mAP50-95(B)', 0):.4f}\")\n",
    "print(f\"  Precision:   {results_dict.get('metrics/precision(B)', 0):.4f}\")\n",
    "print(f\"  Recall:      {results_dict.get('metrics/recall(B)', 0):.4f}\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa5bf8d",
   "metadata": {},
   "source": [
    "## Section 6: Model Export\n",
    "\n",
    "Export trained model to backend for production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b8fedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to backend\n",
    "backend_models_dir = Path('../backend/models')\n",
    "backend_models_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "target_model_path = backend_models_dir / 'yolov11s_finetuned.pt'\n",
    "\n",
    "print(\"üì¶ Exporting Model to Backend\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if 'best_model_path' in locals() and best_model_path.exists():\n",
    "    print(f\"üìÇ Source: {best_model_path}\")\n",
    "    print(f\"üìÇ Target: {target_model_path}\")\n",
    "    \n",
    "    shutil.copy(best_model_path, target_model_path)\n",
    "    \n",
    "    if target_model_path.exists():\n",
    "        size_mb = target_model_path.stat().st_size / (1024*1024)\n",
    "        print(f\"\\n‚úì Model exported successfully!\")\n",
    "        print(f\"  File size: {size_mb:.2f} MB\")\n",
    "        print(f\"  Location: {target_model_path}\")\n",
    "        print(f\"\\nüéØ Model ready for production use!\")\n",
    "        print(f\"  ‚úì Trained on pre-augmented data\")\n",
    "        print(f\"  ‚úì No real-time augmentation used\")\n",
    "        print(f\"  ‚úì Preserved preprocessed features\")\n",
    "    else:\n",
    "        print(\"‚ùå Export failed\")\n",
    "else:\n",
    "    print(\"‚ùå Best model not found - cannot export\")\n",
    "\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d49b2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close WandB run\n",
    "wandb.finish()\n",
    "print(\"‚úì WandB run finished\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Abnormal-Prediction-In-Chest-X-Ray",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
