{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d976257",
   "metadata": {},
   "source": [
    "# Data Preparation - 2 Classes Only (Aortic Enlargement, Cardiomegaly)\n",
    "\n",
    "**Goal:** Prepare dataset với chỉ 2 classes:\n",
    "- Aortic enlargement (Phình động mạch chủ)\n",
    "- Cardiomegaly (Tim to)\n",
    "\n",
    "**No Normal class** - YOLO tự học từ negative samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a770731",
   "metadata": {},
   "source": [
    "## 1. Setup và Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "109e009d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/minhquana/workspace/project_DeepLearning/computer_vision/Abnormal-Prediction-In-Chest-X-Ray\n"
     ]
    }
   ],
   "source": [
    "# Set working directory\n",
    "%cd /home/minhquana/workspace/project_DeepLearning/computer_vision/Abnormal-Prediction-In-Chest-X-Ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e6f84b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Imports successful\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import shutil\n",
    "import json\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "from collections import Counter, defaultdict\n",
    "from typing import Dict, List, Set\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Import preprocessing\n",
    "import sys\n",
    "sys.path.insert(0, str(Path.cwd()))\n",
    "from backend.src.utils.preprocessing import preprocess_image\n",
    "\n",
    "print(\"✓ Imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b9ca01",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3cf7a02b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration:\n",
      "  Source: data\n",
      "  Output: data/preprocessed_2classes\n",
      "  Classes to keep: 2\n",
      "    - Aortic enlargement (Phình động mạch chủ)\n",
      "    - Cardiomegaly (Tim to)\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "DATA_DIR = Path(\"data\")\n",
    "SOURCE_DIR = DATA_DIR  \n",
    "OUTPUT_DIR = DATA_DIR / \"preprocessed_2classes\"\n",
    "\n",
    "# Classes to keep (chỉ 2 classes)\n",
    "CLASSES_TO_KEEP = [\n",
    "    \"Aortic enlargement\",\n",
    "    \"Cardiomegaly\"\n",
    "]\n",
    "\n",
    "# Vietnamese mapping\n",
    "CLASS_MAPPING_VI = {\n",
    "    \"Aortic enlargement\": \"Phình động mạch chủ\",\n",
    "    \"Cardiomegaly\": \"Tim to\"\n",
    "}\n",
    "\n",
    "print(\"Configuration:\")\n",
    "print(f\"  Source: {SOURCE_DIR}\")\n",
    "print(f\"  Output: {OUTPUT_DIR}\")\n",
    "print(f\"  Classes to keep: {len(CLASSES_TO_KEEP)}\")\n",
    "for cls in CLASSES_TO_KEEP:\n",
    "    print(f\"    - {cls} ({CLASS_MAPPING_VI[cls]})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fff5af9",
   "metadata": {},
   "source": [
    "## 3. Load Original Dataset Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5eb82e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dataset:\n",
      "  Classes: 14\n",
      "  Names: ['Aortic enlargement', 'Atelectasis', 'Calcification', 'Cardiomegaly', 'Consolidation', 'ILD', 'Infiltration', 'Lung Opacity', 'Nodule-Mass', 'Other lesion', 'Pleural effusion', 'Pleural thickening', 'Pneumothorax', 'Pulmonary fibrosis']\n",
      "\n",
      "Class indices to keep: [0, 3]\n"
     ]
    }
   ],
   "source": [
    "# Load original data.yaml\n",
    "data_yaml_path = SOURCE_DIR / \"data.yaml\"\n",
    "\n",
    "with open(data_yaml_path, 'r') as f:\n",
    "    original_data_config = yaml.safe_load(f)\n",
    "\n",
    "print(\"Original Dataset:\")\n",
    "print(f\"  Classes: {original_data_config['nc']}\")\n",
    "print(f\"  Names: {original_data_config['names']}\")\n",
    "\n",
    "# Get class indices for classes to keep\n",
    "original_class_names = original_data_config['names']\n",
    "class_indices_to_keep = [\n",
    "    original_class_names.index(cls) for cls in CLASSES_TO_KEEP\n",
    "]\n",
    "\n",
    "print(f\"\\nClass indices to keep: {class_indices_to_keep}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2135a22f",
   "metadata": {},
   "source": [
    "## 4. Analyze Dataset - Count Images per Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44426679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing dataset...\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Counting images:   0%|          | 0/10499 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Counting images: 100%|██████████| 10499/10499 [00:00<00:00, 88183.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRAIN:\n",
      "  Aortic enlargement: 2,134 images\n",
      "  Cardiomegaly: 1,590 images\n",
      "  ---\n",
      "  Per-class total: 3,724 (có overlap)\n",
      "  Unique images: 2,362 (actual count)\n",
      "  Overlap (images with both classes): 1,362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Counting images: 100%|██████████| 3000/3000 [00:00<00:00, 97872.75it/s]\n",
      "Counting images: 100%|██████████| 3000/3000 [00:00<00:00, 97872.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "VALID:\n",
      "  Aortic enlargement: 632 images\n",
      "  Cardiomegaly: 492 images\n",
      "  ---\n",
      "  Per-class total: 1,124 (có overlap)\n",
      "  Unique images: 704 (actual count)\n",
      "  Overlap (images with both classes): 420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Counting images: 100%|██████████| 1499/1499 [00:00<00:00, 95316.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TEST:\n",
      "  Aortic enlargement: 301 images\n",
      "  Cardiomegaly: 218 images\n",
      "  ---\n",
      "  Per-class total: 519 (có overlap)\n",
      "  Unique images: 328 (actual count)\n",
      "  Overlap (images with both classes): 191\n",
      "\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def count_images_per_class(split_dir: Path, label_dir: Path, class_indices: List[int]) -> Dict[int, int]:\n",
    "    \"\"\"\n",
    "    Count images per class (một image có thể chứa nhiều classes).\n",
    "    \n",
    "    Returns:\n",
    "        Dict with keys: \n",
    "        - Per class: {class_id: count}\n",
    "        - 'unique_images': Total unique images containing any target class\n",
    "    \"\"\"\n",
    "    class_counts = defaultdict(int)\n",
    "    unique_images = set()  # Track unique images with target classes\n",
    "    \n",
    "    label_files = list(label_dir.glob('*.txt'))\n",
    "    \n",
    "    for label_file in tqdm(label_files, desc=f\"Counting {split_dir.name}\"):\n",
    "        with open(label_file, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            \n",
    "        # Get unique class IDs in this file\n",
    "        classes_in_file = set()\n",
    "        for line in lines:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) >= 5:\n",
    "                class_id = int(parts[0])\n",
    "                if class_id in class_indices:\n",
    "                    classes_in_file.add(class_id)\n",
    "        \n",
    "        # If this image has any target class, add to unique set\n",
    "        if classes_in_file:\n",
    "            unique_images.add(label_file.stem)\n",
    "        \n",
    "        # Increment count for each class found\n",
    "        for class_id in classes_in_file:\n",
    "            class_counts[class_id] += 1\n",
    "    \n",
    "    result = dict(class_counts)\n",
    "    result['unique_images'] = len(unique_images)\n",
    "    return result\n",
    "\n",
    "# Count for each split\n",
    "print(\"\\nAnalyzing dataset...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for split in ['train', 'valid', 'test']:\n",
    "    split_dir = SOURCE_DIR / split / 'images'\n",
    "    label_dir = SOURCE_DIR / split / 'labels'\n",
    "    \n",
    "    if not split_dir.exists():\n",
    "        print(f\"\\n{split.upper()}: Not found\")\n",
    "        continue\n",
    "    \n",
    "    # Count images per class\n",
    "    class_counts = count_images_per_class(split_dir, label_dir, class_indices_to_keep)\n",
    "    \n",
    "    print(f\"\\n{split.upper()}:\")\n",
    "    per_class_total = 0\n",
    "    for cls_idx, cls_name in zip(class_indices_to_keep, CLASSES_TO_KEEP):\n",
    "        count = class_counts.get(cls_idx, 0)\n",
    "        per_class_total += count\n",
    "        print(f\"  {cls_name}: {count:,} images\")\n",
    "    \n",
    "    unique_count = class_counts.get('unique_images', 0)\n",
    "    overlap_count = per_class_total - unique_count\n",
    "    \n",
    "    print(f\"  ---\")\n",
    "    print(f\"  Per-class total: {per_class_total:,} (có overlap)\")\n",
    "    print(f\"  Unique images: {unique_count:,} (actual count)\")\n",
    "    print(f\"  Overlap (images with both classes): {overlap_count:,}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d6f7c2",
   "metadata": {},
   "source": [
    "## 5. Filter và Copy Images\n",
    "\n",
    "Chỉ copy các ảnh có chứa ít nhất 1 trong 2 classes cần giữ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c3ea18b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Filtering and copying data...\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filtering train: 100%|██████████| 10499/10499 [00:00<00:00, 29480.56it/s]\n",
      "Filtering train: 100%|██████████| 10499/10499 [00:00<00:00, 29480.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  train: Copied 2,362 images, skipped 8,137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filtering valid: 100%|██████████| 3000/3000 [00:00<00:00, 28000.48it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  valid: Copied 704 images, skipped 2,296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filtering test: 100%|██████████| 1499/1499 [00:00<00:00, 26898.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  test: Copied 328 images, skipped 1,171\n",
      "\n",
      "Total images copied: 3,394\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def filter_and_copy_data(source_dir: Path, output_dir: Path, class_indices: List[int], split: str):\n",
    "\n",
    "    # Create output directories\n",
    "    output_img_dir = output_dir / split / 'images'\n",
    "    output_lbl_dir = output_dir / split / 'labels'\n",
    "    output_img_dir.mkdir(parents=True, exist_ok=True)\n",
    "    output_lbl_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Source directories\n",
    "    source_img_dir = source_dir / split / 'images'\n",
    "    source_lbl_dir = source_dir / split / 'labels'\n",
    "    \n",
    "    if not source_img_dir.exists():\n",
    "        print(f\"  {split}: Not found, skipping\")\n",
    "        return\n",
    "    \n",
    "    # Get all label files\n",
    "    label_files = list(source_lbl_dir.glob('*.txt'))\n",
    "    \n",
    "    # Create mapping from old class indices to new (0, 1)\n",
    "    class_id_mapping = {old_idx: new_idx for new_idx, old_idx in enumerate(class_indices)}\n",
    "    \n",
    "    copied_count = 0\n",
    "    skipped_count = 0\n",
    "    \n",
    "    for label_file in tqdm(label_files, desc=f\"Filtering {split}\"):\n",
    "        # Read label file\n",
    "        with open(label_file, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "        \n",
    "        # Filter lines - keep only lines with target classes\n",
    "        filtered_lines = []\n",
    "        for line in lines:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) >= 5:\n",
    "                class_id = int(parts[0])\n",
    "                if class_id in class_indices:\n",
    "                    # Remap class ID (0 or 1)\n",
    "                    new_class_id = class_id_mapping[class_id]\n",
    "                    filtered_lines.append(f\"{new_class_id} {' '.join(parts[1:])}\\n\")\n",
    "        \n",
    "        # Skip if no relevant classes found\n",
    "        if not filtered_lines:\n",
    "            skipped_count += 1\n",
    "            continue\n",
    "        \n",
    "        # Find corresponding image file\n",
    "        img_name = label_file.stem\n",
    "        img_file = None\n",
    "        for ext in ['.jpg', '.jpeg', '.png', '.JPG', '.JPEG', '.PNG']:\n",
    "            candidate = source_img_dir / f\"{img_name}{ext}\"\n",
    "            if candidate.exists():\n",
    "                img_file = candidate\n",
    "                break\n",
    "        \n",
    "        if img_file is None:\n",
    "            print(f\"    Warning: Image not found for {img_name}\")\n",
    "            continue\n",
    "        \n",
    "        # Copy image\n",
    "        shutil.copy2(img_file, output_img_dir / img_file.name)\n",
    "        \n",
    "        # Write filtered label file\n",
    "        output_label_file = output_lbl_dir / label_file.name\n",
    "        with open(output_label_file, 'w') as f:\n",
    "            f.writelines(filtered_lines)\n",
    "        \n",
    "        copied_count += 1\n",
    "    \n",
    "    print(f\"  {split}: Copied {copied_count:,} images, skipped {skipped_count:,}\")\n",
    "    return copied_count\n",
    "\n",
    "# Filter and copy data\n",
    "print(\"\\nFiltering and copying data...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "total_copied = 0\n",
    "for split in ['train', 'valid', 'test']:\n",
    "    count = filter_and_copy_data(SOURCE_DIR, OUTPUT_DIR, class_indices_to_keep, split)\n",
    "    if count:\n",
    "        total_copied += count\n",
    "\n",
    "print(f\"\\nTotal images copied: {total_copied:,}\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce2b72b",
   "metadata": {},
   "source": [
    "## 5.5. Find and Sample Negative Samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b2029758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finding negative samples...\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding negative samples in train:   0%|          | 0/10499 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding negative samples in train: 100%|██████████| 10499/10499 [00:00<00:00, 68839.91it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  TRAIN: Found 8,137 negative samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding negative samples in valid: 100%|██████████| 3000/3000 [00:00<00:00, 71841.19it/s]\n",
      "Finding negative samples in valid: 100%|██████████| 3000/3000 [00:00<00:00, 71841.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  VALID: Found 2,296 negative samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding negative samples in test: 100%|██████████| 1499/1499 [00:00<00:00, 73348.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  TEST: Found 1,171 negative samples\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def find_negative_samples(source_dir: Path, split: str, class_indices: List[int]) -> List[Path]:\n",
    "    \"\"\"\n",
    "    Tìm các ảnh không có label hoặc không chứa các classes cần giữ.\n",
    "    \n",
    "    Args:\n",
    "        source_dir: Source data directory\n",
    "        split: Dataset split (train/valid/test)\n",
    "        class_indices: List of class indices we're keeping\n",
    "        \n",
    "    Returns:\n",
    "        List of image paths that are negative samples\n",
    "    \"\"\"\n",
    "    source_img_dir = source_dir / split / 'images'\n",
    "    source_lbl_dir = source_dir / split / 'labels'\n",
    "    \n",
    "    if not source_img_dir.exists():\n",
    "        return []\n",
    "    \n",
    "    negative_samples = []\n",
    "    \n",
    "    # Get all images\n",
    "    image_files = list(source_img_dir.glob('*.jpg')) + list(source_img_dir.glob('*.png'))\n",
    "    \n",
    "    for img_file in tqdm(image_files, desc=f\"Finding negative samples in {split}\"):\n",
    "        label_file = source_lbl_dir / (img_file.stem + '.txt')\n",
    "        \n",
    "        # Case 1: Label file doesn't exist\n",
    "        if not label_file.exists():\n",
    "            negative_samples.append(img_file)\n",
    "            continue\n",
    "        \n",
    "        # Case 2: Label file is empty\n",
    "        if label_file.stat().st_size == 0:\n",
    "            negative_samples.append(img_file)\n",
    "            continue\n",
    "        \n",
    "        # Case 3: Label file only contains classes we're NOT keeping\n",
    "        with open(label_file, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "        \n",
    "        has_target_class = False\n",
    "        for line in lines:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) >= 5:\n",
    "                class_id = int(parts[0])\n",
    "                if class_id in class_indices:\n",
    "                    has_target_class = True\n",
    "                    break\n",
    "        \n",
    "        if not has_target_class:\n",
    "            negative_samples.append(img_file)\n",
    "    \n",
    "    return negative_samples\n",
    "\n",
    "\n",
    "def sample_negative_samples(\n",
    "    negative_samples: List[Path],\n",
    "    target_count: int,\n",
    "    random_seed: int = 42\n",
    ") -> List[Path]:\n",
    "\n",
    "    random.seed(random_seed)\n",
    "    \n",
    "    if len(negative_samples) <= target_count:\n",
    "        return negative_samples\n",
    "    \n",
    "    return random.sample(negative_samples, target_count)\n",
    "\n",
    "\n",
    "# Find negative samples for each split\n",
    "print(\"\\nFinding negative samples...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "negative_samples = {}\n",
    "for split in ['train', 'valid', 'test']:\n",
    "    neg_samples = find_negative_samples(SOURCE_DIR, split, class_indices_to_keep)\n",
    "    negative_samples[split] = neg_samples\n",
    "    print(f\"  {split.upper()}: Found {len(neg_samples):,} negative samples\")\n",
    "\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "59d5c76d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sampling negative samples to balance dataset...\n",
      "================================================================================\n",
      "  TRAIN:\n",
      "    Positive samples: 2,362\n",
      "    Available negative samples: 8,137\n",
      "    Sampled negative samples: 1,181\n",
      "    Total after balance: 3,543\n",
      "  VALID:\n",
      "    Positive samples: 704\n",
      "    Available negative samples: 2,296\n",
      "    Sampled negative samples: 352\n",
      "    Total after balance: 1,056\n",
      "  TEST:\n",
      "    Positive samples: 328\n",
      "    Available negative samples: 1,171\n",
      "    Sampled negative samples: 164\n",
      "    Total after balance: 492\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Sample negative samples để cân bằng với positive samples\n",
    "print(\"\\nSampling negative samples to balance dataset...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Get counts of images already copied (positive samples)\n",
    "positive_counts = {}\n",
    "for split in ['train', 'valid', 'test']:\n",
    "    img_dir = OUTPUT_DIR / split / 'images'\n",
    "    if img_dir.exists():\n",
    "        count = len(list(img_dir.glob('*.jpg'))) + len(list(img_dir.glob('*.png')))\n",
    "        positive_counts[split] = count\n",
    "    else:\n",
    "        positive_counts[split] = 0\n",
    "\n",
    "# Sample negative samples (equal to positive samples)\n",
    "sampled_negative = {}\n",
    "for split in ['train', 'valid', 'test']:\n",
    "    target_count = round(positive_counts[split] / 2)  # Match positive sample count\n",
    "    sampled = sample_negative_samples(negative_samples[split], target_count)\n",
    "    sampled_negative[split] = sampled\n",
    "    \n",
    "    print(f\"  {split.upper()}:\")\n",
    "    print(f\"    Positive samples: {positive_counts[split]:,}\")\n",
    "    print(f\"    Available negative samples: {len(negative_samples[split]):,}\")\n",
    "    print(f\"    Sampled negative samples: {len(sampled):,}\")\n",
    "    print(f\"    Total after balance: {positive_counts[split] + len(sampled):,}\")\n",
    "\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "899269e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Copying negative samples...\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying train negative samples: 100%|██████████| 1181/1181 [00:00<00:00, 10840.56it/s]\n",
      "Copying train negative samples: 100%|██████████| 1181/1181 [00:00<00:00, 10840.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  TRAIN: Copied 1,181 negative samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying valid negative samples: 100%|██████████| 352/352 [00:00<00:00, 7018.45it/s]\n",
      "Copying valid negative samples: 100%|██████████| 352/352 [00:00<00:00, 7018.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  VALID: Copied 352 negative samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying test negative samples: 100%|██████████| 164/164 [00:00<00:00, 8198.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  TEST: Copied 164 negative samples\n",
      "================================================================================\n",
      "\n",
      "Total negative samples copied: 1,697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Copy negative samples vào output directory\n",
    "print(\"\\nCopying negative samples...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "negative_copied = {}\n",
    "for split in ['train', 'valid', 'test']:\n",
    "    output_img_dir = OUTPUT_DIR / split / 'images'\n",
    "    output_lbl_dir = OUTPUT_DIR / split / 'labels'\n",
    "    \n",
    "    copied = 0\n",
    "    for img_file in tqdm(sampled_negative[split], desc=f\"Copying {split} negative samples\"):\n",
    "        # Copy image\n",
    "        shutil.copy2(img_file, output_img_dir / img_file.name)\n",
    "        \n",
    "        # Create empty label file (no bounding boxes for negative samples)\n",
    "        label_file = output_lbl_dir / (img_file.stem + '.txt')\n",
    "        label_file.touch()  # Create empty file\n",
    "        \n",
    "        copied += 1\n",
    "    \n",
    "    negative_copied[split] = copied\n",
    "    print(f\"  {split.upper()}: Copied {copied:,} negative samples\")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nTotal negative samples copied: {sum(negative_copied.values()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ccfaed0",
   "metadata": {},
   "source": [
    "## 6. Apply Preprocessing\n",
    "\n",
    "Apply standard preprocessing pipeline to all images:\n",
    "1. Grayscale conversion\n",
    "2. Histogram equalization\n",
    "3. Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "07bef154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying preprocessing...\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing train:   0%|          | 0/3543 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing train: 100%|██████████| 3543/3543 [11:33<00:00,  5.11it/s]\n",
      "Preprocessing train: 100%|██████████| 3543/3543 [11:33<00:00,  5.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  train: Preprocessed 3,543 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing valid: 100%|██████████| 1056/1056 [03:29<00:00,  5.04it/s]\n",
      "Preprocessing valid: 100%|██████████| 1056/1056 [03:29<00:00,  5.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  valid: Preprocessed 1,056 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing test: 100%|██████████| 492/492 [01:36<00:00,  5.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  test: Preprocessed 492 images\n",
      "\n",
      "✓ Preprocessing complete\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def apply_preprocessing_to_split(output_dir: Path, split: str):\n",
    "    img_dir = output_dir / split / 'images'\n",
    "    \n",
    "    if not img_dir.exists():\n",
    "        print(f\"  {split}: Not found, skipping\")\n",
    "        return\n",
    "    \n",
    "    image_files = list(img_dir.glob('*.jpg')) + list(img_dir.glob('*.png'))\n",
    "    \n",
    "    for img_file in tqdm(image_files, desc=f\"Preprocessing {split}\"):\n",
    "        # Load image\n",
    "        img = Image.open(img_file)\n",
    "        img_array = np.array(img)\n",
    "        \n",
    "        # Apply preprocessing (grayscale, histogram eq, normalization)\n",
    "        preprocessed = preprocess_image(\n",
    "            img_array, \n",
    "            target_size=None,  # Keep original size\n",
    "            apply_normalization=True\n",
    "        )\n",
    "        \n",
    "        # Convert back to uint8 for saving\n",
    "        preprocessed_uint8 = (preprocessed * 255).astype(np.uint8)\n",
    "        \n",
    "        # Save (overwrite original)\n",
    "        Image.fromarray(preprocessed_uint8).save(img_file)\n",
    "    \n",
    "    print(f\"  {split}: Preprocessed {len(image_files):,} images\")\n",
    "\n",
    "# Apply preprocessing\n",
    "print(\"\\nApplying preprocessing...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for split in ['train', 'valid', 'test']:\n",
    "    apply_preprocessing_to_split(OUTPUT_DIR, split)\n",
    "\n",
    "print(\"\\n✓ Preprocessing complete\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e439b2c6",
   "metadata": {},
   "source": [
    "## 7. Create data.yaml Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5d97b203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Created data/preprocessed_2classes/data.yaml\n",
      "\n",
      "Contents:\n",
      "path: /home/minhquana/workspace/project_DeepLearning/computer_vision/Abnormal-Prediction-In-Chest-X-Ray/data/preprocessed_2classes\n",
      "train: train/images\n",
      "val: valid/images\n",
      "test: test/images\n",
      "nc: 2\n",
      "names:\n",
      "- Aortic enlargement\n",
      "- Cardiomegaly\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create data.yaml (English)\n",
    "data_yaml = {\n",
    "    'path': str(OUTPUT_DIR.absolute()),\n",
    "    'train': 'train/images',\n",
    "    'val': 'valid/images',\n",
    "    'test': 'test/images',\n",
    "    'nc': len(CLASSES_TO_KEEP),\n",
    "    'names': CLASSES_TO_KEEP\n",
    "}\n",
    "\n",
    "data_yaml_path = OUTPUT_DIR / 'data.yaml'\n",
    "with open(data_yaml_path, 'w') as f:\n",
    "    yaml.dump(data_yaml, f, default_flow_style=False, sort_keys=False)\n",
    "\n",
    "print(f\"✓ Created {data_yaml_path}\")\n",
    "print(\"\\nContents:\")\n",
    "with open(data_yaml_path, 'r') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "949eef12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Created data/preprocessed_2classes/data_vi.yaml\n",
      "\n",
      "Contents:\n",
      "path: /home/minhquana/workspace/project_DeepLearning/computer_vision/Abnormal-Prediction-In-Chest-X-Ray/data/preprocessed_2classes\n",
      "train: train/images\n",
      "val: valid/images\n",
      "test: test/images\n",
      "nc: 2\n",
      "names:\n",
      "- Phình động mạch chủ\n",
      "- Tim to\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create data_vi.yaml (Vietnamese)\n",
    "data_yaml_vi = {\n",
    "    'path': str(OUTPUT_DIR.absolute()),\n",
    "    'train': 'train/images',\n",
    "    'val': 'valid/images',\n",
    "    'test': 'test/images',\n",
    "    'nc': len(CLASSES_TO_KEEP),\n",
    "    'names': [CLASS_MAPPING_VI[cls] for cls in CLASSES_TO_KEEP]\n",
    "}\n",
    "\n",
    "data_yaml_vi_path = OUTPUT_DIR / 'data_vi.yaml'\n",
    "with open(data_yaml_vi_path, 'w', encoding='utf-8') as f:\n",
    "    yaml.dump(data_yaml_vi, f, default_flow_style=False, sort_keys=False, allow_unicode=True)\n",
    "\n",
    "print(f\"✓ Created {data_yaml_vi_path}\")\n",
    "print(\"\\nContents:\")\n",
    "with open(data_yaml_vi_path, 'r', encoding='utf-8') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4410085",
   "metadata": {},
   "source": [
    "## 8. Update Class Mapping Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b5fd001e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Created configs/class_mapping_2classes.json\n",
      "\n",
      "Contents:\n",
      "{\n",
      "  \"Aortic enlargement\": \"Phình động mạch chủ\",\n",
      "  \"Cardiomegaly\": \"Tim to\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Update configs/class_mapping.json\n",
    "config_dir = Path(\"configs\")\n",
    "config_dir.mkdir(exist_ok=True)\n",
    "\n",
    "class_mapping_path = config_dir / 'class_mapping_2classes.json'\n",
    "with open(class_mapping_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(CLASS_MAPPING_VI, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"✓ Created {class_mapping_path}\")\n",
    "print(\"\\nContents:\")\n",
    "print(json.dumps(CLASS_MAPPING_VI, ensure_ascii=False, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163ace36",
   "metadata": {},
   "source": [
    "## 9. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4740a556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "DATA PREPARATION COMPLETE\n",
      "================================================================================\n",
      "\n",
      "Output directory: data/preprocessed_2classes\n",
      "\n",
      "Classes (nc=2):\n",
      "  0: Aortic enlargement (Phình động mạch chủ)\n",
      "  1: Cardiomegaly (Tim to)\n",
      "\n",
      "Dataset splits:\n",
      "  train: 3,543 images\n",
      "  valid: 1,056 images\n",
      "  test: 492 images\n",
      "\n",
      "Files created:\n",
      "  - data/preprocessed_2classes/data.yaml\n",
      "  - data/preprocessed_2classes/data_vi.yaml\n",
      "  - configs/class_mapping_2classes.json\n",
      "\n",
      "Next steps:\n",
      "  1. Review preprocessed images in: data/preprocessed_2classes\n",
      "  2. Train model using: notebooks/train_yolov11s.ipynb\n",
      "  3. Use data.yaml: data/preprocessed_2classes/data.yaml\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"DATA PREPARATION COMPLETE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\nOutput directory: {OUTPUT_DIR}\")\n",
    "print(f\"\\nClasses (nc={len(CLASSES_TO_KEEP)}):\")\n",
    "for i, (en, vi) in enumerate(CLASS_MAPPING_VI.items()):\n",
    "    print(f\"  {i}: {en} ({vi})\")\n",
    "\n",
    "print(\"\\nDataset splits:\")\n",
    "for split in ['train', 'valid', 'test']:\n",
    "    img_dir = OUTPUT_DIR / split / 'images'\n",
    "    if img_dir.exists():\n",
    "        count = len(list(img_dir.glob('*.jpg'))) + len(list(img_dir.glob('*.png')))\n",
    "        print(f\"  {split}: {count:,} images\")\n",
    "\n",
    "print(\"\\nFiles created:\")\n",
    "print(f\"  - {data_yaml_path}\")\n",
    "print(f\"  - {data_yaml_vi_path}\")\n",
    "print(f\"  - {class_mapping_path}\")\n",
    "\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"  1. Review preprocessed images in:\", OUTPUT_DIR)\n",
    "print(\"  2. Train model using: notebooks/train_yolov11s.ipynb\")\n",
    "print(f\"  3. Use data.yaml: {data_yaml_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d706b73",
   "metadata": {},
   "source": [
    "## 10. (Optional) Create Augmented Dataset with Gaussian Blur\n",
    "\n",
    "Tạo augmented version của training data với Gaussian blur.\n",
    "- Chỉ augment **training set**\n",
    "- Mỗi ảnh tạo 1 augmented version\n",
    "- Lưu vào `data/preprocessed_2classes_aug/`\n",
    "\n",
    "**Lưu ý:** Section này là OPTIONAL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "64710567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating Augmented Dataset\n",
      "================================================================================\n",
      "  Source: data/preprocessed_2classes\n",
      "  Output: data/preprocessed_2classes_aug\n",
      "  Augment train only: True\n",
      "  Augmentations per image: 1\n",
      "================================================================================\n",
      "\n",
      "Processing TRAIN split...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Copying originals: 100%|██████████| 3543/3543 [00:00<00:00, 8650.22it/s]\n",
      "  Copying originals: 100%|██████████| 3543/3543 [00:00<00:00, 8650.22it/s]\n",
      "  Creating augmented versions: 100%|██████████| 3543/3543 [01:21<00:00, 43.27it/s]\n",
      "  Creating augmented versions: 100%|██████████| 3543/3543 [01:21<00:00, 43.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ✓ Original: 3,543\n",
      "    ✓ Augmented: 3,543\n",
      "    ✓ Total: 7,086\n",
      "\n",
      "Processing VALID split...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Copying originals: 100%|██████████| 1056/1056 [00:00<00:00, 8821.07it/s]\n",
      "  Copying originals: 100%|██████████| 1056/1056 [00:00<00:00, 8821.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ✓ Original: 1,056\n",
      "    ✓ Augmented: 0\n",
      "    ✓ Total: 1,056\n",
      "\n",
      "Processing TEST split...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Copying originals: 100%|██████████| 492/492 [00:00<00:00, 8973.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ✓ Original: 492\n",
      "    ✓ Augmented: 0\n",
      "    ✓ Total: 492\n",
      "\n",
      "================================================================================\n",
      "✓ Augmented dataset created successfully!\n",
      "  Output directory: /home/minhquana/workspace/project_DeepLearning/computer_vision/Abnormal-Prediction-In-Chest-X-Ray/data/preprocessed_2classes_aug\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def create_augmented_dataset(\n",
    "    source_dir: Path,\n",
    "    output_dir: Path,\n",
    "    augment_train_only: bool = True,\n",
    "    num_augmentations: int = 1,\n",
    "):\n",
    "    \"\"\"\n",
    "    Create augmented dataset with Gaussian blur.\n",
    "    \n",
    "    Args:\n",
    "        source_dir: Source preprocessed directory\n",
    "        output_dir: Output directory for augmented data\n",
    "        augment_train_only: Only augment training set\n",
    "        num_augmentations: Number of augmented versions per image\n",
    "    \"\"\"\n",
    "    from backend.src.utils.augmentation import augment_image\n",
    "    \n",
    "    print(f\"\\nCreating Augmented Dataset\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"  Source: {source_dir}\")\n",
    "    print(f\"  Output: {output_dir}\")\n",
    "    print(f\"  Augment train only: {augment_train_only}\")\n",
    "    print(f\"  Augmentations per image: {num_augmentations}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Determine which splits to augment\n",
    "    splits_to_augment = ['train'] if augment_train_only else ['train', 'valid', 'test']\n",
    "    all_splits = ['train', 'valid', 'test']\n",
    "    \n",
    "    aug_stats = {}\n",
    "    \n",
    "    for split in all_splits:\n",
    "        source_images_dir = source_dir / split / 'images'\n",
    "        source_labels_dir = source_dir / split / 'labels'\n",
    "        \n",
    "        output_images_dir = output_dir / split / 'images'\n",
    "        output_labels_dir = output_dir / split / 'labels'\n",
    "        \n",
    "        output_images_dir.mkdir(parents=True, exist_ok=True)\n",
    "        output_labels_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        if not source_images_dir.exists():\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\nProcessing {split.upper()} split...\")\n",
    "        \n",
    "        # Get all images\n",
    "        image_files = list(source_images_dir.glob('*.jpg')) + list(source_images_dir.glob('*.png'))\n",
    "        \n",
    "        original_count = 0\n",
    "        augmented_count = 0\n",
    "        \n",
    "        # Copy original images\n",
    "        for img_path in tqdm(image_files, desc=f\"  Copying originals\"):\n",
    "            # Copy image\n",
    "            shutil.copy(img_path, output_images_dir / img_path.name)\n",
    "            \n",
    "            # Copy label\n",
    "            label_path = source_labels_dir / (img_path.stem + '.txt')\n",
    "            if label_path.exists():\n",
    "                shutil.copy(label_path, output_labels_dir / label_path.name)\n",
    "            \n",
    "            original_count += 1\n",
    "        \n",
    "        # Create augmented versions (only for specified splits)\n",
    "        if split in splits_to_augment:\n",
    "            for img_path in tqdm(image_files, desc=f\"  Creating augmented versions\"):\n",
    "                # Load image\n",
    "                img = Image.open(img_path).convert('L')\n",
    "                img_array = np.array(img)\n",
    "                \n",
    "                # Create N augmented versions\n",
    "                for aug_idx in range(num_augmentations):\n",
    "                    # Apply Gaussian blur augmentation\n",
    "                    img_augmented = augment_image(img_array, augmentation_probability=1.0)\n",
    "                    \n",
    "                    # Save augmented image with suffix\n",
    "                    aug_img_name = f\"{img_path.stem}_aug{aug_idx+1}{img_path.suffix}\"\n",
    "                    aug_img_path = output_images_dir / aug_img_name\n",
    "                    Image.fromarray(img_augmented).save(aug_img_path)\n",
    "                    \n",
    "                    # Copy label with same suffix\n",
    "                    label_path = source_labels_dir / (img_path.stem + '.txt')\n",
    "                    if label_path.exists():\n",
    "                        aug_label_name = f\"{img_path.stem}_aug{aug_idx+1}.txt\"\n",
    "                        aug_label_path = output_labels_dir / aug_label_name\n",
    "                        shutil.copy(label_path, aug_label_path)\n",
    "                    \n",
    "                    augmented_count += 1\n",
    "        \n",
    "        total_count = original_count + augmented_count\n",
    "        aug_stats[split] = {\n",
    "            'original': original_count,\n",
    "            'augmented': augmented_count,\n",
    "            'total': total_count\n",
    "        }\n",
    "        \n",
    "        print(f\"    ✓ Original: {original_count:,}\")\n",
    "        print(f\"    ✓ Augmented: {augmented_count:,}\")\n",
    "        print(f\"    ✓ Total: {total_count:,}\")\n",
    "    \n",
    "    # Copy and update data.yaml\n",
    "    source_yaml = source_dir / 'data.yaml'\n",
    "    output_yaml = output_dir / 'data.yaml'\n",
    "    \n",
    "    with open(source_yaml, 'r') as f:\n",
    "        data_yaml = yaml.safe_load(f)\n",
    "    \n",
    "    # Update path\n",
    "    data_yaml['path'] = str(output_dir.absolute())\n",
    "    \n",
    "    with open(output_yaml, 'w') as f:\n",
    "        yaml.dump(data_yaml, f, default_flow_style=False, sort_keys=False)\n",
    "    \n",
    "    # Copy data_vi.yaml if exists\n",
    "    source_yaml_vi = source_dir / 'data_vi.yaml'\n",
    "    if source_yaml_vi.exists():\n",
    "        output_yaml_vi = output_dir / 'data_vi.yaml'\n",
    "        with open(source_yaml_vi, 'r', encoding='utf-8') as f:\n",
    "            data_yaml_vi = yaml.safe_load(f)\n",
    "        data_yaml_vi['path'] = str(output_dir.absolute())\n",
    "        with open(output_yaml_vi, 'w', encoding='utf-8') as f:\n",
    "            yaml.dump(data_yaml_vi, f, default_flow_style=False, sort_keys=False, allow_unicode=True)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"✓ Augmented dataset created successfully!\")\n",
    "    print(f\"  Output directory: {output_dir.absolute()}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    return aug_stats\n",
    "\n",
    "\n",
    "# Create augmented dataset\n",
    "augmented_output_dir = Path('data/preprocessed_2classes_aug')\n",
    "\n",
    "aug_stats = create_augmented_dataset(\n",
    "    source_dir=OUTPUT_DIR,\n",
    "    output_dir=augmented_output_dir,\n",
    "    augment_train_only=True,\n",
    "    num_augmentations=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9810ea73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Augmented Dataset Summary:\n",
      "================================================================================\n",
      "\n",
      "TRAIN:\n",
      "  Original images: 3,543\n",
      "  Augmented images: 3,543\n",
      "  Total images: 7,086\n",
      "\n",
      "VALID:\n",
      "  Original images: 1,056\n",
      "  Augmented images: 0\n",
      "  Total images: 1,056\n",
      "\n",
      "TEST:\n",
      "  Original images: 492\n",
      "  Augmented images: 0\n",
      "  Total images: 492\n",
      "\n",
      "================================================================================\n",
      "\n",
      "GRAND TOTAL:\n",
      "  Original: 5,091\n",
      "  Augmented: 3,543\n",
      "  Total: 8,634\n",
      "  Augmentation ratio: 69.6%\n",
      "================================================================================\n",
      "\n",
      "✓ Use this for training:\n",
      "  data.yaml: data/preprocessed_2classes_aug/data.yaml\n",
      "  data_vi.yaml: data/preprocessed_2classes_aug/data_vi.yaml\n"
     ]
    }
   ],
   "source": [
    "# Summary của augmented dataset\n",
    "print(\"\\nAugmented Dataset Summary:\")\n",
    "print(\"=\" * 80)\n",
    "for split in ['train', 'valid', 'test']:\n",
    "    print(f\"\\n{split.upper()}:\")\n",
    "    print(f\"  Original images: {aug_stats[split]['original']:,}\")\n",
    "    print(f\"  Augmented images: {aug_stats[split]['augmented']:,}\")\n",
    "    print(f\"  Total images: {aug_stats[split]['total']:,}\")\n",
    "\n",
    "total_original = sum(aug_stats[s]['original'] for s in ['train', 'valid', 'test'])\n",
    "total_augmented = sum(aug_stats[s]['augmented'] for s in ['train', 'valid', 'test'])\n",
    "total_all = sum(aug_stats[s]['total'] for s in ['train', 'valid', 'test'])\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(f\"\\nGRAND TOTAL:\")\n",
    "print(f\"  Original: {total_original:,}\")\n",
    "print(f\"  Augmented: {total_augmented:,}\")\n",
    "print(f\"  Total: {total_all:,}\")\n",
    "print(f\"  Augmentation ratio: {total_augmented/total_original*100:.1f}%\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\n✓ Use this for training:\")\n",
    "print(f\"  data.yaml: {augmented_output_dir / 'data.yaml'}\")\n",
    "print(f\"  data_vi.yaml: {augmented_output_dir / 'data_vi.yaml'}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Abnormal-Prediction-In-Chest-X-Ray",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
