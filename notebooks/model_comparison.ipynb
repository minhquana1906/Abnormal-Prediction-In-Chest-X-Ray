{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee42beac",
   "metadata": {},
   "source": [
    "# Model Comparison: Baseline vs Light Augmentation vs Hard Augmentation\n",
    "\n",
    "Notebook n√†y so s√°nh 3 chi·∫øn l∆∞·ª£c training:\n",
    "- **Baseline**: Kh√¥ng √°p d·ª•ng preprocessing v√† augmentation\n",
    "- **Light Augmented**: Augmentation nh·∫π (histogram_eq, gaussian_blur, rotation ¬±10¬∞, hsv_v=0.4, scale=0.5, translate=0.1, fliplr=0.5)\n",
    "- **Hard Augmented**: Augmentation m·∫°nh (th√™m shear, perspective, mosaic, mixup, copy_paste)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fc2513",
   "metadata": {},
   "source": [
    "## Section 1: Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e75c691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !uv pip install -q ultralytics matplotlib seaborn pandas numpy pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c7fdf4a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01multralytics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m YOLO\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Set style\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úì Imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee6afb9",
   "metadata": {},
   "source": [
    "## Section 2: Load Model Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7972f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying Model Weights\n",
      "================================================================================\n",
      "‚úì Baseline            : ../models/baseline.pt (18.36 MB)\n",
      "‚úì Light Augmented     : ../models/light_augmented.pt (18.36 MB)\n",
      "‚úì Hard Augmented      : ../models/hard_augmented.pt (18.37 MB)\n",
      "\n",
      "‚úì All model weights found!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Define model paths\n",
    "models_dir = Path('../models')\n",
    "\n",
    "model_configs = {\n",
    "    'Baseline': {\n",
    "        'path': models_dir / 'baseline.pt',\n",
    "        'description': 'Kh√¥ng preprocessing, kh√¥ng augmentation',\n",
    "        'color': '#FF6B6B'\n",
    "    },\n",
    "    'Light Augmented': {\n",
    "        'path': models_dir / 'light_augmented.pt',\n",
    "        'description': 'Histogram EQ + Gaussian blur + Rotation ¬±10¬∞ + HSV + Scale + Translate + Flip',\n",
    "        'color': '#4ECDC4'\n",
    "    },\n",
    "    'Hard Augmented': {\n",
    "        'path': models_dir / 'hard_augmented.pt',\n",
    "        'description': 'Light + Shear + Perspective + Mosaic + Mixup + Copy-Paste',\n",
    "        'color': '#95E1D3'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Verify all models exist\n",
    "print(\"Verifying Model Weights\")\n",
    "print(\"=\" * 80)\n",
    "for name, config in model_configs.items():\n",
    "    path = config['path']\n",
    "    if path.exists():\n",
    "        size_mb = path.stat().st_size / (1024*1024)\n",
    "        print(f\"‚úì {name:20s}: {path} ({size_mb:.2f} MB)\")\n",
    "    else:\n",
    "        print(f\"‚úó {name:20s}: NOT FOUND at {path}\")\n",
    "        raise FileNotFoundError(f\"Model not found: {path}\")\n",
    "\n",
    "print(\"\\n‚úì All model weights found!\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbcd528",
   "metadata": {},
   "source": [
    "## Section 3: Verify Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376d780b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying Test Datasets\n",
      "================================================================================\n",
      "‚úì Baseline data.yaml found: ../data/baseline_2classes/data.yaml\n",
      "  Classes: 2 | Names: ['Aortic enlargement', 'Cardiomegaly']\n",
      "  Test images: 328\n",
      "\n",
      "‚úì Preprocessed data.yaml found: ../data/preprocessed_2classes_aug_non_negative/data.yaml\n",
      "  Classes: 2 | Names: ['Aortic enlargement', 'Cardiomegaly']\n",
      "  Test images: 328\n",
      "\n",
      "‚úì Both datasets verified successfully!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Define data paths for each model\n",
    "# Baseline: evaluate on baseline_2classes (raw, no preprocessing)\n",
    "baseline_data_yaml = Path('../data/baseline_2classes/data.yaml')\n",
    "\n",
    "# Light & Hard Augmented: evaluate on preprocessed_2classes_aug_non_negative (with preprocessing)\n",
    "preprocessed_data_yaml = Path('../data/preprocessed_2classes_aug_non_negative/data.yaml')\n",
    "\n",
    "print(\"Verifying Test Datasets\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Verify baseline dataset\n",
    "if not baseline_data_yaml.exists():\n",
    "    print(f\"ERROR: baseline data.yaml not found at {baseline_data_yaml}\")\n",
    "    raise FileNotFoundError(f\"Baseline data.yaml not found\")\n",
    "\n",
    "print(f\"‚úì Baseline data.yaml found: {baseline_data_yaml}\")\n",
    "\n",
    "# Load baseline data config\n",
    "with open(baseline_data_yaml, 'r') as f:\n",
    "    baseline_data_config = yaml.safe_load(f)\n",
    "\n",
    "print(f\"  Classes: {baseline_data_config['nc']} | Names: {baseline_data_config['names']}\")\n",
    "\n",
    "# Count baseline test images\n",
    "baseline_test_images = Path(baseline_data_yaml.parent) / 'test' / 'images'\n",
    "baseline_test_count = len(list(baseline_test_images.glob('*.png'))) + len(list(baseline_test_images.glob('*.jpg')))\n",
    "print(f\"  Test images: {baseline_test_count:,}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Verify preprocessed dataset\n",
    "if not preprocessed_data_yaml.exists():\n",
    "    print(f\"ERROR: preprocessed data.yaml not found at {preprocessed_data_yaml}\")\n",
    "    raise FileNotFoundError(f\"Preprocessed data.yaml not found\")\n",
    "\n",
    "print(f\"‚úì Preprocessed data.yaml found: {preprocessed_data_yaml}\")\n",
    "\n",
    "# Load preprocessed data config\n",
    "with open(preprocessed_data_yaml, 'r') as f:\n",
    "    preprocessed_data_config = yaml.safe_load(f)\n",
    "\n",
    "print(f\"  Classes: {preprocessed_data_config['nc']} | Names: {preprocessed_data_config['names']}\")\n",
    "\n",
    "# Count preprocessed test images\n",
    "preprocessed_test_images = Path(preprocessed_data_yaml.parent) / 'test' / 'images'\n",
    "preprocessed_test_count = len(list(preprocessed_test_images.glob('*.png'))) + len(list(preprocessed_test_images.glob('*.jpg')))\n",
    "print(f\"  Test images: {preprocessed_test_count:,}\")\n",
    "\n",
    "if baseline_test_count == 0 or preprocessed_test_count == 0:\n",
    "    print(\"\\nERROR: No test images found!\")\n",
    "    raise ValueError(\"No test images found in one or both datasets\")\n",
    "\n",
    "print(\"\\n‚úì Both datasets verified successfully!\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608080b0",
   "metadata": {},
   "source": [
    "## Section 4: Evaluate Models on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b848099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Models on Respective Test Datasets\n",
      "================================================================================\n",
      "\n",
      "Evaluating: Baseline\n",
      "Description: Kh√¥ng preprocessing, kh√¥ng augmentation\n",
      "--------------------------------------------------------------------------------\n",
      "Dataset: baseline_2classes (raw, no preprocessing)\n",
      "Ultralytics 8.3.226 üöÄ Python-3.12.3 torch-2.9.0+cu128 CUDA:0 (NVIDIA GeForce RTX 3060, 11906MiB)\n",
      "Ultralytics 8.3.226 üöÄ Python-3.12.3 torch-2.9.0+cu128 CUDA:0 (NVIDIA GeForce RTX 3060, 11906MiB)\n",
      "YOLO11s summary (fused): 100 layers, 9,413,574 parameters, 0 gradients, 21.3 GFLOPs\n",
      "YOLO11s summary (fused): 100 layers, 9,413,574 parameters, 0 gradients, 21.3 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 3971.4¬±1249.2 MB/s, size: 64.6 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/minhquana/workspace/project_DeepLearning/computer_vision/Abnormal-Prediction-In-Chest-X-Ray/data/baseline_2classes/test/labels.cache... 328 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 328/328 980.6Kit/s 0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 3971.4¬±1249.2 MB/s, size: 64.6 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/minhquana/workspace/project_DeepLearning/computer_vision/Abnormal-Prediction-In-Chest-X-Ray/data/baseline_2classes/test/labels.cache... 328 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 328/328 980.6Kit/s 0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 3.3it/s 6.4s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 3.3it/s 6.4s\n",
      "                   all        328        519      0.843      0.883      0.903      0.457\n",
      "Speed: 1.9ms preprocess, 15.3ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1m/home/minhquana/workspace/project_DeepLearning/computer_vision/Abnormal-Prediction-In-Chest-X-Ray/runs/detect/val10\u001b[0m\n",
      "                   all        328        519      0.843      0.883      0.903      0.457\n",
      "Speed: 1.9ms preprocess, 15.3ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1m/home/minhquana/workspace/project_DeepLearning/computer_vision/Abnormal-Prediction-In-Chest-X-Ray/runs/detect/val10\u001b[0m\n",
      "  mAP50:       0.9034\n",
      "  mAP50-95:    0.4567\n",
      "  Precision:   0.8426\n",
      "  Recall:      0.8826\n",
      "\n",
      "Evaluating: Light Augmented\n",
      "Description: Histogram EQ + Gaussian blur + Rotation ¬±10¬∞ + HSV + Scale + Translate + Flip\n",
      "--------------------------------------------------------------------------------\n",
      "Dataset: preprocessed_2classes_aug_non_negative (with histogram_eq)\n",
      "Ultralytics 8.3.226 üöÄ Python-3.12.3 torch-2.9.0+cu128 CUDA:0 (NVIDIA GeForce RTX 3060, 11906MiB)\n",
      "  mAP50:       0.9034\n",
      "  mAP50-95:    0.4567\n",
      "  Precision:   0.8426\n",
      "  Recall:      0.8826\n",
      "\n",
      "Evaluating: Light Augmented\n",
      "Description: Histogram EQ + Gaussian blur + Rotation ¬±10¬∞ + HSV + Scale + Translate + Flip\n",
      "--------------------------------------------------------------------------------\n",
      "Dataset: preprocessed_2classes_aug_non_negative (with histogram_eq)\n",
      "Ultralytics 8.3.226 üöÄ Python-3.12.3 torch-2.9.0+cu128 CUDA:0 (NVIDIA GeForce RTX 3060, 11906MiB)\n",
      "YOLO11s summary (fused): 100 layers, 9,413,574 parameters, 0 gradients, 21.3 GFLOPs\n",
      "YOLO11s summary (fused): 100 layers, 9,413,574 parameters, 0 gradients, 21.3 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 5044.1¬±1080.4 MB/s, size: 100.1 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/minhquana/workspace/project_DeepLearning/computer_vision/Abnormal-Prediction-In-Chest-X-Ray/data/preprocessed_2classes_aug_non_negative/test/labels.cache... 328 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 328/328 823.8Kit/s 0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 5044.1¬±1080.4 MB/s, size: 100.1 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/minhquana/workspace/project_DeepLearning/computer_vision/Abnormal-Prediction-In-Chest-X-Ray/data/preprocessed_2classes_aug_non_negative/test/labels.cache... 328 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 328/328 823.8Kit/s 0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 3.1it/s 6.7s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 3.1it/s 6.7s\n",
      "                   all        328        519      0.852      0.928      0.931      0.491\n",
      "Speed: 2.3ms preprocess, 15.4ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1m/home/minhquana/workspace/project_DeepLearning/computer_vision/Abnormal-Prediction-In-Chest-X-Ray/runs/detect/val11\u001b[0m\n",
      "                   all        328        519      0.852      0.928      0.931      0.491\n",
      "Speed: 2.3ms preprocess, 15.4ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1m/home/minhquana/workspace/project_DeepLearning/computer_vision/Abnormal-Prediction-In-Chest-X-Ray/runs/detect/val11\u001b[0m\n",
      "  mAP50:       0.9310\n",
      "  mAP50-95:    0.4911\n",
      "  Precision:   0.8518\n",
      "  Recall:      0.9281\n",
      "\n",
      "Evaluating: Hard Augmented\n",
      "Description: Light + Shear + Perspective + Mosaic + Mixup + Copy-Paste\n",
      "--------------------------------------------------------------------------------\n",
      "Dataset: preprocessed_2classes_aug_non_negative (with histogram_eq)\n",
      "Ultralytics 8.3.226 üöÄ Python-3.12.3 torch-2.9.0+cu128 CUDA:0 (NVIDIA GeForce RTX 3060, 11906MiB)\n",
      "  mAP50:       0.9310\n",
      "  mAP50-95:    0.4911\n",
      "  Precision:   0.8518\n",
      "  Recall:      0.9281\n",
      "\n",
      "Evaluating: Hard Augmented\n",
      "Description: Light + Shear + Perspective + Mosaic + Mixup + Copy-Paste\n",
      "--------------------------------------------------------------------------------\n",
      "Dataset: preprocessed_2classes_aug_non_negative (with histogram_eq)\n",
      "Ultralytics 8.3.226 üöÄ Python-3.12.3 torch-2.9.0+cu128 CUDA:0 (NVIDIA GeForce RTX 3060, 11906MiB)\n",
      "YOLO11s summary (fused): 100 layers, 9,413,574 parameters, 0 gradients, 21.3 GFLOPs\n",
      "YOLO11s summary (fused): 100 layers, 9,413,574 parameters, 0 gradients, 21.3 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 4667.0¬±1321.1 MB/s, size: 95.2 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/minhquana/workspace/project_DeepLearning/computer_vision/Abnormal-Prediction-In-Chest-X-Ray/data/preprocessed_2classes_aug_non_negative/test/labels.cache... 328 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 328/328 1.2Mit/s 0.0s0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 4667.0¬±1321.1 MB/s, size: 95.2 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/minhquana/workspace/project_DeepLearning/computer_vision/Abnormal-Prediction-In-Chest-X-Ray/data/preprocessed_2classes_aug_non_negative/test/labels.cache... 328 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 328/328 1.2Mit/s 0.0s0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 3.2it/s 6.7s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 3.2it/s 6.7s\n",
      "                   all        328        519      0.912      0.905      0.942      0.503\n",
      "Speed: 2.4ms preprocess, 15.4ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1m/home/minhquana/workspace/project_DeepLearning/computer_vision/Abnormal-Prediction-In-Chest-X-Ray/runs/detect/val12\u001b[0m\n",
      "                   all        328        519      0.912      0.905      0.942      0.503\n",
      "Speed: 2.4ms preprocess, 15.4ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1m/home/minhquana/workspace/project_DeepLearning/computer_vision/Abnormal-Prediction-In-Chest-X-Ray/runs/detect/val12\u001b[0m\n",
      "  mAP50:       0.9418\n",
      "  mAP50-95:    0.5029\n",
      "  Precision:   0.9117\n",
      "  Recall:      0.9055\n",
      "\n",
      "================================================================================\n",
      "‚úì All models evaluated successfully!\n",
      "================================================================================\n",
      "  mAP50:       0.9418\n",
      "  mAP50-95:    0.5029\n",
      "  Precision:   0.9117\n",
      "  Recall:      0.9055\n",
      "\n",
      "================================================================================\n",
      "‚úì All models evaluated successfully!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Evaluate all models\n",
    "results = {}\n",
    "\n",
    "print(\"Evaluating Models on Respective Test Datasets\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for name, config in model_configs.items():\n",
    "    print(f\"\\nEvaluating: {name}\")\n",
    "    print(f\"Description: {config['description']}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # Select correct dataset for each model\n",
    "    if name == 'Baseline':\n",
    "        eval_data_yaml = str(baseline_data_yaml)\n",
    "        dataset_name = \"baseline_2classes (raw, no preprocessing)\"\n",
    "    else:\n",
    "        eval_data_yaml = str(preprocessed_data_yaml)\n",
    "        dataset_name = \"preprocessed_2classes_aug_non_negative (with histogram_eq)\"\n",
    "    \n",
    "    print(f\"Dataset: {dataset_name}\")\n",
    "    \n",
    "    # Load model\n",
    "    model = YOLO(str(config['path']))\n",
    "    \n",
    "    # Run validation on test set\n",
    "    metrics = model.val(data=eval_data_yaml, split='test', verbose=False)\n",
    "    \n",
    "    # Extract metrics\n",
    "    results_dict = metrics.results_dict\n",
    "    results[name] = {\n",
    "        'mAP50': results_dict.get('metrics/mAP50(B)', 0),\n",
    "        'mAP50-95': results_dict.get('metrics/mAP50-95(B)', 0),\n",
    "        'Precision': results_dict.get('metrics/precision(B)', 0),\n",
    "        'Recall': results_dict.get('metrics/recall(B)', 0),\n",
    "        'color': config['color'],\n",
    "        'dataset': dataset_name\n",
    "    }\n",
    "    \n",
    "    print(f\"  mAP50:       {results[name]['mAP50']:.4f}\")\n",
    "    print(f\"  mAP50-95:    {results[name]['mAP50-95']:.4f}\")\n",
    "    print(f\"  Precision:   {results[name]['Precision']:.4f}\")\n",
    "    print(f\"  Recall:      {results[name]['Recall']:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"‚úì All models evaluated successfully!\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95184f8",
   "metadata": {},
   "source": [
    "## Section 5: Comparison Metrics Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b856661d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparison Metrics Table\n",
      "================================================================================\n",
      "\n",
      "Evaluation Datasets per Model:\n",
      "--------------------------------------------------------------------------------\n",
      "  Baseline            : baseline_2classes (raw, no preprocessing)\n",
      "  Light Augmented     : preprocessed_2classes_aug_non_negative (with histogram_eq)\n",
      "  Hard Augmented      : preprocessed_2classes_aug_non_negative (with histogram_eq)\n",
      "\n",
      "Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "                    mAP50  mAP50-95 Precision    Recall\n",
      "Baseline         0.903369  0.456683  0.842646  0.882642\n",
      "Light Augmented  0.931034  0.491081  0.851754  0.928145\n",
      "Hard Augmented    0.94179  0.502943  0.911658  0.905483\n",
      "================================================================================\n",
      "\n",
      "\n",
      "Improvement Analysis (vs Baseline)\n",
      "================================================================================\n",
      "\n",
      "Light Augmented:\n",
      "  (Evaluated on: preprocessed_2classes_aug_non_negative (with histogram_eq))\n",
      "  Note: So s√°nh n√†y c√≥ th·ªÉ kh√¥ng ho√†n to√†n c√¥ng b·∫±ng do kh√°c dataset\n",
      "  mAP50          : 0.9310 (‚Üë +3.06%)\n",
      "  mAP50-95       : 0.4911 (‚Üë +7.53%)\n",
      "  Precision      : 0.8518 (‚Üë +1.08%)\n",
      "  Recall         : 0.9281 (‚Üë +5.16%)\n",
      "\n",
      "Hard Augmented:\n",
      "  (Evaluated on: preprocessed_2classes_aug_non_negative (with histogram_eq))\n",
      "  Note: So s√°nh n√†y c√≥ th·ªÉ kh√¥ng ho√†n to√†n c√¥ng b·∫±ng do kh√°c dataset\n",
      "  mAP50          : 0.9418 (‚Üë +4.25%)\n",
      "  mAP50-95       : 0.5029 (‚Üë +10.13%)\n",
      "  Precision      : 0.9117 (‚Üë +8.19%)\n",
      "  Recall         : 0.9055 (‚Üë +2.59%)\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Create comparison dataframe\n",
    "df_results = pd.DataFrame(results).T\n",
    "dataset_info = df_results[['dataset']]\n",
    "df_results = df_results.drop(columns=['color', 'dataset'])\n",
    "\n",
    "print(\"\\nComparison Metrics Table\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nEvaluation Datasets per Model:\")\n",
    "print(\"-\" * 80)\n",
    "for name, dataset in dataset_info['dataset'].items():\n",
    "    print(f\"  {name:20s}: {dataset}\")\n",
    "\n",
    "print(\"\\nMetrics:\")\n",
    "print(\"-\" * 80)\n",
    "print(df_results.to_string())\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Calculate improvements\n",
    "print(\"\\n\\nImprovement Analysis (vs Baseline)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "baseline_metrics = results['Baseline']\n",
    "\n",
    "for name in ['Light Augmented', 'Hard Augmented']:\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  (Evaluated on: {results[name]['dataset']})\")\n",
    "    print(f\"  Note: So s√°nh n√†y c√≥ th·ªÉ kh√¥ng ho√†n to√†n c√¥ng b·∫±ng do kh√°c dataset\")\n",
    "    for metric in ['mAP50', 'mAP50-95', 'Precision', 'Recall']:\n",
    "        baseline_val = baseline_metrics[metric]\n",
    "        current_val = results[name][metric]\n",
    "        \n",
    "        if baseline_val > 0:\n",
    "            improvement = ((current_val - baseline_val) / baseline_val) * 100\n",
    "            symbol = '‚Üë' if improvement > 0 else '‚Üì'\n",
    "            print(f\"  {metric:15s}: {current_val:.4f} ({symbol} {abs(improvement):+.2f}%)\")\n",
    "        else:\n",
    "            print(f\"  {metric:15s}: {current_val:.4f} (N/A - baseline is 0)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39a0da3",
   "metadata": {},
   "source": [
    "## Section 6: Visualization - Bar Charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfb7149",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_110125/3901160943.py:35: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_xticklabels(model_names, rotation=15, ha='right')\n",
      "/tmp/ipykernel_110125/3901160943.py:35: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_xticklabels(model_names, rotation=15, ha='right')\n",
      "/tmp/ipykernel_110125/3901160943.py:35: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_xticklabels(model_names, rotation=15, ha='right')\n",
      "/tmp/ipykernel_110125/3901160943.py:35: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_xticklabels(model_names, rotation=15, ha='right')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x1200 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Bar chart saved to: docs/model_comparison_bars.png\n"
     ]
    }
   ],
   "source": [
    "# Create bar chart comparison\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('Model Comparison: Baseline vs Light Augmented vs Hard Augmented', \n",
    "             fontsize=16, fontweight='bold', y=0.995)\n",
    "\n",
    "metrics_to_plot = ['mAP50', 'mAP50-95', 'Precision', 'Recall']\n",
    "axes_flat = axes.flatten()\n",
    "\n",
    "for idx, metric in enumerate(metrics_to_plot):\n",
    "    ax = axes_flat[idx]\n",
    "    \n",
    "    # Extract data\n",
    "    model_names = list(results.keys())\n",
    "    values = [results[name][metric] for name in model_names]\n",
    "    colors = [results[name]['color'] for name in model_names]\n",
    "    \n",
    "    # Create bar chart\n",
    "    bars = ax.bar(model_names, values, color=colors, alpha=0.8, edgecolor='black', linewidth=1.5)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.4f}',\n",
    "                ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "    \n",
    "    # Styling\n",
    "    ax.set_title(f'{metric}', fontsize=14, fontweight='bold', pad=10)\n",
    "    ax.set_ylabel('Score', fontsize=12)\n",
    "    ax.set_ylim(0, max(values) * 1.15)\n",
    "    ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "    ax.set_axisbelow(True)\n",
    "    \n",
    "    # Rotate x-axis labels\n",
    "    ax.set_xticklabels(model_names, rotation=15, ha='right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../docs/model_comparison_bars.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Bar chart saved to: docs/model_comparison_bars.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f748b9b",
   "metadata": {},
   "source": [
    "## Section 7: Visualization - Radar Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c262b1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Radar chart saved to: docs/model_comparison_radar.png\n"
     ]
    }
   ],
   "source": [
    "# Create radar chart\n",
    "from math import pi\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 12), subplot_kw=dict(projection='polar'))\n",
    "\n",
    "# Define metrics for radar chart\n",
    "categories = ['mAP50', 'mAP50-95', 'Precision', 'Recall']\n",
    "N = len(categories)\n",
    "\n",
    "# Compute angle for each axis\n",
    "angles = [n / float(N) * 2 * pi for n in range(N)]\n",
    "angles += angles[:1]  # Complete the circle\n",
    "\n",
    "# Plot each model\n",
    "for name in results.keys():\n",
    "    values = [results[name][metric] for metric in categories]\n",
    "    values += values[:1]  # Complete the circle\n",
    "    \n",
    "    ax.plot(angles, values, 'o-', linewidth=2.5, label=name, \n",
    "            color=results[name]['color'], markersize=8)\n",
    "    ax.fill(angles, values, alpha=0.15, color=results[name]['color'])\n",
    "\n",
    "# Fix axis to go in the right order\n",
    "ax.set_xticks(angles[:-1])\n",
    "ax.set_xticklabels(categories, fontsize=12, fontweight='bold')\n",
    "\n",
    "# Set y-axis limits\n",
    "ax.set_ylim(0, 1.0)\n",
    "ax.set_yticks([0.2, 0.4, 0.6, 0.8, 1.0])\n",
    "ax.set_yticklabels(['0.2', '0.4', '0.6', '0.8', '1.0'], fontsize=10)\n",
    "\n",
    "# Add legend\n",
    "ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1), fontsize=11)\n",
    "\n",
    "# Add title\n",
    "plt.title('Model Performance Radar Chart\\nBaseline vs Light Augmented vs Hard Augmented',\n",
    "          fontsize=14, fontweight='bold', pad=30)\n",
    "\n",
    "# Add grid\n",
    "ax.grid(True, linestyle='--', alpha=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../docs/model_comparison_radar.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Radar chart saved to: docs/model_comparison_radar.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfe3cf0",
   "metadata": {},
   "source": [
    "## Section 8: Improvement Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c659c8ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Heatmap saved to: docs/model_comparison_heatmap.png\n"
     ]
    }
   ],
   "source": [
    "# Calculate percentage improvements relative to baseline\n",
    "improvement_data = []\n",
    "\n",
    "baseline_metrics = results['Baseline']\n",
    "\n",
    "for name in ['Baseline', 'Light Augmented', 'Hard Augmented']:\n",
    "    row = []\n",
    "    for metric in ['mAP50', 'mAP50-95', 'Precision', 'Recall']:\n",
    "        baseline_val = baseline_metrics[metric]\n",
    "        current_val = results[name][metric]\n",
    "        \n",
    "        if baseline_val > 0:\n",
    "            improvement = ((current_val - baseline_val) / baseline_val) * 100\n",
    "        else:\n",
    "            improvement = 0\n",
    "        \n",
    "        row.append(improvement)\n",
    "    \n",
    "    improvement_data.append(row)\n",
    "\n",
    "# Create dataframe\n",
    "df_improvement = pd.DataFrame(\n",
    "    improvement_data,\n",
    "    index=['Baseline', 'Light Augmented', 'Hard Augmented'],\n",
    "    columns=['mAP50', 'mAP50-95', 'Precision', 'Recall']\n",
    ")\n",
    "\n",
    "# Create heatmap\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "sns.heatmap(df_improvement, annot=True, fmt='.2f', cmap='RdYlGn', center=0,\n",
    "            cbar_kws={'label': 'Improvement (%)'}, linewidths=2, linecolor='white',\n",
    "            ax=ax, vmin=-10, vmax=50)\n",
    "\n",
    "ax.set_title('Improvement Heatmap (% change vs Baseline)', \n",
    "             fontsize=14, fontweight='bold', pad=15)\n",
    "ax.set_xlabel('Metrics', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Model', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Rotate labels\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=0, ha='center')\n",
    "ax.set_yticklabels(ax.get_yticklabels(), rotation=0, ha='right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../docs/model_comparison_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Heatmap saved to: docs/model_comparison_heatmap.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c0f444",
   "metadata": {},
   "source": [
    "## Section 9: Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2777f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SUMMARY STATISTICS\n",
      "================================================================================\n",
      "\n",
      "‚ö†Ô∏è  IMPORTANT NOTES:\n",
      "--------------------------------------------------------------------------------\n",
      "  ‚Ä¢ Baseline ƒë∆∞·ª£c evaluate tr√™n: baseline_2classes (raw, ch∆∞a preprocessing)\n",
      "  ‚Ä¢ Light & Hard Augmented ƒë∆∞·ª£c evaluate tr√™n: preprocessed_2classes_aug_non_negative\n",
      "  ‚Ä¢ Do v·∫≠y, so s√°nh improvement c√≥ th·ªÉ kh√¥ng ho√†n to√†n c√¥ng b·∫±ng\n",
      "  ‚Ä¢ ƒê·ªÉ so s√°nh c√¥ng b·∫±ng, n√™n c≈©ng evaluate Light/Hard tr√™n baseline_2classes\n",
      "\n",
      "Best Model per Metric:\n",
      "--------------------------------------------------------------------------------\n",
      "  mAP50          : Hard Augmented       (0.9418)\n",
      "                   ‚Üí Evaluated on: preprocessed_2classes_aug_non_negative (with histogram_eq)\n",
      "  mAP50-95       : Hard Augmented       (0.5029)\n",
      "                   ‚Üí Evaluated on: preprocessed_2classes_aug_non_negative (with histogram_eq)\n",
      "  Precision      : Hard Augmented       (0.9117)\n",
      "                   ‚Üí Evaluated on: preprocessed_2classes_aug_non_negative (with histogram_eq)\n",
      "  Recall         : Light Augmented      (0.9281)\n",
      "                   ‚Üí Evaluated on: preprocessed_2classes_aug_non_negative (with histogram_eq)\n",
      "\n",
      "Average Improvement vs Baseline:\n",
      "--------------------------------------------------------------------------------\n",
      "  Light Augmented     : ‚Üë 4.21%\n",
      "  (‚ö†Ô∏è  So s√°nh tr√™n kh√°c dataset, c√≥ th·ªÉ kh√¥ng ch√≠nh x√°c)\n",
      "  Hard Augmented      : ‚Üë 6.29%\n",
      "  (‚ö†Ô∏è  So s√°nh tr√™n kh√°c dataset, c√≥ th·ªÉ kh√¥ng ch√≠nh x√°c)\n",
      "\n",
      "================================================================================\n",
      "RECOMMENDATIONS\n",
      "================================================================================\n",
      "\n",
      "‚úì Best Model (mAP50-95): Hard Augmented\n",
      "  Score: 0.5029\n",
      "  Dataset: preprocessed_2classes_aug_non_negative (with histogram_eq)\n",
      "  Description: Light + Shear + Perspective + Mosaic + Mixup + Copy-Paste\n",
      "\n",
      "Key Findings:\n",
      "--------------------------------------------------------------------------------\n",
      "  1. Baseline (raw dataset) provides baseline performance\n",
      "  2. Light Augmented (preprocessed) helps with histogram equalization\n",
      "  3. Hard Augmented (preprocessed) th√™m aggressive augmentation\n",
      "\n",
      "  ‚ö†Ô∏è  IMPORTANT:\n",
      "  ƒê·ªÉ so s√°nh c√¥ng b·∫±ng, h√£y t·∫°o m·ªôt evaluation tr√™n c√πng dataset!\n",
      "  ‚Üí Evaluate Light/Hard Augmented tr√™n baseline_2classes ƒë·ªÉ th·∫•y\n",
      "    hi·ªáu ·ª©ng th·ª±c s·ª± c·ªßa augmentation (ƒë·ªôc l·∫≠p v·ªõi preprocessing)\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SUMMARY STATISTICS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è  IMPORTANT NOTES:\")\n",
    "print(\"-\" * 80)\n",
    "print(\"  ‚Ä¢ Baseline ƒë∆∞·ª£c evaluate tr√™n: baseline_2classes (raw, ch∆∞a preprocessing)\")\n",
    "print(\"  ‚Ä¢ Light & Hard Augmented ƒë∆∞·ª£c evaluate tr√™n: preprocessed_2classes_aug_non_negative\")\n",
    "print(\"  ‚Ä¢ Do v·∫≠y, so s√°nh improvement c√≥ th·ªÉ kh√¥ng ho√†n to√†n c√¥ng b·∫±ng\")\n",
    "print(\"  ‚Ä¢ ƒê·ªÉ so s√°nh c√¥ng b·∫±ng, n√™n c≈©ng evaluate Light/Hard tr√™n baseline_2classes\")\n",
    "\n",
    "# Find best model for each metric\n",
    "print(\"\\nBest Model per Metric:\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for metric in ['mAP50', 'mAP50-95', 'Precision', 'Recall']:\n",
    "    best_model = max(results.keys(), key=lambda x: results[x][metric])\n",
    "    best_value = results[best_model][metric]\n",
    "    dataset = results[best_model]['dataset']\n",
    "    print(f\"  {metric:15s}: {best_model:20s} ({best_value:.4f})\")\n",
    "    print(f\"                   ‚Üí Evaluated on: {dataset}\")\n",
    "\n",
    "# Calculate average improvements\n",
    "print(\"\\nAverage Improvement vs Baseline:\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for name in ['Light Augmented', 'Hard Augmented']:\n",
    "    improvements = []\n",
    "    for metric in ['mAP50', 'mAP50-95', 'Precision', 'Recall']:\n",
    "        baseline_val = baseline_metrics[metric]\n",
    "        current_val = results[name][metric]\n",
    "        if baseline_val > 0:\n",
    "            improvement = ((current_val - baseline_val) / baseline_val) * 100\n",
    "            improvements.append(improvement)\n",
    "    \n",
    "    avg_improvement = np.mean(improvements)\n",
    "    symbol = '‚Üë' if avg_improvement > 0 else '‚Üì'\n",
    "    print(f\"  {name:20s}: {symbol} {abs(avg_improvement):.2f}%\")\n",
    "    print(f\"  (‚ö†Ô∏è  So s√°nh tr√™n kh√°c dataset, c√≥ th·ªÉ kh√¥ng ch√≠nh x√°c)\")\n",
    "\n",
    "# Recommendations\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"RECOMMENDATIONS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Find overall best model (based on mAP50-95)\n",
    "best_overall = max(results.keys(), key=lambda x: results[x]['mAP50-95'])\n",
    "print(f\"\\n‚úì Best Model (mAP50-95): {best_overall}\")\n",
    "print(f\"  Score: {results[best_overall]['mAP50-95']:.4f}\")\n",
    "print(f\"  Dataset: {results[best_overall]['dataset']}\")\n",
    "print(f\"  Description: {model_configs[best_overall]['description']}\")\n",
    "\n",
    "# Analysis\n",
    "print(\"\\nKey Findings:\")\n",
    "print(\"-\" * 80)\n",
    "print(\"  1. Baseline (raw dataset) provides baseline performance\")\n",
    "print(\"  2. Light Augmented (preprocessed) helps with histogram equalization\")\n",
    "print(\"  3. Hard Augmented (preprocessed) th√™m aggressive augmentation\")\n",
    "print(\"\\n  ‚ö†Ô∏è  IMPORTANT:\")\n",
    "print(\"  ƒê·ªÉ so s√°nh c√¥ng b·∫±ng, h√£y t·∫°o m·ªôt evaluation tr√™n c√πng dataset!\")\n",
    "print(\"  ‚Üí Evaluate Light/Hard Augmented tr√™n baseline_2classes ƒë·ªÉ th·∫•y\")\n",
    "print(\"    hi·ªáu ·ª©ng th·ª±c s·ª± c·ªßa augmentation (ƒë·ªôc l·∫≠p v·ªõi preprocessing)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0346dfec",
   "metadata": {},
   "source": [
    "## Section 11: Fair Comparison - All Models on Baseline Dataset (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683193f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "FAIR COMPARISON: All Models on Baseline Dataset\n",
      "================================================================================\n",
      "\n",
      "Evaluating all models on baseline_2classes (raw, no preprocessing)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Evaluating: Baseline\n",
      "Ultralytics 8.3.226 üöÄ Python-3.12.3 torch-2.9.0+cu128 CUDA:0 (NVIDIA GeForce RTX 3060, 11906MiB)\n",
      "YOLO11s summary (fused): 100 layers, 9,413,574 parameters, 0 gradients, 21.3 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 4466.6¬±1256.2 MB/s, size: 71.9 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/minhquana/workspace/project_DeepLearning/computer_vision/Abnormal-Prediction-In-Chest-X-Ray/data/baseline_2classes/test/labels.cache... 328 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 328/328 846.1Kit/s 0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 3.3it/s 6.4s0.3s\n",
      "                   all        328        519      0.843      0.883      0.903      0.457\n",
      "Speed: 2.0ms preprocess, 14.7ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1m/home/minhquana/workspace/project_DeepLearning/computer_vision/Abnormal-Prediction-In-Chest-X-Ray/runs/detect/val13\u001b[0m\n",
      "  mAP50:       0.9034\n",
      "  mAP50-95:    0.4567\n",
      "  Precision:   0.8426\n",
      "  Recall:      0.8826\n",
      "\n",
      "Evaluating: Light Augmented\n",
      "Ultralytics 8.3.226 üöÄ Python-3.12.3 torch-2.9.0+cu128 CUDA:0 (NVIDIA GeForce RTX 3060, 11906MiB)\n",
      "YOLO11s summary (fused): 100 layers, 9,413,574 parameters, 0 gradients, 21.3 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 3399.8¬±880.3 MB/s, size: 77.6 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/minhquana/workspace/project_DeepLearning/computer_vision/Abnormal-Prediction-In-Chest-X-Ray/data/baseline_2classes/test/labels.cache... 328 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 328/328 929.5Kit/s 0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 3.3it/s 6.4s0.3s\n",
      "                   all        328        519      0.821      0.827      0.865      0.443\n",
      "Speed: 2.0ms preprocess, 14.6ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1m/home/minhquana/workspace/project_DeepLearning/computer_vision/Abnormal-Prediction-In-Chest-X-Ray/runs/detect/val14\u001b[0m\n",
      "  mAP50:       0.8647\n",
      "  mAP50-95:    0.4434\n",
      "  Precision:   0.8210\n",
      "  Recall:      0.8272\n",
      "\n",
      "Evaluating: Hard Augmented\n",
      "Ultralytics 8.3.226 üöÄ Python-3.12.3 torch-2.9.0+cu128 CUDA:0 (NVIDIA GeForce RTX 3060, 11906MiB)\n",
      "YOLO11s summary (fused): 100 layers, 9,413,574 parameters, 0 gradients, 21.3 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 3137.4¬±1811.1 MB/s, size: 82.1 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/minhquana/workspace/project_DeepLearning/computer_vision/Abnormal-Prediction-In-Chest-X-Ray/data/baseline_2classes/test/labels.cache... 328 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 328/328 1.3Mit/s 0.0s0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 3.3it/s 6.3s0.3s\n",
      "                   all        328        519      0.894      0.917      0.935      0.476\n",
      "Speed: 2.0ms preprocess, 14.3ms inference, 0.0ms loss, 0.3ms postprocess per image\n",
      "Results saved to \u001b[1m/home/minhquana/workspace/project_DeepLearning/computer_vision/Abnormal-Prediction-In-Chest-X-Ray/runs/detect/val15\u001b[0m\n",
      "  mAP50:       0.9349\n",
      "  mAP50-95:    0.4755\n",
      "  Precision:   0.8943\n",
      "  Recall:      0.9170\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Fair Comparison Metrics Table (All on baseline_2classes)\n",
      "================================================================================\n",
      "                    mAP50  mAP50-95 Precision    Recall\n",
      "Baseline         0.903369  0.456683  0.842646  0.882642\n",
      "Light Augmented  0.864699  0.443402  0.821036  0.827162\n",
      "Hard Augmented    0.93494  0.475531  0.894328  0.917033\n",
      "================================================================================\n",
      "\n",
      "\n",
      "Fair Improvement Analysis (vs Baseline - same dataset)\n",
      "================================================================================\n",
      "\n",
      "Light Augmented:\n",
      "  mAP50          : 0.8647 (‚Üì +4.28%)\n",
      "  mAP50-95       : 0.4434 (‚Üì +2.91%)\n",
      "  Precision      : 0.8210 (‚Üì +2.56%)\n",
      "  Recall         : 0.8272 (‚Üì +6.29%)\n",
      "\n",
      "Hard Augmented:\n",
      "  mAP50          : 0.9349 (‚Üë +3.49%)\n",
      "  mAP50-95       : 0.4755 (‚Üë +4.13%)\n",
      "  Precision      : 0.8943 (‚Üë +6.13%)\n",
      "  Recall         : 0.9170 (‚Üë +3.90%)\n",
      "\n",
      "================================================================================\n",
      "‚úì Fair comparison complete - hi·ªáu ·ª©ng th·ª±c s·ª± c·ªßa augmentation tr√™n raw data\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Fair comparison: Evaluate all models on the same baseline dataset\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"FAIR COMPARISON: All Models on Baseline Dataset\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "results_fair = {}\n",
    "\n",
    "print(\"\\nEvaluating all models on baseline_2classes (raw, no preprocessing)\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for name, config in model_configs.items():\n",
    "    print(f\"\\nEvaluating: {name}\")\n",
    "    \n",
    "    # Load model\n",
    "    model = YOLO(str(config['path']))\n",
    "    \n",
    "    # Run validation on baseline test set\n",
    "    metrics = model.val(data=str(baseline_data_yaml), split='test', verbose=False)\n",
    "    \n",
    "    # Extract metrics\n",
    "    results_dict = metrics.results_dict\n",
    "    results_fair[name] = {\n",
    "        'mAP50': results_dict.get('metrics/mAP50(B)', 0),\n",
    "        'mAP50-95': results_dict.get('metrics/mAP50-95(B)', 0),\n",
    "        'Precision': results_dict.get('metrics/precision(B)', 0),\n",
    "        'Recall': results_dict.get('metrics/recall(B)', 0),\n",
    "        'color': config['color']\n",
    "    }\n",
    "    \n",
    "    print(f\"  mAP50:       {results_fair[name]['mAP50']:.4f}\")\n",
    "    print(f\"  mAP50-95:    {results_fair[name]['mAP50-95']:.4f}\")\n",
    "    print(f\"  Precision:   {results_fair[name]['Precision']:.4f}\")\n",
    "    print(f\"  Recall:      {results_fair[name]['Recall']:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "\n",
    "# Create comparison dataframe for fair comparison\n",
    "df_results_fair = pd.DataFrame(results_fair).T\n",
    "df_results_fair = df_results_fair.drop(columns=['color'])\n",
    "\n",
    "print(\"\\nFair Comparison Metrics Table (All on baseline_2classes)\")\n",
    "print(\"=\" * 80)\n",
    "print(df_results_fair.to_string())\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Calculate improvements for fair comparison\n",
    "print(\"\\n\\nFair Improvement Analysis (vs Baseline - same dataset)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "baseline_metrics_fair = results_fair['Baseline']\n",
    "\n",
    "for name in ['Light Augmented', 'Hard Augmented']:\n",
    "    print(f\"\\n{name}:\")\n",
    "    for metric in ['mAP50', 'mAP50-95', 'Precision', 'Recall']:\n",
    "        baseline_val = baseline_metrics_fair[metric]\n",
    "        current_val = results_fair[name][metric]\n",
    "        \n",
    "        if baseline_val > 0:\n",
    "            improvement = ((current_val - baseline_val) / baseline_val) * 100\n",
    "            symbol = '‚Üë' if improvement > 0 else '‚Üì'\n",
    "            print(f\"  {metric:15s}: {current_val:.4f} ({symbol} {abs(improvement):+.2f}%)\")\n",
    "        else:\n",
    "            print(f\"  {metric:15s}: {current_val:.4f} (N/A - baseline is 0)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"‚úì Fair comparison complete - hi·ªáu ·ª©ng th·ª±c s·ª± c·ªßa augmentation tr√™n raw data\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0684ff",
   "metadata": {},
   "source": [
    "## Section 12: Fair Comparison - Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c7b157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bar chart comparison for fair results\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('Fair Model Comparison (All on Baseline Dataset)', \n",
    "             fontsize=16, fontweight='bold', y=0.995)\n",
    "\n",
    "metrics_to_plot = ['mAP50', 'mAP50-95', 'Precision', 'Recall']\n",
    "axes_flat = axes.flatten()\n",
    "\n",
    "for idx, metric in enumerate(metrics_to_plot):\n",
    "    ax = axes_flat[idx]\n",
    "    \n",
    "    # Extract data\n",
    "    model_names = list(results_fair.keys())\n",
    "    values = [results_fair[name][metric] for name in model_names]\n",
    "    colors = [results_fair[name]['color'] for name in model_names]\n",
    "    \n",
    "    # Create bar chart\n",
    "    bars = ax.bar(model_names, values, color=colors, alpha=0.8, edgecolor='black', linewidth=1.5)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.4f}',\n",
    "                ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "    \n",
    "    # Styling\n",
    "    ax.set_title(f'{metric}', fontsize=14, fontweight='bold', pad=10)\n",
    "    ax.set_ylabel('Score', fontsize=12)\n",
    "    ax.set_ylim(0, max(values) * 1.15)\n",
    "    ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "    ax.set_axisbelow(True)\n",
    "    \n",
    "    # Rotate x-axis labels\n",
    "    ax.set_xticklabels(model_names, rotation=15, ha='right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../docs/model_comparison_bars_fair.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Fair comparison bar chart saved to: docs/model_comparison_bars_fair.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514410f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create radar chart for fair comparison\n",
    "from math import pi\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 12), subplot_kw=dict(projection='polar'))\n",
    "\n",
    "# Define metrics for radar chart\n",
    "categories = ['mAP50', 'mAP50-95', 'Precision', 'Recall']\n",
    "N = len(categories)\n",
    "\n",
    "# Compute angle for each axis\n",
    "angles = [n / float(N) * 2 * pi for n in range(N)]\n",
    "angles += angles[:1]  # Complete the circle\n",
    "\n",
    "# Plot each model\n",
    "for name in results_fair.keys():\n",
    "    values = [results_fair[name][metric] for metric in categories]\n",
    "    values += values[:1]  # Complete the circle\n",
    "    \n",
    "    ax.plot(angles, values, 'o-', linewidth=2.5, label=name, \n",
    "            color=results_fair[name]['color'], markersize=8)\n",
    "    ax.fill(angles, values, alpha=0.15, color=results_fair[name]['color'])\n",
    "\n",
    "# Fix axis to go in the right order\n",
    "ax.set_xticks(angles[:-1])\n",
    "ax.set_xticklabels(categories, fontsize=12, fontweight='bold')\n",
    "\n",
    "# Set y-axis limits\n",
    "ax.set_ylim(0, 1.0)\n",
    "ax.set_yticks([0.2, 0.4, 0.6, 0.8, 1.0])\n",
    "ax.set_yticklabels(['0.2', '0.4', '0.6', '0.8', '1.0'], fontsize=10)\n",
    "\n",
    "# Add legend\n",
    "ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1), fontsize=11)\n",
    "\n",
    "# Add title\n",
    "plt.title('Fair Model Performance Radar Chart (All on Baseline Dataset)',\n",
    "          fontsize=14, fontweight='bold', pad=30)\n",
    "\n",
    "# Add grid\n",
    "ax.grid(True, linestyle='--', alpha=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../docs/model_comparison_radar_fair.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Fair comparison radar chart saved to: docs/model_comparison_radar_fair.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c0b10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate percentage improvements for fair comparison\n",
    "improvement_data_fair = []\n",
    "\n",
    "baseline_metrics_fair = results_fair['Baseline']\n",
    "\n",
    "for name in ['Baseline', 'Light Augmented', 'Hard Augmented']:\n",
    "    row = []\n",
    "    for metric in ['mAP50', 'mAP50-95', 'Precision', 'Recall']:\n",
    "        baseline_val = baseline_metrics_fair[metric]\n",
    "        current_val = results_fair[name][metric]\n",
    "        \n",
    "        if baseline_val > 0:\n",
    "            improvement = ((current_val - baseline_val) / baseline_val) * 100\n",
    "        else:\n",
    "            improvement = 0\n",
    "        \n",
    "        row.append(improvement)\n",
    "    \n",
    "    improvement_data_fair.append(row)\n",
    "\n",
    "# Create dataframe\n",
    "df_improvement_fair = pd.DataFrame(\n",
    "    improvement_data_fair,\n",
    "    index=['Baseline', 'Light Augmented', 'Hard Augmented'],\n",
    "    columns=['mAP50', 'mAP50-95', 'Precision', 'Recall']\n",
    ")\n",
    "\n",
    "# Create heatmap\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "sns.heatmap(df_improvement_fair, annot=True, fmt='.2f', cmap='RdYlGn', center=0,\n",
    "            cbar_kws={'label': 'Improvement (%)'}, linewidths=2, linecolor='white',\n",
    "            ax=ax, vmin=-10, vmax=10)\n",
    "\n",
    "ax.set_title('Fair Improvement Heatmap (% change vs Baseline on same dataset)', \n",
    "             fontsize=14, fontweight='bold', pad=15)\n",
    "ax.set_xlabel('Metrics', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Model', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Rotate labels\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=0, ha='center')\n",
    "ax.set_yticklabels(ax.get_yticklabels(), rotation=0, ha='right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../docs/model_comparison_heatmap_fair.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Fair comparison heatmap saved to: docs/model_comparison_heatmap_fair.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d390bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Metrics saved to: ../docs/model_comparison_metrics.csv\n",
      "‚úì Improvements saved to: ../docs/model_comparison_improvements.csv\n",
      "\n",
      "‚úì All results exported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Export results to CSV\n",
    "output_dir = Path('../docs')\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Save comparison metrics\n",
    "df_results.to_csv(output_dir / 'model_comparison_metrics.csv')\n",
    "print(f\"‚úì Metrics saved to: {output_dir / 'model_comparison_metrics.csv'}\")\n",
    "\n",
    "# Save improvement percentages\n",
    "df_improvement.to_csv(output_dir / 'model_comparison_improvements.csv')\n",
    "print(f\"‚úì Improvements saved to: {output_dir / 'model_comparison_improvements.csv'}\")\n",
    "\n",
    "print(\"\\n‚úì All results exported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f880db6b",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Notebook n√†y ƒë√£:\n",
    "1. ‚úì Load 3 model weights (baseline, light_augmented, hard_augmented)\n",
    "2. ‚úì Evaluate tr√™n test set\n",
    "3. ‚úì So s√°nh metrics (mAP50, mAP50-95, Precision, Recall)\n",
    "4. ‚úì T·∫°o 3 lo·∫°i bi·ªÉu ƒë·ªì: Bar chart, Radar chart, Heatmap\n",
    "5. ‚úì Ph√¢n t√≠ch improvement v√† ƒë∆∞a ra recommendations\n",
    "6. ‚úì Th·ª±c hi·ªán so s√°nh c√¥ng b·∫±ng (Fair Comparison) tr√™n c√πng m·ªôt dataset v√† tr·ª±c quan h√≥a k·∫øt qu·∫£.\n",
    "7. ‚úì Export k·∫øt qu·∫£ ra CSV files\n",
    "\n",
    "**C√°c file output:**\n",
    "- `docs/model_comparison_bars.png` - Bar chart comparison\n",
    "- `docs/model_comparison_radar.png` - Radar chart comparison  \n",
    "- `docs/model_comparison_heatmap.png` - Improvement heatmap\n",
    "- `docs/model_comparison_bars_fair.png` - Fair comparison bar chart\n",
    "- `docs/model_comparison_radar_fair.png` - Fair comparison radar chart\n",
    "- `docs/model_comparison_heatmap_fair.png` - Fair comparison heatmap\n",
    "- `docs/model_comparison_metrics.csv` - Raw metrics\n",
    "- `docs/model_comparison_improvements.csv` - Improvement percentages"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Abnormal-prediction-in-chest-X-ray",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
