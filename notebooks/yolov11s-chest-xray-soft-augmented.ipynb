{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"41d1afce","cell_type":"markdown","source":"# YOLOv11s Fine-tuning for Chest X-ray Abnormality Detection\n","metadata":{}},{"id":"38d7bbfc","cell_type":"markdown","source":"## Section 1: Setup and Imports","metadata":{}},{"id":"74c92a5c","cell_type":"code","source":"!uv pip install -q roboflow ultralytics wandb tqdm pillow numpy ","metadata":{"execution":{"iopub.status.busy":"2025-11-11T23:40:38.749189Z","iopub.execute_input":"2025-11-11T23:40:38.749495Z","iopub.status.idle":"2025-11-11T23:41:00.129395Z","shell.execute_reply.started":"2025-11-11T23:40:38.749470Z","shell.execute_reply":"2025-11-11T23:41:00.128476Z"},"trusted":true},"outputs":[],"execution_count":1},{"id":"241ec81f-81de-4986-8ba4-b65445f68097","cell_type":"code","source":"!uv pip install --force-reinstall nvidia-cudnn-cu12==9.1.0.70","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:41:00.131260Z","iopub.execute_input":"2025-11-11T23:41:00.131631Z","iopub.status.idle":"2025-11-11T23:41:07.909388Z","shell.execute_reply.started":"2025-11-11T23:41:00.131603Z","shell.execute_reply":"2025-11-11T23:41:07.908491Z"}},"outputs":[{"name":"stdout","text":"\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n\u001b[2K\u001b[2mResolved \u001b[1m2 packages\u001b[0m \u001b[2min 108ms\u001b[0m\u001b[0m                                         \u001b[0m\n\u001b[2K\u001b[2mPrepared \u001b[1m2 packages\u001b[0m \u001b[2min 7.41s\u001b[0m\u001b[0m                                             \n\u001b[2mUninstalled \u001b[1m2 packages\u001b[0m \u001b[2min 2ms\u001b[0m\u001b[0m\n\u001b[2K\u001b[2mInstalled \u001b[1m2 packages\u001b[0m \u001b[2min 3ms\u001b[0m\u001b[0m.1.0.70                          \u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-cublas-cu12\u001b[0m\u001b[2m==12.4.5.8\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cublas-cu12\u001b[0m\u001b[2m==12.9.1.4\u001b[0m\n \u001b[33m~\u001b[39m \u001b[1mnvidia-cudnn-cu12\u001b[0m\u001b[2m==9.1.0.70\u001b[0m\n","output_type":"stream"}],"execution_count":2},{"id":"a5bf9ba0-182d-4763-b289-61bc33d0670b","cell_type":"code","source":"!uv pip uninstall albumentations","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:41:07.910560Z","iopub.execute_input":"2025-11-11T23:41:07.910833Z","iopub.status.idle":"2025-11-11T23:41:08.179230Z","shell.execute_reply.started":"2025-11-11T23:41:07.910799Z","shell.execute_reply":"2025-11-11T23:41:08.178442Z"}},"outputs":[{"name":"stdout","text":"\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n\u001b[2mUninstalled \u001b[1m1 package\u001b[0m \u001b[2min 140ms\u001b[0m\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1malbumentations\u001b[0m\u001b[2m==2.0.8\u001b[0m\n","output_type":"stream"}],"execution_count":3},{"id":"644a5e3b","cell_type":"code","source":"import os\nos.environ[\"ALBUMENTATIONS_DISABLE\"] = \"1\"\n# Import required libraries\nimport shutil\nfrom pathlib import Path\nimport yaml\n\nimport torch\nimport wandb\nfrom ultralytics import YOLO, settings\n\n# Import custom augmentation\nimport sys\nsys.path.insert(0, str(Path.cwd()))\n\nprint(\"‚úì Imports successful\")\nprint(f\"  PyTorch version: {torch.__version__}\")\nprint(f\"  CUDA available: {torch.cuda.is_available()}\")\nif torch.cuda.is_available():\n    print(f\"  GPU: {torch.cuda.get_device_name(0)}\")\n    print(f\"  GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:41:08.181548Z","iopub.execute_input":"2025-11-11T23:41:08.181818Z","iopub.status.idle":"2025-11-11T23:41:17.048053Z","shell.execute_reply.started":"2025-11-11T23:41:08.181794Z","shell.execute_reply":"2025-11-11T23:41:17.047421Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Creating new Ultralytics Settings v0.0.6 file ‚úÖ \nView Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\nUpdate Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n‚úì Imports successful\n  PyTorch version: 2.6.0+cu124\n  CUDA available: True\n  GPU: Tesla T4\n  GPU Memory: 15.8 GB\n","output_type":"stream"}],"execution_count":4},{"id":"062737cc","cell_type":"markdown","source":"## Section 2: Verify Preprocessed Data","metadata":{}},{"id":"b568c272-26ba-4326-bd68-70427bc707de","cell_type":"code","source":"import gdown\ngdown.download(quiet=True, id=\"1H9LIHZpl8nSd6R0NZyHQHDTcs49pYzOt\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:41:56.655842Z","iopub.execute_input":"2025-11-11T23:41:56.656137Z","iopub.status.idle":"2025-11-11T23:42:01.161464Z","shell.execute_reply.started":"2025-11-11T23:41:56.656117Z","shell.execute_reply":"2025-11-11T23:42:01.160774Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"'preprocessed_2classes_aug_non_negative.zip'"},"metadata":{}}],"execution_count":9},{"id":"06a1e38e-17db-48da-b565-096355c35d0e","cell_type":"code","source":"os.makedirs('data/', exist_ok=True)\n!unzip -q /kaggle/working/preprocessed_2classes_aug_non_negative.zip -d data/","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:42:01.162519Z","iopub.execute_input":"2025-11-11T23:42:01.162935Z","iopub.status.idle":"2025-11-11T23:42:06.828223Z","shell.execute_reply.started":"2025-11-11T23:42:01.162916Z","shell.execute_reply":"2025-11-11T23:42:06.827313Z"}},"outputs":[],"execution_count":10},{"id":"e94609bf-ffd7-4d97-90e5-7da918bd5f75","cell_type":"code","source":"!cat /kaggle/working/data/preprocessed_2classes_aug_non_negative/data.yaml","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:42:06.829262Z","iopub.execute_input":"2025-11-11T23:42:06.829565Z","iopub.status.idle":"2025-11-11T23:42:06.958296Z","shell.execute_reply.started":"2025-11-11T23:42:06.829531Z","shell.execute_reply":"2025-11-11T23:42:06.957550Z"}},"outputs":[{"name":"stdout","text":"path: /home/minhquana/workspace/project_DeepLearning/computer_vision/Abnormal-Prediction-In-Chest-X-Ray/data/preprocessed_2classes_aug_non_negative\ntrain: train/images\nval: valid/images\ntest: test/images\nnc: 2\nnames:\n- Aortic enlargement\n- Cardiomegaly\n","output_type":"stream"}],"execution_count":11},{"id":"384b05b3-5459-4a08-8b96-3b6d695ee2dd","cell_type":"code","source":"# Correct paths in data.yaml\ndata_yaml_path = Path('/kaggle/working/data/preprocessed_2classes_aug_non_negative/data.yaml')\n\nif data_yaml_path.exists():\n    print(f\"Correcting paths in {data_yaml_path}\")\n    with open(data_yaml_path, 'r') as f:\n        data_yaml_content = f.read()\n\n    # Replace the incorrect path with the correct one\n    corrected_yaml_content = data_yaml_content.replace(\n        \"/home/minhquana/workspace/project_DeepLearning/computer_vision/Abnormal-Prediction-In-Chest-X-Ray/data/preprocessed_2classes_aug_non_negative\",\n        \"/kaggle/working/data/preprocessed_2classes_aug_non_negative\"\n    )\n\n    with open(data_yaml_path, 'w') as f:\n        f.write(corrected_yaml_content)\n\n    print(\"‚úì Paths corrected successfully!\")\n    print(\"\\nContent of corrected data.yaml:\")\n    print(\"-\" * 80)\n    print(corrected_yaml_content)\n    print(\"-\" * 80)\n\nelse:\n    print(f\"Error: data.yaml not found at {data_yaml_path}\")\n    raise FileNotFoundError(f\"data.yaml not found at {data_yaml_path}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:42:06.960307Z","iopub.execute_input":"2025-11-11T23:42:06.960538Z","iopub.status.idle":"2025-11-11T23:42:06.968473Z","shell.execute_reply.started":"2025-11-11T23:42:06.960517Z","shell.execute_reply":"2025-11-11T23:42:06.967775Z"}},"outputs":[{"name":"stdout","text":"Correcting paths in /kaggle/working/data/preprocessed_2classes_aug_non_negative/data.yaml\n‚úì Paths corrected successfully!\n\nContent of corrected data.yaml:\n--------------------------------------------------------------------------------\npath: /kaggle/working/data/preprocessed_2classes_aug_non_negative\ntrain: train/images\nval: valid/images\ntest: test/images\nnc: 2\nnames:\n- Aortic enlargement\n- Cardiomegaly\n\n--------------------------------------------------------------------------------\n","output_type":"stream"}],"execution_count":12},{"id":"c0b57cdb","cell_type":"code","source":"# Verify preprocessed data directory\npreprocessed_dir = Path('data/preprocessed_2classes_aug_non_negative')\ndata_yaml = preprocessed_dir / 'data.yaml'\n\nprint(\"Verifying Preprocessed Data\")\nprint(\"=\" * 80)\n\nif not preprocessed_dir.exists():\n    print(\"ERROR: Preprocessed data not found!\")\n    print(f\"   Expected location: {preprocessed_dir.absolute()}\")\n    print(\"\\nPlease run data_preparation.ipynb first to create preprocessed data.\")\n    raise FileNotFoundError(f\"Preprocessed data not found at {preprocessed_dir}\")\n\nif not data_yaml.exists():\n    print(f\"ERROR: data.yaml not found at {data_yaml}\")\n    raise FileNotFoundError(f\"data.yaml not found\")\n\nprint(f\"‚úì Preprocessed data directory found: {preprocessed_dir}\")\nprint(f\"‚úì Data YAML found: {data_yaml}\")\n\n# Load data.yaml\nwith open(data_yaml, 'r') as f:\n    data_config = yaml.safe_load(f)\n\nprint(f\"\\nDataset Configuration:\")\nprint(f\"  Number of classes: {data_config['nc']}\")\nprint(f\"  Class names: {data_config['names']}\")\n\n# Count images in each split\nsplits = ['train', 'valid', 'test']\nsplit_counts = {}\n\nfor split in splits:\n    images_dir = preprocessed_dir / split / 'images'\n    if images_dir.exists():\n        count = len(list(images_dir.glob('*.png'))) + len(list(images_dir.glob('*.jpg')))\n        split_counts[split] = count\n    else:\n        split_counts[split] = 0\n\nprint(f\"\\nDataset Statistics:\")\nprint(f\"  Train:      {split_counts['train']:,} images\")\nprint(f\"  Validation: {split_counts['valid']:,} images\")\nprint(f\"  Test:       {split_counts['test']:,} images\")\nprint(f\"  Total:      {sum(split_counts.values()):,} images\")\n\nif split_counts['train'] == 0:\n    print(\"\\nERROR: No training images found!\")\n    raise ValueError(\"No training images found in preprocessed data\")\n\nprint(\"\\n‚úì Data verification complete - ready for training!\")\nprint(\"=\" * 80)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:42:06.969119Z","iopub.execute_input":"2025-11-11T23:42:06.969279Z","iopub.status.idle":"2025-11-11T23:42:07.018306Z","shell.execute_reply.started":"2025-11-11T23:42:06.969266Z","shell.execute_reply":"2025-11-11T23:42:07.017512Z"}},"outputs":[{"name":"stdout","text":"Verifying Preprocessed Data\n================================================================================\n‚úì Preprocessed data directory found: data/preprocessed_2classes_aug_non_negative\n‚úì Data YAML found: data/preprocessed_2classes_aug_non_negative/data.yaml\n\nDataset Configuration:\n  Number of classes: 2\n  Class names: ['Aortic enlargement', 'Cardiomegaly']\n\nDataset Statistics:\n  Train:      4,724 images\n  Validation: 704 images\n  Test:       328 images\n  Total:      5,756 images\n\n‚úì Data verification complete - ready for training!\n================================================================================\n","output_type":"stream"}],"execution_count":13},{"id":"887a7279","cell_type":"markdown","source":"## Section 3: WandB Setup","metadata":{}},{"id":"0c680bfc-b2e7-47a9-a30f-7bc7fd384f2a","cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nkey = user_secrets.get_secret(\"wandb_api_key\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:42:07.019213Z","iopub.execute_input":"2025-11-11T23:42:07.019474Z","iopub.status.idle":"2025-11-11T23:42:07.134039Z","shell.execute_reply.started":"2025-11-11T23:42:07.019450Z","shell.execute_reply":"2025-11-11T23:42:07.133358Z"}},"outputs":[],"execution_count":14},{"id":"35609f76","cell_type":"code","source":"# Login to WandB\nwandb.login(key=key)\nprint(\"‚úì Logged into Weights & Biases successfully\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:42:07.134770Z","iopub.execute_input":"2025-11-11T23:42:07.134981Z","iopub.status.idle":"2025-11-11T23:42:14.314187Z","shell.execute_reply.started":"2025-11-11T23:42:07.134966Z","shell.execute_reply":"2025-11-11T23:42:14.313608Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mminhquana\u001b[0m (\u001b[33mminhquana-university-of-transportation-and-communication\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"name":"stdout","text":"‚úì Logged into Weights & Biases successfully\n","output_type":"stream"}],"execution_count":15},{"id":"f969a042","cell_type":"code","source":"NAME=\"yolov11s-AdamW-2classes-light-augment-non-neg\"\nPROJECT=\"chest-xray-abnormality-detection\"\nEPOCH=200\nBATCH_SIZE=48\nIMG_SIZE=1024\nPATIENCE=10\nOPTIMIZER=\"AdamW\"\nLR=0.00008\nLRF=0.001\nDEVICE=[0, 1]\nWARMUP_EPOCH=10.0\nWEIGHT_DECAY=0.001","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:42:14.314960Z","iopub.execute_input":"2025-11-11T23:42:14.315449Z","iopub.status.idle":"2025-11-11T23:42:14.319773Z","shell.execute_reply.started":"2025-11-11T23:42:14.315405Z","shell.execute_reply":"2025-11-11T23:42:14.319192Z"}},"outputs":[],"execution_count":16},{"id":"5bbf1148","cell_type":"code","source":"# Initialize WandB project\nwandb.init(\n    project=PROJECT,\n    name=NAME,\n    config={\n        \"model\": \"YOLOv11s\",\n        \"dataset\": \"VinBigData Chest X-ray v3 (Preprocessed + Filtered)\",\n        \"epochs\": EPOCH,\n        \"batch_size\": BATCH_SIZE,\n        \"image_size\": IMG_SIZE,\n        \"patience\": PATIENCE,\n        \"optimizer\": OPTIMIZER,\n        \"learning_rate\": LR,\n        \"preprocessing\": \"grayscale + histogram_eq + normalization (NO blur)\",\n        \"augmentation\": \"gaussian_blur (custom callback) + rotation (YOLO degrees=5.0)\",\n        \"training_strategy\": \"minimal augmentation to preserve medical features\",\n        \"gaussian_blur\": \"80% 3x3, 20% 5x5 with sigma=0.5\",\n    }\n)\n\nprint(\"‚úì WandB initialized successfully\")\nprint(f\"  Project: chest-xray-abnormality-detection\")\nprint(f\"  Run name: {wandb.run.name}\")\nprint(f\"  Run URL: {wandb.run.url}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:42:14.320772Z","iopub.execute_input":"2025-11-11T23:42:14.321023Z","iopub.status.idle":"2025-11-11T23:42:22.738982Z","shell.execute_reply.started":"2025-11-11T23:42:14.321006Z","shell.execute_reply":"2025-11-11T23:42:22.738315Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.21.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20251111_234214-st4y9gr8</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/minhquana-university-of-transportation-and-communication/chest-xray-abnormality-detection/runs/st4y9gr8' target=\"_blank\">yolov11s-AdamW-2classes-light-augment-non-neg</a></strong> to <a href='https://wandb.ai/minhquana-university-of-transportation-and-communication/chest-xray-abnormality-detection' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/minhquana-university-of-transportation-and-communication/chest-xray-abnormality-detection' target=\"_blank\">https://wandb.ai/minhquana-university-of-transportation-and-communication/chest-xray-abnormality-detection</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/minhquana-university-of-transportation-and-communication/chest-xray-abnormality-detection/runs/st4y9gr8' target=\"_blank\">https://wandb.ai/minhquana-university-of-transportation-and-communication/chest-xray-abnormality-detection/runs/st4y9gr8</a>"},"metadata":{}},{"name":"stdout","text":"‚úì WandB initialized successfully\n  Project: chest-xray-abnormality-detection\n  Run name: yolov11s-AdamW-2classes-light-augment-non-neg\n  Run URL: https://wandb.ai/minhquana-university-of-transportation-and-communication/chest-xray-abnormality-detection/runs/st4y9gr8\n","output_type":"stream"}],"execution_count":17},{"id":"933ec05f","cell_type":"code","source":"# Enable WandB integration in Ultralytics\nsettings.update({'wandb': True})\n\nprint(\"‚úì WandB integration enabled for Ultralytics YOLO\")\nprint(\"\\nTraining metrics will be automatically logged to WandB:\")\nprint(\"   - Loss curves (box_loss, cls_loss, dfl_loss)\")\nprint(\"   - mAP scores (mAP50, mAP50-95)\")\nprint(\"   - Learning rate schedules\")\nprint(\"   - Training/validation images with predictions\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:42:22.740922Z","iopub.execute_input":"2025-11-11T23:42:22.741319Z","iopub.status.idle":"2025-11-11T23:42:28.241561Z","shell.execute_reply.started":"2025-11-11T23:42:22.741301Z","shell.execute_reply":"2025-11-11T23:42:28.240874Z"}},"outputs":[{"name":"stdout","text":"‚úì WandB integration enabled for Ultralytics YOLO\n\nTraining metrics will be automatically logged to WandB:\n   - Loss curves (box_loss, cls_loss, dfl_loss)\n   - mAP scores (mAP50, mAP50-95)\n   - Learning rate schedules\n   - Training/validation images with predictions\n","output_type":"stream"}],"execution_count":18},{"id":"16153797","cell_type":"markdown","source":"## Section 4: Training Configuration\n\nConfigure training parameters with minimal augmentation strategy.","metadata":{}},{"id":"45043374","cell_type":"code","source":"# Training configuration\ntraining_config = {\n    # Data\n    'data': str(data_yaml),\n    \n    # Training hyperparameters\n    'epochs': EPOCH,\n    'batch': BATCH_SIZE,\n    'imgsz': IMG_SIZE,\n    'patience': PATIENCE,\n    'save': True,\n    'plots': True,\n    'verbose': True,\n    \n    # Device and performance\n    'device': DEVICE,\n    'workers': 8,\n    'cache': False,\n    \n    # Optimization parameters\n    'optimizer': OPTIMIZER,\n    'lr0': LR,\n    'lrf': LRF,          # Final learning rate (lr0 * lrf)\n    'momentum': 0.937,\n    'weight_decay': WEIGHT_DECAY,\n    'warmup_epochs': WARMUP_EPOCH,\n    'warmup_momentum': 0.8,\n    'warmup_bias_lr': 0.1,\n    'cos_lr': True,         # Use cosine learning rate scheduler\n    \n    'degrees': 10.0,         # TƒÉng ƒë·ªô xoay m·ªôt ch√∫t\n    'hsv_h': 0.00,          # Th√™m m·ªôt ch√∫t bi·∫øn ƒë·ªïi m√†u s·∫Øc (d√π ·∫£nh x√°m)\n    'hsv_s': 0.0,            # TƒÉng bi·∫øn ƒë·ªïi ƒë·ªô b√£o h√≤a\n    'hsv_v': 0.4,            # QUAN TR·ªåNG: Th√™m bi·∫øn ƒë·ªïi ƒë·ªô s√°ng/t∆∞∆°ng ph·∫£n\n    'translate': 0.1,        # D·ªãch chuy·ªÉn ·∫£nh +/- 10%\n    'scale': 0.5,            # Co gi√£n ·∫£nh +/- 50%\n    'shear': 0.0,            # Th√™m bi·∫øn ƒë·ªïi c·∫Øt x√©o\n    'perspective': 0.00,    # Th√™m m·ªôt ch√∫t bi·∫øn ƒë·ªïi g√≥c nh√¨n\n    'fliplr': 0.5,           # L·∫≠t ngang 50% ·∫£nh. D√π gi·∫£i ph·∫´u b·ªã ƒë·∫£o, n√≥ gi√∫p m√¥ h√¨nh h·ªçc t·ªïng qu√°t.\n    'flipud': 0.0,           # Kh√¥ng n√™n l·∫≠t d·ªçc v·ªõi X-quang ng·ª±c\n    'mosaic': 0.0,           # B·∫≠t Mosaic augmentation\n    'mixup': 0.0,            # B·∫≠t Mixup v·ªõi t·ª∑ l·ªá th·∫•p\n    'copy_paste': 0.0,       # R·∫•t h·ªØu √≠ch cho class imbalance, h√£y th·ª≠ b·∫≠t n√≥\n    'erasing': 0.0,\n    # \"rect\": True,\n    # \"multi_scale\": True,\n    \n}\n\nprint(\"Training Configuration\")\nprint(\"=\" * 80)\nfor key, value in training_config.items():\n    print(f\"  {key:25s}: {value}\")\nprint(\"=\" * 80)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:42:28.242308Z","iopub.execute_input":"2025-11-11T23:42:28.242598Z","iopub.status.idle":"2025-11-11T23:42:33.655417Z","shell.execute_reply.started":"2025-11-11T23:42:28.242570Z","shell.execute_reply":"2025-11-11T23:42:33.654597Z"}},"outputs":[{"name":"stdout","text":"Training Configuration\n================================================================================\n  data                     : data/preprocessed_2classes_aug_non_negative/data.yaml\n  epochs                   : 200\n  batch                    : 48\n  imgsz                    : 1024\n  patience                 : 10\n  save                     : True\n  plots                    : True\n  verbose                  : True\n  device                   : [0, 1]\n  workers                  : 8\n  cache                    : False\n  optimizer                : AdamW\n  lr0                      : 8e-05\n  lrf                      : 0.001\n  momentum                 : 0.937\n  weight_decay             : 0.001\n  warmup_epochs            : 10.0\n  warmup_momentum          : 0.8\n  warmup_bias_lr           : 0.1\n  cos_lr                   : True\n  degrees                  : 10.0\n  hsv_h                    : 0.0\n  hsv_s                    : 0.0\n  hsv_v                    : 0.4\n  translate                : 0.1\n  scale                    : 0.5\n  shear                    : 0.0\n  perspective              : 0.0\n  fliplr                   : 0.5\n  flipud                   : 0.0\n  mosaic                   : 0.0\n  mixup                    : 0.0\n  copy_paste               : 0.0\n  erasing                  : 0.0\n================================================================================\n","output_type":"stream"}],"execution_count":19},{"id":"29b6d562","cell_type":"markdown","source":"## Section 5: Model Training\n\nTrain YOLOv11s with custom augmentation callback.","metadata":{}},{"id":"98236b87","cell_type":"code","source":"# Load YOLOv11s model\nprint(\"\\nLoading YOLOv11s model...\")\nmodel = YOLO('yolo11s.pt')\n\nprint(\"‚úì Model loaded successfully\")\nprint(f\"  Model architecture: YOLOv11s\")\nprint(f\"  Parameters: ~{sum(p.numel() for p in model.model.parameters()) / 1e6:.1f}M\")\n\nprint(\"\\nStarting training...\")\nprint(\"Progress will be tracked in WandB dashboard\")\nprint(\"-\" * 80)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:42:33.656346Z","iopub.execute_input":"2025-11-11T23:42:33.656671Z","iopub.status.idle":"2025-11-11T23:42:39.683998Z","shell.execute_reply.started":"2025-11-11T23:42:33.656643Z","shell.execute_reply":"2025-11-11T23:42:39.683229Z"}},"outputs":[{"name":"stdout","text":"\nLoading YOLOv11s model...\n\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11s.pt to 'yolo11s.pt': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 18.4MB 83.1MB/s 0.2s 0.2s<0.0s\n‚úì Model loaded successfully\n  Model architecture: YOLOv11s\n  Parameters: ~9.5M\n\nStarting training...\nProgress will be tracked in WandB dashboard\n--------------------------------------------------------------------------------\n","output_type":"stream"}],"execution_count":20},{"id":"fe011fe0","cell_type":"code","source":"# Train the model\ntry:\n    results = model.train(\n        **training_config,\n        project=PROJECT,\n        name=NAME\n    )\n    \n    print(\"\\n\" + \"=\" * 80)\n    print(\"‚úì Training completed successfully!\")\n    print(\"=\" * 80)\n    \n    # Check if results is valid\n    if results is None:\n        print(\"\\nWARNING: Training returned None - checking training directory...\")\n        # Find the latest training directory\n        training_dir = Path('chest-xray-abnormality-detection')\n        if training_dir.exists():\n            # Get all run directories sorted by modification time\n            run_dirs = sorted(training_dir.glob('yolov11s-Adam*'), \n                            key=lambda x: x.stat().st_mtime, reverse=True)\n            if run_dirs:\n                latest_run = run_dirs[0]\n                print(f\"  Found latest training run: {latest_run}\")\n                best_model_path = latest_run / 'weights' / 'best.pt'\n                last_model_path = latest_run / 'weights' / 'last.pt'\n                \n                if best_model_path.exists():\n                    print(f\"  ‚úì Best model found: {best_model_path}\")\n                elif last_model_path.exists():\n                    print(f\"  ‚úì Last model found: {last_model_path}\")\n                    best_model_path = last_model_path\n                else:\n                    print(f\"  No model weights found in {latest_run}\")\n                    best_model_path = None\n            else:\n                print(\"  No training runs found\")\n                best_model_path = None\n        else:\n            print(\"  Training directory not found\")\n            best_model_path = None\n    else:\n        # Display results\n        print(\"\\nTraining Results:\")\n        if hasattr(results, 'results_dict'):\n            print(f\"  Best mAP50: {results.results_dict.get('metrics/mAP50(B)', 'N/A')}\")\n            print(f\"  Best mAP50-95: {results.results_dict.get('metrics/mAP50-95(B)', 'N/A')}\")\n        \n        # Save best model path\n        if hasattr(results, 'save_dir') and results.save_dir:\n            best_model_path = Path(results.save_dir) / 'weights' / 'best.pt'\n            print(f\"\\nBest model saved to: {best_model_path}\")\n        else:\n            print(\"\\nWARNING: results.save_dir not available\")\n            best_model_path = None\n    \nexcept Exception as e:\n    print(f\"\\nTraining failed: {e}\")\n    import traceback\n    traceback.print_exc()\n    best_model_path = None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T23:42:39.685056Z","iopub.execute_input":"2025-11-11T23:42:39.685336Z","iopub.status.idle":"2025-11-12T00:27:23.151281Z","shell.execute_reply.started":"2025-11-11T23:42:39.685317Z","shell.execute_reply":"2025-11-12T00:27:23.150406Z"}},"outputs":[{"name":"stdout","text":"Ultralytics 8.3.227 üöÄ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n                                                       CUDA:1 (Tesla T4, 15095MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=48, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=True, cutmix=0.0, data=data/preprocessed_2classes_aug_non_negative/data.yaml, degrees=10.0, deterministic=True, device=0,1, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=200, erasing=0.0, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.0, hsv_s=0.0, hsv_v=0.4, imgsz=1024, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=8e-05, lrf=0.001, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11s.pt, momentum=0.937, mosaic=0.0, multi_scale=False, name=yolov11s-AdamW-2classes-light-augment-non-neg, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=10, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=chest-xray-abnormality-detection, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/chest-xray-abnormality-detection/yolov11s-AdamW-2classes-light-augment-non-neg, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=10.0, warmup_momentum=0.8, weight_decay=0.001, workers=8, workspace=None\n\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 755.1KB 14.7MB/s 0.1s\nOverriding model.yaml nc=80 with nc=2\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n  2                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n  3                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n  4                  -1  1    103360  ultralytics.nn.modules.block.C3k2            [128, 256, 1, False, 0.25]    \n  5                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n  6                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n  8                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n 10                  -1  1    990976  ultralytics.nn.modules.block.C2PSA           [512, 512, 1]                 \n 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 13                  -1  1    443776  ultralytics.nn.modules.block.C3k2            [768, 256, 1, False]          \n 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 16                  -1  1    127680  ultralytics.nn.modules.block.C3k2            [512, 128, 1, False]          \n 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 19                  -1  1    345472  ultralytics.nn.modules.block.C3k2            [384, 256, 1, False]          \n 20                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 22                  -1  1   1511424  ultralytics.nn.modules.block.C3k2            [768, 512, 1, True]           \n 23        [16, 19, 22]  1    820182  ultralytics.nn.modules.head.Detect           [2, [128, 256, 512]]          \nYOLO11s summary: 181 layers, 9,428,566 parameters, 9,428,550 gradients, 21.6 GFLOPs\n\nTransferred 493/499 items from pretrained weights\n\u001b[34m\u001b[1mDDP:\u001b[0m debug command /usr/bin/python3 -m torch.distributed.run --nproc_per_node 2 --master_port 50653 /root/.config/Ultralytics/DDP/_temp_ceubs2te137367398458896.py\nUltralytics 8.3.227 üöÄ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n                                                       CUDA:1 (Tesla T4, 15095MiB)\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\nwandb: Currently logged in as: minhquana (minhquana-university-of-transportation-and-communication) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\nwandb: Tracking run with wandb version 0.21.0\nwandb: Run data is saved locally in /kaggle/working/wandb/run-20251111_234255-ivmzqro0\nwandb: Run `wandb offline` to turn off syncing.\nwandb: Syncing run yolov11s-AdamW-2classes-light-augment-non-neg\nwandb: ‚≠êÔ∏è View project at https://wandb.ai/minhquana-university-of-transportation-and-communication/chest-xray-abnormality-detection\nwandb: üöÄ View run at https://wandb.ai/minhquana-university-of-transportation-and-communication/chest-xray-abnormality-detection/runs/ivmzqro0\n","output_type":"stream"},{"name":"stdout","text":"Overriding model.yaml nc=80 with nc=2\nTransferred 493/499 items from pretrained weights\nFreezing layer 'model.23.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5.4MB 63.1MB/s 0.1s\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1607.3¬±343.8 MB/s, size: 78.2 KB)\n\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/data/preprocessed_2classes_aug_non_negative/train/labels... 4724 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4724/4724 1.3Kit/s 3.6s0.0s\n\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/data/preprocessed_2classes_aug_non_negative/train/labels.cache\n\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 552.5¬±413.9 MB/s, size: 75.6 KB)\n\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/data/preprocessed_2classes_aug_non_negative/valid/labels... 704 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 704/704 918.1it/s 0.8s0.0s\n\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/data/preprocessed_2classes_aug_non_negative/valid/labels.cache\nPlotting labels to /kaggle/working/chest-xray-abnormality-detection/yolov11s-AdamW-2classes-light-augment-non-neg/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=8e-05, momentum=0.937) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.00075), 87 bias(decay=0.0)\nImage sizes 1024 train, 1024 val\nUsing 4 dataloader workers\nLogging results to \u001b[1m/kaggle/working/chest-xray-abnormality-detection/yolov11s-AdamW-2classes-light-augment-non-neg\u001b[0m\nStarting training for 200 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      1/200      14.3G      1.843      3.163      1.887         14       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 99/99 1.0it/s 1:430.9sss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 0.9it/s 9.1s1.1ss\n                   all        704       1124     0.0787      0.264     0.0588     0.0223\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      2/200      14.3G      1.477      1.083      1.546         14       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 99/99 0.9it/s 1:450.8sss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.0it/s 7.8s1.0ss\n                   all        704       1124       0.65      0.537      0.615      0.274\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      3/200      14.3G      1.452      1.018      1.514         17       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 99/99 0.9it/s 1:450.8sss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.0it/s 7.7s1.1ss\n                   all        704       1124      0.795      0.848      0.848      0.422\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      4/200      14.3G      1.439      0.959      1.507         18       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 99/99 0.9it/s 1:450.8sss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.0it/s 7.8s1.1ss\n                   all        704       1124      0.754      0.835        0.8      0.414\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      5/200      14.3G      1.419     0.9172      1.485         14       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 99/99 0.9it/s 1:450.8sss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.1it/s 7.3s1.0ss\n                   all        704       1124       0.86      0.876      0.887      0.425\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      6/200      14.3G      1.414     0.8746      1.475         16       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 99/99 0.9it/s 1:450.8sss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.1it/s 7.4s1.0ss\n                   all        704       1124       0.85      0.911      0.919      0.434\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      7/200      14.3G      1.411      0.866      1.472         19       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 99/99 0.9it/s 1:450.8sss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.0it/s 8.0s1.2ss\n                   all        704       1124      0.869      0.904      0.912      0.474\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      8/200      14.3G      1.391     0.8346      1.458         15       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 99/99 0.9it/s 1:450.8sss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.1it/s 7.4s1.0ss\n                   all        704       1124      0.874      0.906      0.929      0.474\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      9/200      14.3G      1.384      0.824      1.453         17       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 99/99 0.9it/s 1:450.8sss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.1it/s 7.5s1.0ss\n                   all        704       1124      0.825      0.925      0.913      0.458\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     10/200      14.3G      1.387     0.8227      1.447         16       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 99/99 0.9it/s 1:450.8sss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.0it/s 8.1s1.1ss\n                   all        704       1124      0.852      0.908      0.904      0.485\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     11/200      14.3G      1.378     0.8027       1.45         17       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 99/99 0.9it/s 1:450.8sss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.1it/s 7.6s1.1ss\n                   all        704       1124      0.876      0.922      0.928      0.481\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     12/200      14.3G      1.361     0.7822      1.436         18       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 99/99 0.9it/s 1:450.8sss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.1it/s 7.2s1.0ss\n                   all        704       1124      0.853      0.918      0.898       0.48\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     13/200      14.3G      1.347     0.7618      1.424         15       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 99/99 0.9it/s 1:450.8sss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.1it/s 7.5s1.0ss\n                   all        704       1124      0.871      0.918      0.931      0.499\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     14/200      14.3G      1.338     0.7556      1.426         19       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 99/99 0.9it/s 1:450.8sss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.1it/s 7.4s1.0ss\n                   all        704       1124      0.862      0.928      0.919       0.48\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     15/200      14.3G      1.336     0.7418      1.421         14       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 99/99 0.9it/s 1:450.8sss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.0it/s 7.8s1.1ss\n                   all        704       1124       0.87      0.909      0.931      0.494\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     16/200      14.3G      1.327     0.7233      1.416         15       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 99/99 0.9it/s 1:450.8sss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.1it/s 7.3s1.0ss\n                   all        704       1124      0.874      0.919      0.935      0.491\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     17/200      14.3G      1.314     0.7112      1.404         17       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 99/99 0.9it/s 1:450.8sss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.1it/s 7.4s1.0ss\n                   all        704       1124      0.867      0.902      0.904      0.481\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     18/200      14.3G      1.313     0.6956      1.401         18       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 99/99 0.9it/s 1:450.8sss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.1it/s 7.4s1.0ss\n                   all        704       1124      0.827      0.908      0.891      0.466\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     19/200      14.3G      1.284     0.6923      1.394         16       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 99/99 0.9it/s 1:450.8sss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.1it/s 7.5s1.1ss\n                   all        704       1124      0.873      0.914      0.917      0.487\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     20/200      14.3G      1.296     0.6756      1.388         16       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 99/99 0.9it/s 1:450.8sss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.1it/s 7.5s1.1ss\n                   all        704       1124      0.884      0.892      0.919       0.48\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     21/200      14.3G      1.258     0.6661      1.375         16       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 99/99 0.9it/s 1:450.8sss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.0it/s 7.8s1.1ss\n                   all        704       1124      0.856      0.889      0.888      0.446\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     22/200      14.3G       1.27     0.6492      1.382         19       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 99/99 0.9it/s 1:450.8sss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.0it/s 7.8s1.1ss\n                   all        704       1124      0.879      0.889      0.926      0.491\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K     23/200      14.3G       1.24      0.636      1.376         16       1024: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 99/99 0.9it/s 1:450.8sss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 1.1it/s 7.4s1.0ss\n                   all        704       1124      0.877      0.922      0.926      0.476\n\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 10 epochs. Best results observed at epoch 13, best model saved as best.pt.\nTo update EarlyStopping(patience=10) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n\n23 epochs completed in 0.727 hours.\nOptimizer stripped from /kaggle/working/chest-xray-abnormality-detection/yolov11s-AdamW-2classes-light-augment-non-neg/weights/last.pt, 19.3MB\nOptimizer stripped from /kaggle/working/chest-xray-abnormality-detection/yolov11s-AdamW-2classes-light-augment-non-neg/weights/best.pt, 19.3MB\n\nValidating /kaggle/working/chest-xray-abnormality-detection/yolov11s-AdamW-2classes-light-augment-non-neg/weights/best.pt...\nYOLO11s summary (fused): 100 layers, 9,413,574 parameters, 0 gradients, 21.3 GFLOPs\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8/8 0.7it/s 12.1s1.2s\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\n/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\n","output_type":"stream"},{"name":"stdout","text":"                   all        704       1124      0.871      0.918      0.931      0.498\n    Aortic enlargement        632        632      0.881      0.887      0.902      0.464\n          Cardiomegaly        492        492      0.861      0.949       0.96      0.533\nSpeed: 0.3ms preprocess, 7.5ms inference, 0.0ms loss, 2.7ms postprocess per image\nResults saved to \u001b[1m/kaggle/working/chest-xray-abnormality-detection/yolov11s-AdamW-2classes-light-augment-non-neg\u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"wandb: WARNING Tried to log to step 23 that is less than the current step 24. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\nwandb:                                                                                \n","output_type":"stream"},{"name":"stdout","text":"\n================================================================================\n‚úì Training completed successfully!\n================================================================================\n\nWARNING: Training returned None - checking training directory...\n  Found latest training run: chest-xray-abnormality-detection/yolov11s-AdamW-2classes-light-augment-non-neg\n  ‚úì Best model found: chest-xray-abnormality-detection/yolov11s-AdamW-2classes-light-augment-non-neg/weights/best.pt\n","output_type":"stream"}],"execution_count":21},{"id":"2c9e4f32","cell_type":"markdown","source":"## Section 6: Model Validation","metadata":{}},{"id":"51d595a0","cell_type":"code","source":"# Validate on test set\nprint(\"Model Validation on Test Set\")\nprint(\"=\" * 80)\n\n# Load best model\nif 'best_model_path' in locals() and best_model_path.exists():\n    print(f\"Loading best model: {best_model_path}\")\n    model = YOLO(str(best_model_path))\nelse:\n    print(\"Using last trained model\")\n\n# model = YOLO(\"/kaggle/working/chest-xray-abnormality-detection/yolov11s-AdamW-/weights/best.pt\")\n\nprint(\"\\nRunning validation...\")\nmetrics = model.val(data=str(data_yaml), split='test')\n\nprint(\"\\nValidation Results:\")\nprint(\"=\" * 80)\nresults_dict = metrics.results_dict\nprint(f\"  mAP50:       {results_dict.get('metrics/mAP50(B)', 0):.4f}\")\nprint(f\"  mAP50-95:    {results_dict.get('metrics/mAP50-95(B)', 0):.4f}\")\nprint(f\"  Precision:   {results_dict.get('metrics/precision(B)', 0):.4f}\")\nprint(f\"  Recall:      {results_dict.get('metrics/recall(B)', 0):.4f}\")\nprint(\"=\" * 80) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T00:27:23.152124Z","iopub.execute_input":"2025-11-12T00:27:23.152336Z","iopub.status.idle":"2025-11-12T00:27:45.053695Z","shell.execute_reply.started":"2025-11-12T00:27:23.152319Z","shell.execute_reply":"2025-11-12T00:27:45.052925Z"}},"outputs":[{"name":"stdout","text":"Model Validation on Test Set\n================================================================================\nLoading best model: chest-xray-abnormality-detection/yolov11s-AdamW-2classes-light-augment-non-neg/weights/best.pt\n\nRunning validation...\nUltralytics 8.3.227 üöÄ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\nYOLO11s summary (fused): 100 layers, 9,413,574 parameters, 0 gradients, 21.3 GFLOPs\n\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1767.9¬±408.8 MB/s, size: 96.7 KB)\n\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/data/preprocessed_2classes_aug_non_negative/test/labels... 328 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 328/328 1.4Kit/s 0.2s<0.1s\n\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/data/preprocessed_2classes_aug_non_negative/test/labels.cache\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 21/21 1.9it/s 11.0s0.5s\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\n/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\n","output_type":"stream"},{"name":"stdout","text":"                   all        328        519      0.852      0.928      0.929      0.491\n    Aortic enlargement        301        301      0.879      0.916      0.915      0.477\n          Cardiomegaly        218        218      0.825       0.94      0.943      0.504\nSpeed: 3.0ms preprocess, 25.2ms inference, 0.0ms loss, 2.2ms postprocess per image\nResults saved to \u001b[1m/kaggle/working/runs/detect/val\u001b[0m\n\nValidation Results:\n================================================================================\n  mAP50:       0.9295\n  mAP50-95:    0.4908\n  Precision:   0.8518\n  Recall:      0.9281\n================================================================================\n","output_type":"stream"}],"execution_count":22},{"id":"52b03bfe","cell_type":"markdown","source":"## Section 7: Model Export","metadata":{}},{"id":"602ff5d0","cell_type":"code","source":"# Export to backend\nbackend_models_dir = Path('backend/models')\nbackend_models_dir.mkdir(parents=True, exist_ok=True)\n\ntarget_model_path = backend_models_dir / 'yolov11s_finetuned.pt'\n\nprint(\"Exporting Model to Backend\")\nprint(\"=\" * 80)\n\n# Check if best_model_path exists\nif 'best_model_path' not in locals() or best_model_path is None:\n    print(\"WARNING: best_model_path not found from training\")\n    print(\"   Searching for latest trained model...\")\n    \n    # Try to find the latest model\n    training_dir = Path('chest-xray-abnormality-detection')\n    if training_dir.exists():\n        run_dirs = sorted(training_dir.glob('yolov11s-Adam*'), \n                        key=lambda x: x.stat().st_mtime, reverse=True)\n        if run_dirs:\n            latest_run = run_dirs[0]\n            best_model_path = latest_run / 'weights' / 'best.pt'\n            if not best_model_path.exists():\n                best_model_path = latest_run / 'weights' / 'last.pt'\n            \n            if best_model_path.exists():\n                print(f\"   ‚úì Found model: {best_model_path}\")\n            else:\n                print(f\"   No model weights found\")\n                best_model_path = None\n        else:\n            print(\"   No training runs found\")\n            best_model_path = None\n    else:\n        print(\"   Training directory not found\")\n        best_model_path = None\n\nif best_model_path and best_model_path.exists():\n    print(f\"Source: {best_model_path}\")\n    print(f\"Target: {target_model_path}\")\n    \n    shutil.copy(best_model_path, target_model_path)\n    \n    if target_model_path.exists():\n        size_mb = target_model_path.stat().st_size / (1024*1024)\n        print(f\"\\n‚úì Model exported successfully!\")\n        print(f\"  File size: {size_mb:.2f} MB\")\n        print(f\"  Location: {target_model_path}\")\n        print(f\"\\nModel ready for production use!\")\n    else:\n        print(\"Export failed\")\nelse:\n    print(\"Cannot export - model not found\")\n    print(\"\\nPlease check:\")\n    print(\"  1. Training completed successfully\")\n    print(\"  2. Model weights exist in training directory\")\n    print(\"  3. No errors during training\")\n\nprint(\"=\" * 80)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T00:27:45.054766Z","iopub.execute_input":"2025-11-12T00:27:45.055184Z","iopub.status.idle":"2025-11-12T00:27:50.379604Z","shell.execute_reply.started":"2025-11-12T00:27:45.055160Z","shell.execute_reply":"2025-11-12T00:27:50.378890Z"}},"outputs":[{"name":"stdout","text":"Exporting Model to Backend\n================================================================================\nSource: chest-xray-abnormality-detection/yolov11s-AdamW-2classes-light-augment-non-neg/weights/best.pt\nTarget: backend/models/yolov11s_finetuned.pt\n\n‚úì Model exported successfully!\n  File size: 18.36 MB\n  Location: backend/models/yolov11s_finetuned.pt\n\nModel ready for production use!\n================================================================================\n","output_type":"stream"}],"execution_count":23},{"id":"5afe21dd","cell_type":"code","source":"# Close WandB run\nwandb.finish()\nprint(\"‚úì WandB run finished\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T00:27:50.380509Z","iopub.execute_input":"2025-11-12T00:27:50.380745Z","iopub.status.idle":"2025-11-12T00:28:01.905867Z","shell.execute_reply.started":"2025-11-12T00:27:50.380717Z","shell.execute_reply":"2025-11-12T00:28:01.905056Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">yolov11s-AdamW-2classes-light-augment-non-neg</strong> at: <a href='https://wandb.ai/minhquana-university-of-transportation-and-communication/chest-xray-abnormality-detection/runs/st4y9gr8' target=\"_blank\">https://wandb.ai/minhquana-university-of-transportation-and-communication/chest-xray-abnormality-detection/runs/st4y9gr8</a><br> View project at: <a href='https://wandb.ai/minhquana-university-of-transportation-and-communication/chest-xray-abnormality-detection' target=\"_blank\">https://wandb.ai/minhquana-university-of-transportation-and-communication/chest-xray-abnormality-detection</a><br>Synced 5 W&B file(s), 0 media file(s), 7 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20251111_234214-st4y9gr8/logs</code>"},"metadata":{}},{"name":"stdout","text":"‚úì WandB run finished\n","output_type":"stream"}],"execution_count":24},{"id":"fe7efa34","cell_type":"markdown","source":"## Section 8: Training Summary","metadata":{}},{"id":"15a08fb9","cell_type":"code","source":"print(\"\\nTRAINING SUMMARY\")\nprint(\"=\" * 80)\n\nprint(\"\\nCompleted Tasks:\")\nprint(\"  1. ‚úì Loaded preprocessed data from data/preprocessed/\")\nprint(\"  2. ‚úì Applied custom Gaussian blur augmentation during training\")\nprint(\"  3. ‚úì Applied YOLO rotation augmentation (¬±5¬∞)\")\nprint(\"  4. ‚úì Trained YOLOv11s model for 100 epochs with early stopping\")\nprint(\"  5. ‚úì Tracked training with WandB\")\nprint(\"  6. ‚úì Validated on test set\")\nprint(\"  7. ‚úì Exported best model to backend/models/\")\n\nprint(\"\\nFinal Metrics:\")\nif 'results_dict' in locals():\n    print(f\"  mAP50:       {results_dict.get('metrics/mAP50(B)', 'N/A')}\")\n    print(f\"  mAP50-95:    {results_dict.get('metrics/mAP50-95(B)', 'N/A')}\")\n    print(f\"  Precision:   {results_dict.get('metrics/precision(B)', 'N/A')}\")\n    print(f\"  Recall:      {results_dict.get('metrics/recall(B)', 'N/A')}\")\n\nprint(\"\\n\" + \"=\" * 80)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T00:28:01.906785Z","iopub.execute_input":"2025-11-12T00:28:01.907072Z","iopub.status.idle":"2025-11-12T00:28:01.913234Z","shell.execute_reply.started":"2025-11-12T00:28:01.907045Z","shell.execute_reply":"2025-11-12T00:28:01.912510Z"}},"outputs":[{"name":"stdout","text":"\nTRAINING SUMMARY\n================================================================================\n\nCompleted Tasks:\n  1. ‚úì Loaded preprocessed data from data/preprocessed/\n  2. ‚úì Applied custom Gaussian blur augmentation during training\n  3. ‚úì Applied YOLO rotation augmentation (¬±5¬∞)\n  4. ‚úì Trained YOLOv11s model for 100 epochs with early stopping\n  5. ‚úì Tracked training with WandB\n  6. ‚úì Validated on test set\n  7. ‚úì Exported best model to backend/models/\n\nFinal Metrics:\n  mAP50:       0.9294574711390676\n  mAP50-95:    0.4908356754308693\n  Precision:   0.8517678152817729\n  Recall:      0.9281285628590692\n\n================================================================================\n","output_type":"stream"}],"execution_count":25}]}