{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d7df9b2",
   "metadata": {},
   "source": [
    "# YOLOv11s Fine-Tuning for Chest X-Ray Abnormality Detection\n",
    "\n",
    "**Purpose**: Fine-tune YOLOv11s model on VinBigData Chest X-ray dataset for detecting 14 disease classes\n",
    "\n",
    "**Date**: 2025-11-08\n",
    "\n",
    "**Dataset**: Roboflow Universe - VinBigData Chest X-ray Symptom Detection (version 3, YOLOv11 format)\n",
    "\n",
    "**Output**: Trained model weights exported to `../backend/models/yolov11s_finetuned.pt`\n",
    "\n",
    "## Workflow Overview\n",
    "\n",
    "1. **Dataset Download**: Download preprocessed dataset from Roboflow\n",
    "2. **Auto-Labeling**: Label images without annotations as \"Normal\" (BÃ¬nh thÆ°á»ng)\n",
    "3. **Class Mapping Verification**: Ensure English-Vietnamese class mapping is correct\n",
    "4. **Preprocessing**: Apply filters for data augmentation\n",
    "5. **Training**: Fine-tune YOLOv11s with tqdm progress tracking and WandB logging\n",
    "6. **Validation**: Test model on validation set\n",
    "7. **Export**: Save best weights for production use\n",
    "\n",
    "## Requirements\n",
    "\n",
    "- Python 3.12.3+\n",
    "- ultralytics (YOLOv11)\n",
    "- roboflow (dataset download)\n",
    "- wandb (experiment tracking)\n",
    "- tqdm (progress bars)\n",
    "- numpy, pillow (image processing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a4c0b4",
   "metadata": {},
   "source": [
    "## Section 1: Environment Setup\n",
    "\n",
    "Install required packages and import dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d12ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Install required packages\n",
    "# !pip install -q roboflow ultralytics wandb tqdm pillow numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40790c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import os\n",
    "import json\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Set working directory to repository root\n",
    "os.chdir('..')\n",
    "print(f\"Current working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9401553e",
   "metadata": {},
   "source": [
    "## Section 2: Dataset Download from Roboflow\n",
    "\n",
    "Download the VinBigData Chest X-ray Symptom Detection dataset (version 3) in YOLOv11 format.\n",
    "\n",
    "**API Key**: wQ9S049DhK8xjIhNy6zv\n",
    "\n",
    "**Project**: chest-xray-symptom-detection\n",
    "\n",
    "**Workspace**: vinbigdataxrayproject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a493f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from roboflow import Roboflow\n",
    "\n",
    "# Initialize Roboflow with API key\n",
    "rf = Roboflow(api_key=\"wQ9S049DhK8xjIhNy6zv\")\n",
    "\n",
    "# Access the VinBigData Chest X-ray project\n",
    "project = rf.workspace(\"vinbigdataxrayproject\").project(\"chest-xray-symptom-detection\")\n",
    "\n",
    "# Download version 3 in YOLOv11 format\n",
    "version = project.version(3)\n",
    "dataset = version.download(\"yolov11\")\n",
    "\n",
    "print(f\"\\nâœ“ Dataset downloaded to: {dataset.location}\")\n",
    "print(f\"âœ“ Dataset structure:\")\n",
    "print(f\"  - Train: {dataset.location}/train/\")\n",
    "print(f\"  - Validation: {dataset.location}/valid/\")\n",
    "print(f\"  - Test: {dataset.location}/test/\")\n",
    "print(f\"  - Config: {dataset.location}/data.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7902fb76",
   "metadata": {},
   "source": [
    "## Section 3: Auto-Labeling Normal Images\n",
    "\n",
    "Images without bounding box annotations (empty or missing .txt files) should be labeled as \"Normal\" (BÃ¬nh thÆ°á»ng).\n",
    "\n",
    "This ensures the model can distinguish between healthy and abnormal X-rays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928d8dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto-label images without annotations as \"Normal\"\n",
    "\n",
    "def auto_label_normal_images(dataset_path):\n",
    "    \"\"\"\n",
    "    Scan labels directory and assign \"Normal\" class to images with empty/missing .txt files.\n",
    "    \n",
    "    Args:\n",
    "        dataset_path: Path to dataset root (contains train/, valid/, test/)\n",
    "    \"\"\"\n",
    "    normal_count = 0\n",
    "    \n",
    "    for split in ['train', 'valid', 'test']:\n",
    "        images_dir = Path(dataset_path) / split / 'images'\n",
    "        labels_dir = Path(dataset_path) / split / 'labels'\n",
    "        \n",
    "        if not images_dir.exists():\n",
    "            print(f\"âš ï¸ Skipping {split}: images directory not found\")\n",
    "            continue\n",
    "            \n",
    "        # Create labels directory if it doesn't exist\n",
    "        labels_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Get all image files\n",
    "        image_files = list(images_dir.glob('*.jpg')) + list(images_dir.glob('*.png'))\n",
    "        \n",
    "        print(f\"\\nğŸ“ Processing {split} split: {len(image_files)} images\")\n",
    "        \n",
    "        for img_path in tqdm(image_files, desc=f\"Auto-labeling {split}\"):\n",
    "            # Get corresponding label file path\n",
    "            label_path = labels_dir / f\"{img_path.stem}.txt\"\n",
    "            \n",
    "            # Check if label file exists and is non-empty\n",
    "            if not label_path.exists() or label_path.stat().st_size == 0:\n",
    "                # Create empty label file (indicates \"Normal\" - no bounding boxes)\n",
    "                label_path.touch()\n",
    "                normal_count += 1\n",
    "        \n",
    "        # Count normal vs abnormal images\n",
    "        total_images = len(image_files)\n",
    "        normal_images = sum(1 for f in labels_dir.glob('*.txt') if f.stat().st_size == 0)\n",
    "        abnormal_images = total_images - normal_images\n",
    "        \n",
    "        print(f\"  âœ“ {split}: {normal_images} normal, {abnormal_images} abnormal images\")\n",
    "    \n",
    "    print(f\"\\nâœ“ Auto-labeling complete: {normal_count} images labeled as 'Normal'\")\n",
    "    return normal_count\n",
    "\n",
    "# Run auto-labeling on downloaded dataset\n",
    "dataset_path = dataset.location\n",
    "normal_count = auto_label_normal_images(dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2784214a",
   "metadata": {},
   "source": [
    "## Section 4: Class Mapping Verification\n",
    "\n",
    "Verify that all 14 English disease classes map correctly to Vietnamese translations.\n",
    "\n",
    "Update the dataset.yaml file with Vietnamese class names for consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37442095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load class mapping from configs\n",
    "with open('configs/class_mapping.json', 'r', encoding='utf-8') as f:\n",
    "    class_mapping = json.load(f)\n",
    "\n",
    "print(\"ğŸ“‹ English-Vietnamese Class Mapping:\")\n",
    "print(\"=\" * 60)\n",
    "for idx, (en_name, vi_name) in enumerate(class_mapping.items()):\n",
    "    print(f\"{idx:2d}. {en_name:25s} â†’ {vi_name}\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"âœ“ Total classes: {len(class_mapping)}\")\n",
    "\n",
    "# Load dataset.yaml\n",
    "yaml_path = Path(dataset.location) / 'data.yaml'\n",
    "print(f\"\\nğŸ“„ Reading dataset config: {yaml_path}\")\n",
    "\n",
    "# Read and update data.yaml with Vietnamese names\n",
    "with open(yaml_path, 'r') as f:\n",
    "    yaml_content = f.read()\n",
    "\n",
    "print(\"\\nğŸ” Original data.yaml classes:\")\n",
    "print(yaml_content)\n",
    "\n",
    "# Parse class names from data.yaml\n",
    "import yaml\n",
    "with open(yaml_path, 'r') as f:\n",
    "    data_config = yaml.safe_load(f)\n",
    "\n",
    "# Verify that all classes in dataset have Vietnamese mappings\n",
    "dataset_classes = data_config.get('names', [])\n",
    "print(f\"\\nâœ“ Dataset has {len(dataset_classes)} classes\")\n",
    "\n",
    "# Check for missing mappings\n",
    "missing_mappings = []\n",
    "for class_name in dataset_classes:\n",
    "    if class_name not in class_mapping and class_name != \"Normal\":\n",
    "        missing_mappings.append(class_name)\n",
    "\n",
    "if missing_mappings:\n",
    "    print(f\"âš ï¸ WARNING: {len(missing_mappings)} classes missing Vietnamese mapping:\")\n",
    "    for cls in missing_mappings:\n",
    "        print(f\"  - {cls}\")\n",
    "else:\n",
    "    print(\"âœ“ All classes have Vietnamese mappings!\")\n",
    "\n",
    "# Create Vietnamese version of class names\n",
    "vietnamese_names = []\n",
    "for class_name in dataset_classes:\n",
    "    vi_name = class_mapping.get(class_name, class_name)\n",
    "    vietnamese_names.append(vi_name)\n",
    "\n",
    "# Update data.yaml with Vietnamese names\n",
    "data_config['names_vi'] = vietnamese_names\n",
    "data_config['names_en'] = dataset_classes\n",
    "\n",
    "# Save updated data.yaml\n",
    "yaml_output_path = Path(dataset.location) / 'data_vi.yaml'\n",
    "with open(yaml_output_path, 'w', encoding='utf-8') as f:\n",
    "    yaml.dump(data_config, f, allow_unicode=True, default_flow_style=False)\n",
    "\n",
    "print(f\"\\nâœ“ Updated config saved to: {yaml_output_path}\")\n",
    "print(f\"âœ“ Vietnamese names added: {len(vietnamese_names)} classes\")\n",
    "\n",
    "# Display mapping summary\n",
    "print(\"\\nğŸ“Š Class Mapping Summary:\")\n",
    "print(\"=\" * 60)\n",
    "for idx, (en, vi) in enumerate(zip(dataset_classes, vietnamese_names)):\n",
    "    print(f\"{idx:2d}. {en:25s} â†’ {vi}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c912ce1c",
   "metadata": {},
   "source": [
    "## Section 5: Preprocessing and Data Augmentation\n",
    "\n",
    "Apply custom filters from backend for preprocessing:\n",
    "- Histogram Equalization (contrast enhancement)\n",
    "- Gaussian Blur (noise reduction)\n",
    "\n",
    "**Note**: This section will be implemented in tasks T062-T065"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0b61bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import custom filter implementations from backend\n",
    "import sys\n",
    "sys.path.append('../backend/src')\n",
    "\n",
    "from filters.histogram import apply_histogram_equalization\n",
    "from filters.gaussian import apply_gaussian_blur\n",
    "\n",
    "print(\"âœ“ Filter implementations imported successfully\")\n",
    "print(\"  - Histogram Equalization: apply_histogram_equalization()\")\n",
    "print(\"  - Gaussian Blur: apply_gaussian_blur()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a211b2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply preprocessing filters to enhance training images (optional)\n",
    "\n",
    "def preprocess_image(image_path, output_path):\n",
    "    \"\"\"\n",
    "    Apply histogram equalization and Gaussian blur for contrast enhancement.\n",
    "    \n",
    "    Args:\n",
    "        image_path: Path to input image\n",
    "        output_path: Path to save preprocessed image\n",
    "    \"\"\"\n",
    "    # Load image\n",
    "    img = Image.open(image_path).convert('L')  # Convert to grayscale\n",
    "    img_array = np.array(img)\n",
    "    \n",
    "    # Apply histogram equalization for contrast enhancement\n",
    "    img_equalized = apply_histogram_equalization(img_array)\n",
    "    \n",
    "    # Apply Gaussian blur for noise reduction\n",
    "    img_blurred = apply_gaussian_blur(img_equalized)\n",
    "    \n",
    "    # Save preprocessed image\n",
    "    result_img = Image.fromarray(img_blurred.astype(np.uint8))\n",
    "    result_img.save(output_path)\n",
    "    \n",
    "    return img_blurred\n",
    "\n",
    "# Create preprocessed dataset directory\n",
    "preprocessed_dir = Path(dataset.location) / 'preprocessed'\n",
    "preprocessed_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"ğŸ”„ Preprocessing training images...\")\n",
    "print(f\"ğŸ“ Output directory: {preprocessed_dir}\")\n",
    "\n",
    "# Preprocess training images (optional - can be used for augmentation)\n",
    "train_images_dir = Path(dataset.location) / 'train' / 'images'\n",
    "preprocessed_train_dir = preprocessed_dir / 'train' / 'images'\n",
    "preprocessed_train_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Sample preprocessing (process first 100 images as demo)\n",
    "sample_images = list(train_images_dir.glob('*.jpg'))[:100]\n",
    "\n",
    "if sample_images:\n",
    "    print(f\"ğŸ“Š Processing {len(sample_images)} sample images...\")\n",
    "    \n",
    "    for img_path in tqdm(sample_images, desc=\"Preprocessing\"):\n",
    "        output_path = preprocessed_train_dir / img_path.name\n",
    "        try:\n",
    "            preprocess_image(img_path, output_path)\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Error processing {img_path.name}: {e}\")\n",
    "    \n",
    "    print(f\"âœ“ Preprocessing complete: {len(list(preprocessed_train_dir.glob('*.jpg')))} images processed\")\n",
    "else:\n",
    "    print(\"âš ï¸ No training images found to preprocess\")\n",
    "\n",
    "print(\"\\nğŸ’¡ Note: Preprocessing is optional. Original images can be used for training.\")\n",
    "print(\"   Preprocessed images are stored separately and can be used for comparison.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b878a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation with filter-based and geometric transforms\n",
    "\n",
    "import random\n",
    "\n",
    "def augment_image(img_array):\n",
    "    \"\"\"\n",
    "    Apply random augmentations to an image.\n",
    "    \n",
    "    Args:\n",
    "        img_array: Input image as numpy array\n",
    "        \n",
    "    Returns:\n",
    "        Augmented image as numpy array\n",
    "    \"\"\"\n",
    "    # Random filter application (50% chance)\n",
    "    if random.random() > 0.5:\n",
    "        if random.random() > 0.5:\n",
    "            img_array = apply_histogram_equalization(img_array)\n",
    "        else:\n",
    "            img_array = apply_gaussian_blur(img_array)\n",
    "    \n",
    "    # Convert to PIL for geometric transforms\n",
    "    img = Image.fromarray(img_array.astype(np.uint8))\n",
    "    \n",
    "    # Random horizontal flip (50% chance)\n",
    "    if random.random() > 0.5:\n",
    "        img = img.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "    \n",
    "    # Random rotation (-15 to 15 degrees)\n",
    "    if random.random() > 0.5:\n",
    "        angle = random.uniform(-15, 15)\n",
    "        img = img.rotate(angle, fillcolor=0)\n",
    "    \n",
    "    # Random brightness adjustment (0.8 to 1.2)\n",
    "    if random.random() > 0.5:\n",
    "        from PIL import ImageEnhance\n",
    "        enhancer = ImageEnhance.Brightness(img)\n",
    "        factor = random.uniform(0.8, 1.2)\n",
    "        img = enhancer.enhance(factor)\n",
    "    \n",
    "    # Random contrast adjustment (0.8 to 1.2)\n",
    "    if random.random() > 0.5:\n",
    "        from PIL import ImageEnhance\n",
    "        enhancer = ImageEnhance.Contrast(img)\n",
    "        factor = random.uniform(0.8, 1.2)\n",
    "        img = enhancer.enhance(factor)\n",
    "    \n",
    "    return np.array(img)\n",
    "\n",
    "# Create augmented dataset directory\n",
    "augmented_dir = Path(dataset.location) / 'augmented'\n",
    "augmented_train_dir = augmented_dir / 'train' / 'images'\n",
    "augmented_labels_dir = augmented_dir / 'train' / 'labels'\n",
    "augmented_train_dir.mkdir(parents=True, exist_ok=True)\n",
    "augmented_labels_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"ğŸ² Data Augmentation Configuration:\")\n",
    "print(\"=\" * 60)\n",
    "print(\"Augmentation techniques:\")\n",
    "print(\"  âœ“ Random histogram equalization (50% chance)\")\n",
    "print(\"  âœ“ Random Gaussian blur (50% chance)\")\n",
    "print(\"  âœ“ Random horizontal flip (50% chance)\")\n",
    "print(\"  âœ“ Random rotation Â±15Â° (50% chance)\")\n",
    "print(\"  âœ“ Random brightness 0.8-1.2x (50% chance)\")\n",
    "print(\"  âœ“ Random contrast 0.8-1.2x (50% chance)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Sample augmentation (augment first 50 images as demo)\n",
    "train_images_dir = Path(dataset.location) / 'train' / 'images'\n",
    "train_labels_dir = Path(dataset.location) / 'train' / 'labels'\n",
    "sample_images = list(train_images_dir.glob('*.jpg'))[:50]\n",
    "\n",
    "if sample_images:\n",
    "    print(f\"\\nğŸ“Š Augmenting {len(sample_images)} sample images...\")\n",
    "    \n",
    "    augmented_count = 0\n",
    "    for img_path in tqdm(sample_images, desc=\"Augmenting\"):\n",
    "        try:\n",
    "            # Load and augment image\n",
    "            img = Image.open(img_path).convert('L')\n",
    "            img_array = np.array(img)\n",
    "            augmented_array = augment_image(img_array)\n",
    "            \n",
    "            # Save augmented image\n",
    "            aug_img_path = augmented_train_dir / f\"aug_{img_path.name}\"\n",
    "            Image.fromarray(augmented_array.astype(np.uint8)).save(aug_img_path)\n",
    "            \n",
    "            # Copy corresponding label file\n",
    "            label_path = train_labels_dir / f\"{img_path.stem}.txt\"\n",
    "            if label_path.exists():\n",
    "                aug_label_path = augmented_labels_dir / f\"aug_{img_path.stem}.txt\"\n",
    "                shutil.copy(label_path, aug_label_path)\n",
    "            \n",
    "            augmented_count += 1\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Error augmenting {img_path.name}: {e}\")\n",
    "    \n",
    "    print(f\"\\nâœ“ Augmentation complete: {augmented_count} images augmented\")\n",
    "    print(f\"ğŸ“ Augmented images: {augmented_train_dir}\")\n",
    "    print(f\"ğŸ“ Augmented labels: {augmented_labels_dir}\")\n",
    "else:\n",
    "    print(\"âš ï¸ No training images found for augmentation\")\n",
    "\n",
    "print(\"\\nğŸ’¡ Note: Augmented images can be merged with original training set\")\n",
    "print(\"   to increase dataset diversity and improve model generalization.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ed7aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset statistics visualization\n",
    "\n",
    "def analyze_dataset(dataset_path):\n",
    "    \"\"\"\n",
    "    Analyze dataset and collect statistics.\n",
    "    \n",
    "    Args:\n",
    "        dataset_path: Path to dataset root\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with dataset statistics\n",
    "    \"\"\"\n",
    "    stats = {\n",
    "        'splits': {},\n",
    "        'class_distribution': {},\n",
    "        'image_dimensions': [],\n",
    "        'normal_count': 0,\n",
    "        'abnormal_count': 0\n",
    "    }\n",
    "    \n",
    "    for split in ['train', 'valid', 'test']:\n",
    "        images_dir = Path(dataset_path) / split / 'images'\n",
    "        labels_dir = Path(dataset_path) / split / 'labels'\n",
    "        \n",
    "        if not images_dir.exists():\n",
    "            continue\n",
    "        \n",
    "        image_files = list(images_dir.glob('*.jpg')) + list(images_dir.glob('*.png'))\n",
    "        \n",
    "        split_stats = {\n",
    "            'total_images': len(image_files),\n",
    "            'normal': 0,\n",
    "            'abnormal': 0,\n",
    "            'total_annotations': 0\n",
    "        }\n",
    "        \n",
    "        # Analyze each image\n",
    "        for img_path in image_files:\n",
    "            # Get image dimensions\n",
    "            try:\n",
    "                img = Image.open(img_path)\n",
    "                stats['image_dimensions'].append(img.size)\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            # Check labels\n",
    "            label_path = labels_dir / f\"{img_path.stem}.txt\"\n",
    "            if label_path.exists() and label_path.stat().st_size > 0:\n",
    "                split_stats['abnormal'] += 1\n",
    "                stats['abnormal_count'] += 1\n",
    "                # Count annotations\n",
    "                with open(label_path, 'r') as f:\n",
    "                    annotations = f.readlines()\n",
    "                    split_stats['total_annotations'] += len(annotations)\n",
    "            else:\n",
    "                split_stats['normal'] += 1\n",
    "                stats['normal_count'] += 1\n",
    "        \n",
    "        stats['splits'][split] = split_stats\n",
    "    \n",
    "    return stats\n",
    "\n",
    "# Analyze original dataset\n",
    "print(\"ğŸ“Š Dataset Statistics Analysis\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "dataset_stats = analyze_dataset(dataset.location)\n",
    "\n",
    "# Display split statistics\n",
    "print(\"\\nğŸ—‚ï¸ Dataset Splits:\")\n",
    "print(\"-\" * 80)\n",
    "for split, split_stats in dataset_stats['splits'].items():\n",
    "    total = split_stats['total_images']\n",
    "    normal = split_stats['normal']\n",
    "    abnormal = split_stats['abnormal']\n",
    "    normal_pct = (normal / total * 100) if total > 0 else 0\n",
    "    abnormal_pct = (abnormal / total * 100) if total > 0 else 0\n",
    "    \n",
    "    print(f\"\\n{split.upper()}:\")\n",
    "    print(f\"  Total images:      {total:5d}\")\n",
    "    print(f\"  Normal (healthy):  {normal:5d} ({normal_pct:5.1f}%)\")\n",
    "    print(f\"  Abnormal:          {abnormal:5d} ({abnormal_pct:5.1f}%)\")\n",
    "    print(f\"  Total annotations: {split_stats['total_annotations']:5d}\")\n",
    "\n",
    "# Overall statistics\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ğŸ“ˆ Overall Dataset Statistics:\")\n",
    "print(\"-\" * 80)\n",
    "total_images = dataset_stats['normal_count'] + dataset_stats['abnormal_count']\n",
    "normal_pct = (dataset_stats['normal_count'] / total_images * 100) if total_images > 0 else 0\n",
    "abnormal_pct = (dataset_stats['abnormal_count'] / total_images * 100) if total_images > 0 else 0\n",
    "\n",
    "print(f\"Total images:      {total_images:5d}\")\n",
    "print(f\"Normal (healthy):  {dataset_stats['normal_count']:5d} ({normal_pct:5.1f}%)\")\n",
    "print(f\"Abnormal:          {dataset_stats['abnormal_count']:5d} ({abnormal_pct:5.1f}%)\")\n",
    "\n",
    "# Image dimensions statistics\n",
    "if dataset_stats['image_dimensions']:\n",
    "    widths = [dim[0] for dim in dataset_stats['image_dimensions']]\n",
    "    heights = [dim[1] for dim in dataset_stats['image_dimensions']]\n",
    "    \n",
    "    print(f\"\\nğŸ“ Image Dimensions:\")\n",
    "    print(f\"  Width  - Min: {min(widths):4d}px, Max: {max(widths):4d}px, Avg: {sum(widths)//len(widths):4d}px\")\n",
    "    print(f\"  Height - Min: {min(heights):4d}px, Max: {max(heights):4d}px, Avg: {sum(heights)//len(heights):4d}px\")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Class balance analysis\n",
    "print(\"\\nâš–ï¸ Dataset Balance Analysis:\")\n",
    "if normal_pct > 80:\n",
    "    print(\"  âš ï¸ WARNING: Dataset is heavily imbalanced towards normal images\")\n",
    "    print(\"     Consider using weighted loss or oversampling abnormal cases\")\n",
    "elif abnormal_pct > 80:\n",
    "    print(\"  âš ï¸ WARNING: Dataset is heavily imbalanced towards abnormal images\")\n",
    "    print(\"     This is unusual for medical datasets\")\n",
    "elif 40 <= normal_pct <= 60:\n",
    "    print(\"  âœ“ Dataset is well balanced between normal and abnormal cases\")\n",
    "else:\n",
    "    print(\"  â„¹ï¸ Dataset has moderate class imbalance\")\n",
    "    print(\"     Consider monitoring per-class metrics during training\")\n",
    "\n",
    "print(\"\\nâœ“ Dataset analysis complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ef861e",
   "metadata": {},
   "source": [
    "## Section 6: Model Training\n",
    "\n",
    "Fine-tune YOLOv11s with:\n",
    "- Base model: yolov11s.pt\n",
    "- Epochs: 50\n",
    "- Batch size: 16\n",
    "- Image size: 640\n",
    "- Early stopping patience: 10\n",
    "\n",
    "**Note**: This section will be implemented in tasks T066-T070"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bc7c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Weights & Biases for experiment tracking\n",
    "\n",
    "import wandb\n",
    "\n",
    "# Initialize WandB project\n",
    "wandb.init(\n",
    "    project=\"chest-xray-detection\",\n",
    "    name=\"yolov11s-finetune\",\n",
    "    config={\n",
    "        \"model\": \"YOLOv11s\",\n",
    "        \"dataset\": \"VinBigData Chest X-ray v3\",\n",
    "        \"epochs\": 50,\n",
    "        \"batch_size\": 16,\n",
    "        \"image_size\": 640,\n",
    "        \"patience\": 10,\n",
    "        \"optimizer\": \"AdamW\",\n",
    "        \"learning_rate\": 0.001,\n",
    "        \"augmentation\": \"enabled\",\n",
    "        \"preprocessing\": \"histogram_eq + gaussian_blur\"\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"âœ“ WandB initialized successfully\")\n",
    "print(f\"  Project: chest-xray-detection\")\n",
    "print(f\"  Run name: {wandb.run.name}\")\n",
    "print(f\"  Run URL: {wandb.run.url}\")\n",
    "print(\"\\nğŸ“Š Hyperparameters logged:\")\n",
    "for key, value in wandb.config.items():\n",
    "    print(f\"  - {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2ef8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train YOLOv11s model with integrated progress tracking and logging\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Training configuration\n",
    "training_config = {\n",
    "    'data': str(Path(dataset.location) / 'data.yaml'),\n",
    "    'epochs': 50,\n",
    "    'batch': 16,\n",
    "    'imgsz': 640,\n",
    "    'patience': 10,\n",
    "    'save': True,\n",
    "    'plots': True,\n",
    "    'verbose': True,\n",
    "    'device': 'cuda' if os.system('nvidia-smi > /dev/null 2>&1') == 0 else 'cpu'\n",
    "}\n",
    "\n",
    "print(\"ğŸš€ Starting YOLOv11s Training\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nâš™ï¸ Training Configuration:\")\n",
    "for key, value in training_config.items():\n",
    "    print(f\"  {key:15s}: {value}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Check device\n",
    "device_info = training_config['device']\n",
    "if device_info == 'cuda':\n",
    "    print(\"\\nğŸ® GPU detected: Training will use CUDA acceleration\")\n",
    "else:\n",
    "    print(\"\\nğŸ’» No GPU detected: Training will use CPU (slower)\")\n",
    "\n",
    "# Load base YOLOv11s model\n",
    "print(\"\\nğŸ“¦ Loading base YOLOv11s model...\")\n",
    "model = YOLO('yolov11s.pt')\n",
    "\n",
    "print(\"âœ“ Model loaded successfully\")\n",
    "print(f\"  Model architecture: YOLOv11s\")\n",
    "print(f\"  Parameters: ~{sum(p.numel() for p in model.model.parameters()) / 1e6:.1f}M\")\n",
    "\n",
    "# Train the model with WandB integration\n",
    "# Note: Ultralytics automatically integrates with WandB when wandb.init() has been called\n",
    "print(\"\\nğŸ‹ï¸ Starting training...\")\n",
    "print(\"ğŸ“Š Progress will be tracked with tqdm and logged to WandB\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "try:\n",
    "    results = model.train(\n",
    "        **training_config,\n",
    "        # WandB is automatically integrated by ultralytics\n",
    "        project='chest-xray-detection',\n",
    "        name='yolov11s-finetune'\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"âœ“ Training completed successfully!\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Display training results\n",
    "    print(\"\\nğŸ“ˆ Training Results:\")\n",
    "    print(f\"  Best epoch: {results.best_epoch if hasattr(results, 'best_epoch') else 'N/A'}\")\n",
    "    print(f\"  Best mAP50: {results.results_dict.get('metrics/mAP50(B)', 'N/A')}\")\n",
    "    print(f\"  Best mAP50-95: {results.results_dict.get('metrics/mAP50-95(B)', 'N/A')}\")\n",
    "    print(f\"  Final loss: {results.results_dict.get('train/box_loss', 'N/A')}\")\n",
    "    \n",
    "    # Save best model path\n",
    "    best_model_path = results.save_dir / 'weights' / 'best.pt'\n",
    "    print(f\"\\nğŸ’¾ Best model saved to: {best_model_path}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\nâŒ Training failed with error: {e}\")\n",
    "    print(\"Please check the error message above and try again\")\n",
    "    raise\n",
    "\n",
    "print(\"\\nâœ“ Training phase complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e3f692",
   "metadata": {},
   "source": [
    "## Section 7: Validation and Analysis\n",
    "\n",
    "Test trained model on validation set:\n",
    "- Calculate mAP (mean Average Precision)\n",
    "- Generate confusion matrix\n",
    "- Visualize predictions with Vietnamese labels\n",
    "\n",
    "**Note**: This section will be implemented in tasks T071-T074"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c6348b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate trained model on test set\n",
    "\n",
    "print(\"ğŸ§ª Model Validation on Test Set\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Load the fine-tuned model\n",
    "if best_model_path.exists():\n",
    "    print(f\"ğŸ“¦ Loading fine-tuned model: {best_model_path}\")\n",
    "    model = YOLO(str(best_model_path))\n",
    "    print(\"âœ“ Model loaded successfully\")\n",
    "else:\n",
    "    print(\"âš ï¸ WARNING: Fine-tuned model not found, using last trained model\")\n",
    "    model = YOLO('runs/detect/train/weights/best.pt')\n",
    "\n",
    "# Run validation on test set\n",
    "test_data_yaml = Path(dataset.location) / 'data.yaml'\n",
    "\n",
    "print(f\"\\nğŸ” Running validation on test set...\")\n",
    "print(f\"ğŸ“„ Data config: {test_data_yaml}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "try:\n",
    "    # Validate the model\n",
    "    metrics = model.val(data=str(test_data_yaml), split='test')\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"ğŸ“Š Validation Results:\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Display key metrics\n",
    "    results_dict = metrics.results_dict\n",
    "    \n",
    "    print(\"\\nğŸ¯ Overall Metrics:\")\n",
    "    print(f\"  mAP50:       {results_dict.get('metrics/mAP50(B)', 0):.4f}\")\n",
    "    print(f\"  mAP50-95:    {results_dict.get('metrics/mAP50-95(B)', 0):.4f}\")\n",
    "    print(f\"  Precision:   {results_dict.get('metrics/precision(B)', 0):.4f}\")\n",
    "    print(f\"  Recall:      {results_dict.get('metrics/recall(B)', 0):.4f}\")\n",
    "    \n",
    "    # Per-class metrics if available\n",
    "    if hasattr(metrics, 'box'):\n",
    "        print(\"\\nğŸ“‹ Per-Class Metrics:\")\n",
    "        print(f\"  {'Class':<25s} {'Precision':>10s} {'Recall':>10s} {'mAP50':>10s}\")\n",
    "        print(\"  \" + \"-\" * 60)\n",
    "        \n",
    "        # Get class names\n",
    "        class_names = model.names\n",
    "        \n",
    "        # Display metrics for each class\n",
    "        for class_id, class_name in class_names.items():\n",
    "            if hasattr(metrics.box, 'class_result'):\n",
    "                try:\n",
    "                    class_metrics = metrics.box.class_result(class_id)\n",
    "                    p = class_metrics[0] if len(class_metrics) > 0 else 0\n",
    "                    r = class_metrics[1] if len(class_metrics) > 1 else 0\n",
    "                    ap50 = class_metrics[2] if len(class_metrics) > 2 else 0\n",
    "                    print(f\"  {class_name:<25s} {p:>10.4f} {r:>10.4f} {ap50:>10.4f}\")\n",
    "                except:\n",
    "                    pass\n",
    "    \n",
    "    # Confusion matrix location\n",
    "    confusion_matrix_path = Path('runs/detect/val/confusion_matrix.png')\n",
    "    if confusion_matrix_path.exists():\n",
    "        print(f\"\\nğŸ“ˆ Confusion matrix saved to: {confusion_matrix_path}\")\n",
    "    \n",
    "    print(\"\\nâœ“ Validation complete\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\nâŒ Validation failed: {e}\")\n",
    "    print(\"   Please ensure training was completed successfully\")\n",
    "    raise\n",
    "\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d7ad46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify Vietnamese label mapping in predictions\n",
    "\n",
    "print(\"ğŸŒ Vietnamese Label Verification\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Load class mapping\n",
    "with open('configs/class_mapping.json', 'r', encoding='utf-8') as f:\n",
    "    class_mapping = json.load(f)\n",
    "\n",
    "print(\"\\nğŸ“‹ Verifying model predictions use correct Vietnamese labels...\")\n",
    "\n",
    "# Get model's class names\n",
    "model_classes = model.names\n",
    "\n",
    "print(f\"\\nâœ“ Model has {len(model_classes)} classes\")\n",
    "print(\"\\nğŸ” Class Mapping Verification:\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'Class ID':<10s} {'English Name':<30s} {'Vietnamese Name':<30s} {'Status':<10s}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Verify each class\n",
    "mapping_errors = []\n",
    "for class_id, class_name_en in model_classes.items():\n",
    "    # Check if English name has Vietnamese mapping\n",
    "    if class_name_en in class_mapping:\n",
    "        class_name_vi = class_mapping[class_name_en]\n",
    "        status = \"âœ“ OK\"\n",
    "    else:\n",
    "        class_name_vi = \"MISSING\"\n",
    "        status = \"âœ— ERROR\"\n",
    "        mapping_errors.append(class_name_en)\n",
    "    \n",
    "    print(f\"{class_id:<10d} {class_name_en:<30s} {class_name_vi:<30s} {status:<10s}\")\n",
    "\n",
    "print(\"-\" * 80)\n",
    "\n",
    "if mapping_errors:\n",
    "    print(f\"\\nâŒ Found {len(mapping_errors)} classes without Vietnamese mapping:\")\n",
    "    for cls in mapping_errors:\n",
    "        print(f\"   - {cls}\")\n",
    "    print(\"\\nâš ï¸ WARNING: These classes will display in English in the application\")\n",
    "    print(\"   Update configs/class_mapping.json to add missing translations\")\n",
    "else:\n",
    "    print(\"\\nâœ“ All classes have Vietnamese translations!\")\n",
    "    print(\"  Predictions will display correctly in the web application\")\n",
    "\n",
    "# Create reverse mapping (Vietnamese to English) for validation\n",
    "reverse_mapping = {vi: en for en, vi in class_mapping.items()}\n",
    "\n",
    "print(f\"\\nğŸ“Š Mapping Statistics:\")\n",
    "print(f\"  Total classes in model:  {len(model_classes)}\")\n",
    "print(f\"  Classes with Vietnamese: {len(model_classes) - len(mapping_errors)}\")\n",
    "print(f\"  Classes missing Vietnamese: {len(mapping_errors)}\")\n",
    "print(f\"  Coverage: {(len(model_classes) - len(mapping_errors)) / len(model_classes) * 100:.1f}%\")\n",
    "\n",
    "# Test prediction with Vietnamese labels (if model is loaded)\n",
    "print(\"\\nğŸ§ª Testing prediction with Vietnamese labels...\")\n",
    "test_images_dir = Path(dataset.location) / 'test' / 'images'\n",
    "if test_images_dir.exists():\n",
    "    test_images = list(test_images_dir.glob('*.jpg'))[:1]  # Test with first image\n",
    "    \n",
    "    if test_images:\n",
    "        test_img = test_images[0]\n",
    "        print(f\"   Test image: {test_img.name}\")\n",
    "        \n",
    "        # Run prediction\n",
    "        results = model(test_img, verbose=False)\n",
    "        \n",
    "        if len(results) > 0 and len(results[0].boxes) > 0:\n",
    "            print(f\"   âœ“ Found {len(results[0].boxes)} detections\")\n",
    "            \n",
    "            # Display detections with Vietnamese labels\n",
    "            for box in results[0].boxes[:3]:  # Show first 3\n",
    "                class_id = int(box.cls[0])\n",
    "                confidence = float(box.conf[0])\n",
    "                class_name_en = model_classes[class_id]\n",
    "                class_name_vi = class_mapping.get(class_name_en, class_name_en)\n",
    "                \n",
    "                print(f\"     - {class_name_vi} ({class_name_en}): {confidence:.2%}\")\n",
    "        else:\n",
    "            print(\"   âœ“ No detections (image is normal)\")\n",
    "    else:\n",
    "        print(\"   âš ï¸ No test images found\")\n",
    "else:\n",
    "    print(\"   âš ï¸ Test images directory not found\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"âœ“ Vietnamese label verification complete\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3764f4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sample predictions with Vietnamese labels\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "print(\"ğŸ–¼ï¸ Sample Prediction Visualization\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Get test images\n",
    "test_images_dir = Path(dataset.location) / 'test' / 'images'\n",
    "\n",
    "if not test_images_dir.exists():\n",
    "    print(\"âš ï¸ Test images directory not found\")\n",
    "else:\n",
    "    # Select sample images (mix of normal and abnormal if possible)\n",
    "    test_images = list(test_images_dir.glob('*.jpg'))[:6]  # Show 6 samples\n",
    "    \n",
    "    if not test_images:\n",
    "        print(\"âš ï¸ No test images found\")\n",
    "    else:\n",
    "        print(f\"ğŸ“Š Visualizing predictions for {len(test_images)} sample images...\")\n",
    "        \n",
    "        # Create figure with subplots\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        for idx, img_path in enumerate(test_images):\n",
    "            if idx >= len(axes):\n",
    "                break\n",
    "            \n",
    "            ax = axes[idx]\n",
    "            \n",
    "            # Load image\n",
    "            img = Image.open(img_path)\n",
    "            img_array = np.array(img)\n",
    "            \n",
    "            # Run prediction\n",
    "            results = model(img_path, verbose=False)\n",
    "            \n",
    "            # Display image\n",
    "            ax.imshow(img_array, cmap='gray')\n",
    "            ax.set_title(f\"{img_path.name}\", fontsize=10, pad=10)\n",
    "            ax.axis('off')\n",
    "            \n",
    "            # Draw bounding boxes with Vietnamese labels\n",
    "            if len(results) > 0 and len(results[0].boxes) > 0:\n",
    "                boxes = results[0].boxes\n",
    "                \n",
    "                for box in boxes:\n",
    "                    # Get box coordinates (xyxy format)\n",
    "                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
    "                    confidence = float(box.conf[0])\n",
    "                    class_id = int(box.cls[0])\n",
    "                    \n",
    "                    # Get Vietnamese label\n",
    "                    class_name_en = model_classes[class_id]\n",
    "                    class_name_vi = class_mapping.get(class_name_en, class_name_en)\n",
    "                    \n",
    "                    # Determine box style based on confidence\n",
    "                    if confidence > 0.7:\n",
    "                        color = 'red'\n",
    "                        linestyle = '-'  # Solid\n",
    "                        label_prefix = 'ğŸ”´'\n",
    "                    elif confidence > 0.4:\n",
    "                        color = 'orange'\n",
    "                        linestyle = '--'  # Dashed\n",
    "                        label_prefix = 'ğŸŸ '\n",
    "                    else:\n",
    "                        continue  # Skip low confidence\n",
    "                    \n",
    "                    # Draw bounding box\n",
    "                    width = x2 - x1\n",
    "                    height = y2 - y1\n",
    "                    rect = patches.Rectangle(\n",
    "                        (x1, y1), width, height,\n",
    "                        linewidth=2,\n",
    "                        edgecolor=color,\n",
    "                        facecolor='none',\n",
    "                        linestyle=linestyle\n",
    "                    )\n",
    "                    ax.add_patch(rect)\n",
    "                    \n",
    "                    # Add label with Vietnamese name and confidence\n",
    "                    label_text = f\"{label_prefix} {class_name_vi}\\n{confidence:.1%}\"\n",
    "                    ax.text(\n",
    "                        x1, y1 - 10,\n",
    "                        label_text,\n",
    "                        color='white',\n",
    "                        fontsize=9,\n",
    "                        bbox=dict(\n",
    "                            boxstyle='round,pad=0.5',\n",
    "                            facecolor=color,\n",
    "                            alpha=0.8,\n",
    "                            edgecolor='none'\n",
    "                        ),\n",
    "                        verticalalignment='bottom'\n",
    "                    )\n",
    "                \n",
    "                # Add detection count\n",
    "                detection_text = f\"PhÃ¡t hiá»‡n: {len(boxes)} báº¥t thÆ°á»ng\"\n",
    "                ax.text(\n",
    "                    10, img_array.shape[0] - 10,\n",
    "                    detection_text,\n",
    "                    color='white',\n",
    "                    fontsize=10,\n",
    "                    bbox=dict(\n",
    "                        boxstyle='round,pad=0.5',\n",
    "                        facecolor='blue',\n",
    "                        alpha=0.7,\n",
    "                        edgecolor='none'\n",
    "                    ),\n",
    "                    verticalalignment='bottom'\n",
    "                )\n",
    "            else:\n",
    "                # Normal image - no detections\n",
    "                normal_text = \"âœ“ BÃ¬nh thÆ°á»ng\\n(KhÃ´ng phÃ¡t hiá»‡n báº¥t thÆ°á»ng)\"\n",
    "                ax.text(\n",
    "                    img_array.shape[1] // 2, img_array.shape[0] // 2,\n",
    "                    normal_text,\n",
    "                    color='white',\n",
    "                    fontsize=12,\n",
    "                    ha='center',\n",
    "                    va='center',\n",
    "                    bbox=dict(\n",
    "                        boxstyle='round,pad=1',\n",
    "                        facecolor='green',\n",
    "                        alpha=0.8,\n",
    "                        edgecolor='none'\n",
    "                    )\n",
    "                )\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('sample_predictions_vi.png', dpi=150, bbox_inches='tight')\n",
    "        print(f\"\\nâœ“ Visualization saved to: sample_predictions_vi.png\")\n",
    "        plt.show()\n",
    "        \n",
    "        # Legend\n",
    "        print(\"\\nğŸ“– Legend:\")\n",
    "        print(\"  ğŸ”´ Solid red box    = High confidence (>70%)\")\n",
    "        print(\"  ğŸŸ  Dashed orange box = Medium confidence (40-70%)\")\n",
    "        print(\"  âœ“ Green overlay     = Normal (no abnormalities)\")\n",
    "        \n",
    "        print(\"\\nğŸ’¡ All labels are displayed in Vietnamese as configured\")\n",
    "        print(\"   This matches the production behavior in the web application\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"âœ“ Sample prediction visualization complete\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0227eee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare base YOLOv11s vs fine-tuned model performance\n",
    "\n",
    "print(\"âš–ï¸ Model Comparison: Base vs Fine-Tuned\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Load both models\n",
    "print(\"\\nğŸ“¦ Loading models for comparison...\")\n",
    "\n",
    "# Fine-tuned model (already loaded)\n",
    "finetuned_model = model\n",
    "print(f\"âœ“ Fine-tuned model: {target_model_path}\")\n",
    "\n",
    "# Base model\n",
    "base_model = YOLO('yolov11s.pt')\n",
    "print(f\"âœ“ Base model: yolov11s.pt (pretrained on COCO)\")\n",
    "\n",
    "# Prepare test data\n",
    "test_data_yaml = Path(dataset.location) / 'data.yaml'\n",
    "\n",
    "print(\"\\nğŸ”¬ Evaluating both models on test set...\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Evaluate fine-tuned model\n",
    "print(\"\\n1ï¸âƒ£ Fine-tuned Model Evaluation:\")\n",
    "try:\n",
    "    finetuned_metrics = finetuned_model.val(data=str(test_data_yaml), split='test', verbose=False)\n",
    "    finetuned_results = finetuned_metrics.results_dict\n",
    "    \n",
    "    finetuned_map50 = finetuned_results.get('metrics/mAP50(B)', 0)\n",
    "    finetuned_map50_95 = finetuned_results.get('metrics/mAP50-95(B)', 0)\n",
    "    finetuned_precision = finetuned_results.get('metrics/precision(B)', 0)\n",
    "    finetuned_recall = finetuned_results.get('metrics/recall(B)', 0)\n",
    "    \n",
    "    print(f\"   mAP50:       {finetuned_map50:.4f}\")\n",
    "    print(f\"   mAP50-95:    {finetuned_map50_95:.4f}\")\n",
    "    print(f\"   Precision:   {finetuned_precision:.4f}\")\n",
    "    print(f\"   Recall:      {finetuned_recall:.4f}\")\n",
    "except Exception as e:\n",
    "    print(f\"   âŒ Evaluation failed: {e}\")\n",
    "    finetuned_map50 = 0\n",
    "    finetuned_map50_95 = 0\n",
    "    finetuned_precision = 0\n",
    "    finetuned_recall = 0\n",
    "\n",
    "# Evaluate base model\n",
    "print(\"\\n2ï¸âƒ£ Base Model Evaluation:\")\n",
    "try:\n",
    "    base_metrics = base_model.val(data=str(test_data_yaml), split='test', verbose=False)\n",
    "    base_results = base_metrics.results_dict\n",
    "    \n",
    "    base_map50 = base_results.get('metrics/mAP50(B)', 0)\n",
    "    base_map50_95 = base_results.get('metrics/mAP50-95(B)', 0)\n",
    "    base_precision = base_results.get('metrics/precision(B)', 0)\n",
    "    base_recall = base_results.get('metrics/recall(B)', 0)\n",
    "    \n",
    "    print(f\"   mAP50:       {base_map50:.4f}\")\n",
    "    print(f\"   mAP50-95:    {base_map50_95:.4f}\")\n",
    "    print(f\"   Precision:   {base_precision:.4f}\")\n",
    "    print(f\"   Recall:      {base_recall:.4f}\")\n",
    "except Exception as e:\n",
    "    print(f\"   âŒ Evaluation failed: {e}\")\n",
    "    base_map50 = 0\n",
    "    base_map50_95 = 0\n",
    "    base_precision = 0\n",
    "    base_recall = 0\n",
    "\n",
    "# Calculate improvements\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ğŸ“Š Performance Comparison:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "def calc_improvement(base, finetuned):\n",
    "    \"\"\"Calculate percentage improvement\"\"\"\n",
    "    if base == 0:\n",
    "        return 0\n",
    "    return ((finetuned - base) / base) * 100\n",
    "\n",
    "improvements = {\n",
    "    'mAP50': calc_improvement(base_map50, finetuned_map50),\n",
    "    'mAP50-95': calc_improvement(base_map50_95, finetuned_map50_95),\n",
    "    'Precision': calc_improvement(base_precision, finetuned_precision),\n",
    "    'Recall': calc_improvement(base_recall, finetuned_recall)\n",
    "}\n",
    "\n",
    "# Display comparison table\n",
    "print(f\"\\n{'Metric':<15s} {'Base':>12s} {'Fine-tuned':>12s} {'Improvement':>15s}\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'mAP50':<15s} {base_map50:>12.4f} {finetuned_map50:>12.4f} {improvements['mAP50']:>14.1f}%\")\n",
    "print(f\"{'mAP50-95':<15s} {base_map50_95:>12.4f} {finetuned_map50_95:>12.4f} {improvements['mAP50-95']:>14.1f}%\")\n",
    "print(f\"{'Precision':<15s} {base_precision:>12.4f} {finetuned_precision:>12.4f} {improvements['Precision']:>14.1f}%\")\n",
    "print(f\"{'Recall':<15s} {base_recall:>12.4f} {finetuned_recall:>12.4f} {improvements['Recall']:>14.1f}%\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Overall assessment\n",
    "avg_improvement = sum(improvements.values()) / len(improvements)\n",
    "print(f\"\\nğŸ“ˆ Average Improvement: {avg_improvement:+.1f}%\")\n",
    "\n",
    "if avg_improvement > 20:\n",
    "    print(\"\\nğŸ‰ EXCELLENT: Fine-tuning significantly improved model performance!\")\n",
    "    print(\"   The model is well-suited for chest X-ray abnormality detection\")\n",
    "elif avg_improvement > 10:\n",
    "    print(\"\\nâœ“ GOOD: Fine-tuning improved model performance\")\n",
    "    print(\"   The model shows better accuracy on the target dataset\")\n",
    "elif avg_improvement > 0:\n",
    "    print(\"\\nâœ“ MODERATE: Fine-tuning provided some improvement\")\n",
    "    print(\"   Consider additional training epochs or data augmentation\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸ WARNING: Fine-tuning did not improve performance\")\n",
    "    print(\"   Check training logs, hyperparameters, or dataset quality\")\n",
    "\n",
    "# Visualize comparison\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "\n",
    "metrics_names = ['mAP50', 'mAP50-95', 'Precision', 'Recall']\n",
    "base_values = [base_map50, base_map50_95, base_precision, base_recall]\n",
    "finetuned_values = [finetuned_map50, finetuned_map50_95, finetuned_precision, finetuned_recall]\n",
    "\n",
    "x = np.arange(len(metrics_names))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax.bar(x - width/2, base_values, width, label='Base YOLOv11s', color='lightblue')\n",
    "bars2 = ax.bar(x + width/2, finetuned_values, width, label='Fine-tuned', color='darkblue')\n",
    "\n",
    "ax.set_xlabel('Metrics', fontsize=12)\n",
    "ax.set_ylabel('Score', fontsize=12)\n",
    "ax.set_title('Base vs Fine-tuned Model Performance', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(metrics_names)\n",
    "ax.legend()\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bars in [bars1, bars2]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.3f}',\n",
    "                ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('model_comparison.png', dpi=150, bbox_inches='tight')\n",
    "print(f\"\\nâœ“ Comparison chart saved to: model_comparison.png\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"âœ“ Model comparison complete\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nğŸ¯ Recommendation:\")\n",
    "if avg_improvement > 10:\n",
    "    print(\"   âœ“ Use the fine-tuned model in production\")\n",
    "    print(f\"   âœ“ Model path: {target_model_path}\")\n",
    "else:\n",
    "    print(\"   âš ï¸ Review training configuration and dataset quality\")\n",
    "    print(\"   âš ï¸ Consider longer training or different hyperparameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca46dd1",
   "metadata": {},
   "source": [
    "## Section 8: Model Export\n",
    "\n",
    "Export best trained weights to backend models directory for production use.\n",
    "\n",
    "**Output path**: `backend/models/yolov11s_finetuned.pt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd442a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export best model weights to backend for production use\n",
    "\n",
    "# Define target path for backend\n",
    "backend_models_dir = Path('../backend/models')\n",
    "backend_models_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "target_model_path = backend_models_dir / 'yolov11s_finetuned.pt'\n",
    "\n",
    "print(\"ğŸ“¦ Exporting Model Weights\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Check if training was completed\n",
    "if 'best_model_path' not in locals():\n",
    "    print(\"âš ï¸ WARNING: Training results not found in this session\")\n",
    "    print(\"   Attempting to find best model from runs directory...\")\n",
    "    \n",
    "    # Try to find the most recent training run\n",
    "    runs_dir = Path('runs/detect')\n",
    "    if runs_dir.exists():\n",
    "        train_dirs = sorted([d for d in runs_dir.iterdir() if d.is_dir()], \n",
    "                          key=lambda x: x.stat().st_mtime, reverse=True)\n",
    "        if train_dirs:\n",
    "            best_model_path = train_dirs[0] / 'weights' / 'best.pt'\n",
    "            print(f\"   Found: {best_model_path}\")\n",
    "        else:\n",
    "            print(\"âŒ No training runs found. Please run training first.\")\n",
    "            best_model_path = None\n",
    "    else:\n",
    "        print(\"âŒ No runs directory found. Please run training first.\")\n",
    "        best_model_path = None\n",
    "else:\n",
    "    print(f\"âœ“ Using best model from training: {best_model_path}\")\n",
    "\n",
    "# Copy model to backend\n",
    "if best_model_path and Path(best_model_path).exists():\n",
    "    print(f\"\\nğŸ“‚ Source: {best_model_path}\")\n",
    "    print(f\"ğŸ“‚ Target: {target_model_path}\")\n",
    "    \n",
    "    # Copy the model file\n",
    "    shutil.copy(best_model_path, target_model_path)\n",
    "    \n",
    "    # Verify the copy\n",
    "    if target_model_path.exists():\n",
    "        source_size = Path(best_model_path).stat().st_size\n",
    "        target_size = target_model_path.stat().st_size\n",
    "        \n",
    "        print(f\"\\nâœ“ Model exported successfully!\")\n",
    "        print(f\"  File size: {target_size / (1024*1024):.2f} MB\")\n",
    "        \n",
    "        if source_size == target_size:\n",
    "            print(f\"  âœ“ Checksum verified: File copied correctly\")\n",
    "        else:\n",
    "            print(f\"  âš ï¸ WARNING: File sizes differ (source: {source_size}, target: {target_size})\")\n",
    "        \n",
    "        print(f\"\\nğŸ¯ Model is ready for production use!\")\n",
    "        print(f\"   Backend can now load weights from: {target_model_path}\")\n",
    "        print(f\"   Update backend.src.models.yolo_detector.py to use this path\")\n",
    "    else:\n",
    "        print(\"âŒ Error: Model export failed - file not found at target location\")\n",
    "else:\n",
    "    print(\"\\nâŒ Error: Cannot export model - best weights file not found\")\n",
    "    print(\"   Please complete training first\")\n",
    "\n",
    "# Test model loading (optional)\n",
    "try:\n",
    "    print(\"\\nğŸ” Testing model loading...\")\n",
    "    test_model = YOLO(str(target_model_path))\n",
    "    print(\"âœ“ Model loads successfully in Ultralytics YOLO\")\n",
    "    print(f\"  Model type: {type(test_model.model).__name__}\")\n",
    "    print(f\"  Number of classes: {len(test_model.names)}\")\n",
    "    print(f\"  Class names: {list(test_model.names.values())[:5]}...\")  # Show first 5 classes\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ Warning: Model loading test failed: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"âœ“ Model export complete\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Close WandB run\n",
    "wandb.finish()\n",
    "print(\"\\nâœ“ WandB run finished\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Abnormal-prediction-in-chest-X-ray",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
